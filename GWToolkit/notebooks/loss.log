 iteration      100/  200000 | consumed samples:         3200 | elapsed time per iteration (ms): 303.6 | learning rate: 4.444E-05 | global batch size:    32 | lm loss: 9.706122E-02 | loss scale: 2097152.0 | grad norm: 0.024 | number of skipped iterations:  12 | number of nan iterations:   0 |
 iteration      200/  200000 | consumed samples:         6400 | elapsed time per iteration (ms): 264.3 | learning rate: 9.495E-05 | global batch size:    32 | lm loss: 2.122366E-03 | loss scale: 2097152.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/  200000 | consumed samples:         9600 | elapsed time per iteration (ms): 261.4 | learning rate: 9.992E-05 | global batch size:    32 | lm loss: 1.275565E-03 | loss scale: 2097152.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/  200000 | consumed samples:        12800 | elapsed time per iteration (ms): 262.2 | learning rate: 9.983E-05 | global batch size:    32 | lm loss: 1.008312E-03 | loss scale: 2097152.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/  200000 | consumed samples:        16000 | elapsed time per iteration (ms): 259.3 | learning rate: 9.974E-05 | global batch size:    32 | lm loss: 9.232771E-04 | loss scale: 2097152.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/  200000 | consumed samples:        19200 | elapsed time per iteration (ms): 266.6 | learning rate: 9.964E-05 | global batch size:    32 | lm loss: 6.531002E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/  200000 | consumed samples:        22400 | elapsed time per iteration (ms): 253.1 | learning rate: 9.955E-05 | global batch size:    32 | lm loss: 6.531756E-04 | loss scale: 2097152.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/  200000 | consumed samples:        25600 | elapsed time per iteration (ms): 253.3 | learning rate: 9.946E-05 | global batch size:    32 | lm loss: 6.483161E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/  200000 | consumed samples:        28800 | elapsed time per iteration (ms): 256.7 | learning rate: 9.937E-05 | global batch size:    32 | lm loss: 6.528109E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/  200000 | consumed samples:        32000 | elapsed time per iteration (ms): 254.2 | learning rate: 9.928E-05 | global batch size:    32 | lm loss: 6.433538E-04 | loss scale: 2097152.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1100/  200000 | consumed samples:        35200 | elapsed time per iteration (ms): 266.7 | learning rate: 9.919E-05 | global batch size:    32 | lm loss: 6.440675E-04 | loss scale: 4194304.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1200/  200000 | consumed samples:        38400 | elapsed time per iteration (ms): 254.1 | learning rate: 9.910E-05 | global batch size:    32 | lm loss: 6.573156E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1300/  200000 | consumed samples:        41600 | elapsed time per iteration (ms): 254.4 | learning rate: 9.901E-05 | global batch size:    32 | lm loss: 6.447437E-04 | loss scale: 4194304.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1400/  200000 | consumed samples:        44800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.892E-05 | global batch size:    32 | lm loss: 6.527977E-04 | loss scale: 4194304.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1500/  200000 | consumed samples:        48000 | elapsed time per iteration (ms): 254.7 | learning rate: 9.882E-05 | global batch size:    32 | lm loss: 6.486205E-04 | loss scale: 4194304.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1600/  200000 | consumed samples:        51200 | elapsed time per iteration (ms): 264.6 | learning rate: 9.873E-05 | global batch size:    32 | lm loss: 6.633323E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1700/  200000 | consumed samples:        54400 | elapsed time per iteration (ms): 258.4 | learning rate: 9.864E-05 | global batch size:    32 | lm loss: 6.533711E-04 | loss scale: 4194304.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1800/  200000 | consumed samples:        57600 | elapsed time per iteration (ms): 253.8 | learning rate: 9.855E-05 | global batch size:    32 | lm loss: 6.604908E-04 | loss scale: 4194304.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1900/  200000 | consumed samples:        60800 | elapsed time per iteration (ms): 259.0 | learning rate: 9.846E-05 | global batch size:    32 | lm loss: 6.657952E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2000/  200000 | consumed samples:        64000 | elapsed time per iteration (ms): 260.7 | learning rate: 9.837E-05 | global batch size:    32 | lm loss: 6.632921E-04 | loss scale: 4194304.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2100/  200000 | consumed samples:        67200 | elapsed time per iteration (ms): 274.5 | learning rate: 9.828E-05 | global batch size:    32 | lm loss: 6.739845E-04 | loss scale: 8388608.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2200/  200000 | consumed samples:        70400 | elapsed time per iteration (ms): 258.3 | learning rate: 9.819E-05 | global batch size:    32 | lm loss: 6.662659E-04 | loss scale: 8388608.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2300/  200000 | consumed samples:        73600 | elapsed time per iteration (ms): 257.1 | learning rate: 9.810E-05 | global batch size:    32 | lm loss: 6.718781E-04 | loss scale: 8388608.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2400/  200000 | consumed samples:        76800 | elapsed time per iteration (ms): 259.0 | learning rate: 9.801E-05 | global batch size:    32 | lm loss: 6.627337E-04 | loss scale: 8388608.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2500/  200000 | consumed samples:        80000 | elapsed time per iteration (ms): 256.1 | learning rate: 9.791E-05 | global batch size:    32 | lm loss: 6.646355E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2600/  200000 | consumed samples:        83200 | elapsed time per iteration (ms): 269.5 | learning rate: 9.782E-05 | global batch size:    32 | lm loss: 6.516803E-04 | loss scale: 8388608.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2700/  200000 | consumed samples:        86400 | elapsed time per iteration (ms): 261.2 | learning rate: 9.773E-05 | global batch size:    32 | lm loss: 6.710421E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2800/  200000 | consumed samples:        89600 | elapsed time per iteration (ms): 255.9 | learning rate: 9.764E-05 | global batch size:    32 | lm loss: 6.740583E-04 | loss scale: 8388608.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2900/  200000 | consumed samples:        92800 | elapsed time per iteration (ms): 257.4 | learning rate: 9.755E-05 | global batch size:    32 | lm loss: 6.590704E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3000/  200000 | consumed samples:        96000 | elapsed time per iteration (ms): 257.4 | learning rate: 9.746E-05 | global batch size:    32 | lm loss: 6.700991E-04 | loss scale: 8388608.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3100/  200000 | consumed samples:        99200 | elapsed time per iteration (ms): 274.1 | learning rate: 9.737E-05 | global batch size:    32 | lm loss: 6.570277E-04 | loss scale: 16777216.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3200/  200000 | consumed samples:       102400 | elapsed time per iteration (ms): 257.9 | learning rate: 9.728E-05 | global batch size:    32 | lm loss: 6.794741E-04 | loss scale: 16777216.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3300/  200000 | consumed samples:       105600 | elapsed time per iteration (ms): 259.1 | learning rate: 9.719E-05 | global batch size:    32 | lm loss: 6.458659E-04 | loss scale: 16777216.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3400/  200000 | consumed samples:       108800 | elapsed time per iteration (ms): 257.4 | learning rate: 9.709E-05 | global batch size:    32 | lm loss: 6.754433E-04 | loss scale: 16777216.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3500/  200000 | consumed samples:       112000 | elapsed time per iteration (ms): 257.8 | learning rate: 9.700E-05 | global batch size:    32 | lm loss: 6.659480E-04 | loss scale: 16777216.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3600/  200000 | consumed samples:       115200 | elapsed time per iteration (ms): 273.4 | learning rate: 9.691E-05 | global batch size:    32 | lm loss: 6.666736E-04 | loss scale: 16777216.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3700/  200000 | consumed samples:       118400 | elapsed time per iteration (ms): 256.9 | learning rate: 9.682E-05 | global batch size:    32 | lm loss: 6.585941E-04 | loss scale: 16777216.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3800/  200000 | consumed samples:       121600 | elapsed time per iteration (ms): 263.0 | learning rate: 9.673E-05 | global batch size:    32 | lm loss: 6.816215E-04 | loss scale: 16777216.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3900/  200000 | consumed samples:       124800 | elapsed time per iteration (ms): 257.3 | learning rate: 9.664E-05 | global batch size:    32 | lm loss: 6.839024E-04 | loss scale: 16777216.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4000/  200000 | consumed samples:       128000 | elapsed time per iteration (ms): 252.9 | learning rate: 9.655E-05 | global batch size:    32 | lm loss: 6.417631E-04 | loss scale: 16777216.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4100/  200000 | consumed samples:       131200 | elapsed time per iteration (ms): 270.4 | learning rate: 9.646E-05 | global batch size:    32 | lm loss: 6.542465E-04 | loss scale: 33554432.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4200/  200000 | consumed samples:       134400 | elapsed time per iteration (ms): 254.7 | learning rate: 9.637E-05 | global batch size:    32 | lm loss: 6.580620E-04 | loss scale: 33554432.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4300/  200000 | consumed samples:       137600 | elapsed time per iteration (ms): 252.8 | learning rate: 9.627E-05 | global batch size:    32 | lm loss: 6.576505E-04 | loss scale: 33554432.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4400/  200000 | consumed samples:       140800 | elapsed time per iteration (ms): 255.6 | learning rate: 9.618E-05 | global batch size:    32 | lm loss: 6.230443E-04 | loss scale: 33554432.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4500/  200000 | consumed samples:       144000 | elapsed time per iteration (ms): 262.4 | learning rate: 9.609E-05 | global batch size:    32 | lm loss: 9.362479E-04 | loss scale: 33554432.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4600/  200000 | consumed samples:       147200 | elapsed time per iteration (ms): 270.3 | learning rate: 9.600E-05 | global batch size:    32 | lm loss: 6.850941E-04 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4700/  200000 | consumed samples:       150400 | elapsed time per iteration (ms): 255.9 | learning rate: 9.591E-05 | global batch size:    32 | lm loss: 6.668676E-04 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4800/  200000 | consumed samples:       153600 | elapsed time per iteration (ms): 255.6 | learning rate: 9.582E-05 | global batch size:    32 | lm loss: 6.672812E-04 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4900/  200000 | consumed samples:       156800 | elapsed time per iteration (ms): 256.3 | learning rate: 9.573E-05 | global batch size:    32 | lm loss: 6.636014E-04 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5000/  200000 | consumed samples:       160000 | elapsed time per iteration (ms): 254.9 | learning rate: 9.564E-05 | global batch size:    32 | lm loss: 6.549595E-04 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5100/  200000 | consumed samples:       163200 | elapsed time per iteration (ms): 267.2 | learning rate: 9.555E-05 | global batch size:    32 | lm loss: 6.576794E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5200/  200000 | consumed samples:       166400 | elapsed time per iteration (ms): 249.3 | learning rate: 9.545E-05 | global batch size:    32 | lm loss: 6.704904E-04 | loss scale: 67108864.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5300/  200000 | consumed samples:       169600 | elapsed time per iteration (ms): 258.4 | learning rate: 9.536E-05 | global batch size:    32 | lm loss: 6.583305E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5400/  200000 | consumed samples:       172800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.527E-05 | global batch size:    32 | lm loss: 6.717139E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5500/  200000 | consumed samples:       176000 | elapsed time per iteration (ms): 254.6 | learning rate: 9.518E-05 | global batch size:    32 | lm loss: 7.205898E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5600/  200000 | consumed samples:       179200 | elapsed time per iteration (ms): 265.7 | learning rate: 9.509E-05 | global batch size:    32 | lm loss: 6.694280E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5700/  200000 | consumed samples:       182400 | elapsed time per iteration (ms): 257.8 | learning rate: 9.500E-05 | global batch size:    32 | lm loss: 6.564434E-04 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5800/  200000 | consumed samples:       185600 | elapsed time per iteration (ms): 255.1 | learning rate: 9.491E-05 | global batch size:    32 | lm loss: 6.675154E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5900/  200000 | consumed samples:       188800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.482E-05 | global batch size:    32 | lm loss: 6.914335E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6000/  200000 | consumed samples:       192000 | elapsed time per iteration (ms): 251.8 | learning rate: 9.473E-05 | global batch size:    32 | lm loss: 6.628920E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6100/  200000 | consumed samples:       195200 | elapsed time per iteration (ms): 271.0 | learning rate: 9.463E-05 | global batch size:    32 | lm loss: 6.649253E-04 | loss scale: 134217728.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6200/  200000 | consumed samples:       198400 | elapsed time per iteration (ms): 256.0 | learning rate: 9.454E-05 | global batch size:    32 | lm loss: 6.666468E-04 | loss scale: 134217728.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6300/  200000 | consumed samples:       201600 | elapsed time per iteration (ms): 259.7 | learning rate: 9.445E-05 | global batch size:    32 | lm loss: 6.685780E-04 | loss scale: 134217728.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6400/  200000 | consumed samples:       204800 | elapsed time per iteration (ms): 254.1 | learning rate: 9.436E-05 | global batch size:    32 | lm loss: 6.554129E-04 | loss scale: 134217728.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6500/  200000 | consumed samples:       208000 | elapsed time per iteration (ms): 249.3 | learning rate: 9.427E-05 | global batch size:    32 | lm loss: 6.379052E-04 | loss scale: 67108864.0 | grad norm: 0.021 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration     6600/  200000 | consumed samples:       211200 | elapsed time per iteration (ms): 266.5 | learning rate: 9.418E-05 | global batch size:    32 | lm loss: 6.199125E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6700/  200000 | consumed samples:       214400 | elapsed time per iteration (ms): 253.1 | learning rate: 9.409E-05 | global batch size:    32 | lm loss: 6.038041E-04 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6800/  200000 | consumed samples:       217600 | elapsed time per iteration (ms): 264.5 | learning rate: 9.400E-05 | global batch size:    32 | lm loss: 6.062541E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6900/  200000 | consumed samples:       220800 | elapsed time per iteration (ms): 251.5 | learning rate: 9.391E-05 | global batch size:    32 | lm loss: 6.083208E-04 | loss scale: 67108864.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7000/  200000 | consumed samples:       224000 | elapsed time per iteration (ms): 255.6 | learning rate: 9.382E-05 | global batch size:    32 | lm loss: 5.684185E-04 | loss scale: 67108864.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7100/  200000 | consumed samples:       227200 | elapsed time per iteration (ms): 270.0 | learning rate: 9.373E-05 | global batch size:    32 | lm loss: 5.564332E-04 | loss scale: 67108864.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7200/  200000 | consumed samples:       230400 | elapsed time per iteration (ms): 253.8 | learning rate: 9.363E-05 | global batch size:    32 | lm loss: 5.029616E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7300/  200000 | consumed samples:       233600 | elapsed time per iteration (ms): 253.9 | learning rate: 9.354E-05 | global batch size:    32 | lm loss: 4.911084E-04 | loss scale: 67108864.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7400/  200000 | consumed samples:       236800 | elapsed time per iteration (ms): 253.3 | learning rate: 9.345E-05 | global batch size:    32 | lm loss: 3.637996E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7500/  200000 | consumed samples:       240000 | elapsed time per iteration (ms): 263.7 | learning rate: 9.336E-05 | global batch size:    32 | lm loss: 3.247115E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7600/  200000 | consumed samples:       243200 | elapsed time per iteration (ms): 271.8 | learning rate: 9.327E-05 | global batch size:    32 | lm loss: 2.859428E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7700/  200000 | consumed samples:       246400 | elapsed time per iteration (ms): 259.5 | learning rate: 9.318E-05 | global batch size:    32 | lm loss: 2.435664E-04 | loss scale: 134217728.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7800/  200000 | consumed samples:       249600 | elapsed time per iteration (ms): 254.3 | learning rate: 9.309E-05 | global batch size:    32 | lm loss: 2.313434E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7900/  200000 | consumed samples:       252800 | elapsed time per iteration (ms): 255.8 | learning rate: 9.300E-05 | global batch size:    32 | lm loss: 2.083290E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8000/  200000 | consumed samples:       256000 | elapsed time per iteration (ms): 255.0 | learning rate: 9.291E-05 | global batch size:    32 | lm loss: 1.941747E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8100/  200000 | consumed samples:       259200 | elapsed time per iteration (ms): 269.8 | learning rate: 9.281E-05 | global batch size:    32 | lm loss: 1.974218E-04 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8200/  200000 | consumed samples:       262400 | elapsed time per iteration (ms): 257.0 | learning rate: 9.272E-05 | global batch size:    32 | lm loss: 1.809771E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     8300/  200000 | consumed samples:       265600 | elapsed time per iteration (ms): 256.4 | learning rate: 9.263E-05 | global batch size:    32 | lm loss: 1.720501E-04 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     8400/  200000 | consumed samples:       268800 | elapsed time per iteration (ms): 253.6 | learning rate: 9.254E-05 | global batch size:    32 | lm loss: 1.522172E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8500/  200000 | consumed samples:       272000 | elapsed time per iteration (ms): 254.7 | learning rate: 9.245E-05 | global batch size:    32 | lm loss: 1.474098E-04 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8600/  200000 | consumed samples:       275200 | elapsed time per iteration (ms): 264.1 | learning rate: 9.236E-05 | global batch size:    32 | lm loss: 1.429363E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8700/  200000 | consumed samples:       278400 | elapsed time per iteration (ms): 258.0 | learning rate: 9.227E-05 | global batch size:    32 | lm loss: 1.324781E-04 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8800/  200000 | consumed samples:       281600 | elapsed time per iteration (ms): 264.2 | learning rate: 9.218E-05 | global batch size:    32 | lm loss: 1.364638E-04 | loss scale: 67108864.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8900/  200000 | consumed samples:       284800 | elapsed time per iteration (ms): 255.7 | learning rate: 9.209E-05 | global batch size:    32 | lm loss: 1.339422E-04 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9000/  200000 | consumed samples:       288000 | elapsed time per iteration (ms): 260.8 | learning rate: 9.200E-05 | global batch size:    32 | lm loss: 1.307620E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9100/  200000 | consumed samples:       291200 | elapsed time per iteration (ms): 265.4 | learning rate: 9.191E-05 | global batch size:    32 | lm loss: 1.301183E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9200/  200000 | consumed samples:       294400 | elapsed time per iteration (ms): 256.1 | learning rate: 9.181E-05 | global batch size:    32 | lm loss: 1.142497E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9300/  200000 | consumed samples:       297600 | elapsed time per iteration (ms): 253.7 | learning rate: 9.172E-05 | global batch size:    32 | lm loss: 1.120337E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9400/  200000 | consumed samples:       300800 | elapsed time per iteration (ms): 254.2 | learning rate: 9.163E-05 | global batch size:    32 | lm loss: 1.204555E-04 | loss scale: 134217728.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9500/  200000 | consumed samples:       304000 | elapsed time per iteration (ms): 254.0 | learning rate: 9.154E-05 | global batch size:    32 | lm loss: 1.187519E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9600/  200000 | consumed samples:       307200 | elapsed time per iteration (ms): 266.7 | learning rate: 9.145E-05 | global batch size:    32 | lm loss: 1.095530E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9700/  200000 | consumed samples:       310400 | elapsed time per iteration (ms): 253.7 | learning rate: 9.136E-05 | global batch size:    32 | lm loss: 1.011459E-04 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9800/  200000 | consumed samples:       313600 | elapsed time per iteration (ms): 250.4 | learning rate: 9.127E-05 | global batch size:    32 | lm loss: 1.049916E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     9900/  200000 | consumed samples:       316800 | elapsed time per iteration (ms): 252.2 | learning rate: 9.118E-05 | global batch size:    32 | lm loss: 1.144618E-04 | loss scale: 134217728.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10000/  200000 | consumed samples:       320000 | elapsed time per iteration (ms): 252.4 | learning rate: 9.109E-05 | global batch size:    32 | lm loss: 1.202325E-04 | loss scale: 134217728.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10100/  200000 | consumed samples:       323200 | elapsed time per iteration (ms): 265.2 | learning rate: 9.100E-05 | global batch size:    32 | lm loss: 9.871851E-05 | loss scale: 134217728.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10200/  200000 | consumed samples:       326400 | elapsed time per iteration (ms): 259.5 | learning rate: 9.090E-05 | global batch size:    32 | lm loss: 1.041510E-04 | loss scale: 134217728.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10300/  200000 | consumed samples:       329600 | elapsed time per iteration (ms): 255.1 | learning rate: 9.081E-05 | global batch size:    32 | lm loss: 1.134543E-04 | loss scale: 134217728.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10400/  200000 | consumed samples:       332800 | elapsed time per iteration (ms): 260.4 | learning rate: 9.072E-05 | global batch size:    32 | lm loss: 9.927821E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10500/  200000 | consumed samples:       336000 | elapsed time per iteration (ms): 251.9 | learning rate: 9.063E-05 | global batch size:    32 | lm loss: 9.240475E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10600/  200000 | consumed samples:       339200 | elapsed time per iteration (ms): 274.2 | learning rate: 9.054E-05 | global batch size:    32 | lm loss: 9.571443E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10700/  200000 | consumed samples:       342400 | elapsed time per iteration (ms): 257.5 | learning rate: 9.045E-05 | global batch size:    32 | lm loss: 9.286555E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10800/  200000 | consumed samples:       345600 | elapsed time per iteration (ms): 252.9 | learning rate: 9.036E-05 | global batch size:    32 | lm loss: 1.056184E-04 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    10900/  200000 | consumed samples:       348800 | elapsed time per iteration (ms): 253.2 | learning rate: 9.027E-05 | global batch size:    32 | lm loss: 8.993842E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11000/  200000 | consumed samples:       352000 | elapsed time per iteration (ms): 255.1 | learning rate: 9.018E-05 | global batch size:    32 | lm loss: 9.151815E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11100/  200000 | consumed samples:       355200 | elapsed time per iteration (ms): 270.2 | learning rate: 9.009E-05 | global batch size:    32 | lm loss: 8.987840E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11200/  200000 | consumed samples:       358400 | elapsed time per iteration (ms): 261.9 | learning rate: 8.999E-05 | global batch size:    32 | lm loss: 1.034726E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11300/  200000 | consumed samples:       361600 | elapsed time per iteration (ms): 254.9 | learning rate: 8.990E-05 | global batch size:    32 | lm loss: 9.026983E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11400/  200000 | consumed samples:       364800 | elapsed time per iteration (ms): 254.1 | learning rate: 8.981E-05 | global batch size:    32 | lm loss: 8.876670E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11500/  200000 | consumed samples:       368000 | elapsed time per iteration (ms): 253.7 | learning rate: 8.972E-05 | global batch size:    32 | lm loss: 8.447748E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11600/  200000 | consumed samples:       371200 | elapsed time per iteration (ms): 265.0 | learning rate: 8.963E-05 | global batch size:    32 | lm loss: 8.218158E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11700/  200000 | consumed samples:       374400 | elapsed time per iteration (ms): 251.9 | learning rate: 8.954E-05 | global batch size:    32 | lm loss: 8.542181E-05 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    11800/  200000 | consumed samples:       377600 | elapsed time per iteration (ms): 252.5 | learning rate: 8.945E-05 | global batch size:    32 | lm loss: 8.541317E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11900/  200000 | consumed samples:       380800 | elapsed time per iteration (ms): 263.2 | learning rate: 8.936E-05 | global batch size:    32 | lm loss: 8.118355E-05 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12000/  200000 | consumed samples:       384000 | elapsed time per iteration (ms): 253.5 | learning rate: 8.927E-05 | global batch size:    32 | lm loss: 8.654658E-05 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12100/  200000 | consumed samples:       387200 | elapsed time per iteration (ms): 266.7 | learning rate: 8.918E-05 | global batch size:    32 | lm loss: 8.903409E-05 | loss scale: 33554432.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12200/  200000 | consumed samples:       390400 | elapsed time per iteration (ms): 253.7 | learning rate: 8.908E-05 | global batch size:    32 | lm loss: 8.642395E-05 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12300/  200000 | consumed samples:       393600 | elapsed time per iteration (ms): 254.8 | learning rate: 8.899E-05 | global batch size:    32 | lm loss: 8.255916E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12400/  200000 | consumed samples:       396800 | elapsed time per iteration (ms): 254.9 | learning rate: 8.890E-05 | global batch size:    32 | lm loss: 7.565868E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12500/  200000 | consumed samples:       400000 | elapsed time per iteration (ms): 254.1 | learning rate: 8.881E-05 | global batch size:    32 | lm loss: 8.689513E-05 | loss scale: 33554432.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12600/  200000 | consumed samples:       403200 | elapsed time per iteration (ms): 275.9 | learning rate: 8.872E-05 | global batch size:    32 | lm loss: 8.464648E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12700/  200000 | consumed samples:       406400 | elapsed time per iteration (ms): 254.1 | learning rate: 8.863E-05 | global batch size:    32 | lm loss: 7.828865E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12800/  200000 | consumed samples:       409600 | elapsed time per iteration (ms): 261.7 | learning rate: 8.854E-05 | global batch size:    32 | lm loss: 8.274710E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12900/  200000 | consumed samples:       412800 | elapsed time per iteration (ms): 257.5 | learning rate: 8.845E-05 | global batch size:    32 | lm loss: 7.419335E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13000/  200000 | consumed samples:       416000 | elapsed time per iteration (ms): 252.3 | learning rate: 8.836E-05 | global batch size:    32 | lm loss: 7.658334E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13100/  200000 | consumed samples:       419200 | elapsed time per iteration (ms): 266.5 | learning rate: 8.826E-05 | global batch size:    32 | lm loss: 7.449465E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13200/  200000 | consumed samples:       422400 | elapsed time per iteration (ms): 251.7 | learning rate: 8.817E-05 | global batch size:    32 | lm loss: 8.570069E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13300/  200000 | consumed samples:       425600 | elapsed time per iteration (ms): 254.6 | learning rate: 8.808E-05 | global batch size:    32 | lm loss: 7.562949E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13400/  200000 | consumed samples:       428800 | elapsed time per iteration (ms): 261.7 | learning rate: 8.799E-05 | global batch size:    32 | lm loss: 8.011111E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13500/  200000 | consumed samples:       432000 | elapsed time per iteration (ms): 253.6 | learning rate: 8.790E-05 | global batch size:    32 | lm loss: 7.830413E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13600/  200000 | consumed samples:       435200 | elapsed time per iteration (ms): 263.9 | learning rate: 8.781E-05 | global batch size:    32 | lm loss: 8.892001E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13700/  200000 | consumed samples:       438400 | elapsed time per iteration (ms): 254.7 | learning rate: 8.772E-05 | global batch size:    32 | lm loss: 7.455702E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13800/  200000 | consumed samples:       441600 | elapsed time per iteration (ms): 253.6 | learning rate: 8.763E-05 | global batch size:    32 | lm loss: 7.497571E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    13900/  200000 | consumed samples:       444800 | elapsed time per iteration (ms): 254.4 | learning rate: 8.754E-05 | global batch size:    32 | lm loss: 7.445254E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14000/  200000 | consumed samples:       448000 | elapsed time per iteration (ms): 254.4 | learning rate: 8.745E-05 | global batch size:    32 | lm loss: 6.997975E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14100/  200000 | consumed samples:       451200 | elapsed time per iteration (ms): 285.5 | learning rate: 8.736E-05 | global batch size:    32 | lm loss: 8.220960E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    14200/  200000 | consumed samples:       454400 | elapsed time per iteration (ms): 258.4 | learning rate: 8.726E-05 | global batch size:    32 | lm loss: 7.312521E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14300/  200000 | consumed samples:       457600 | elapsed time per iteration (ms): 259.3 | learning rate: 8.717E-05 | global batch size:    32 | lm loss: 7.279892E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14400/  200000 | consumed samples:       460800 | elapsed time per iteration (ms): 264.3 | learning rate: 8.708E-05 | global batch size:    32 | lm loss: 6.783302E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14500/  200000 | consumed samples:       464000 | elapsed time per iteration (ms): 259.8 | learning rate: 8.699E-05 | global batch size:    32 | lm loss: 7.111533E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14600/  200000 | consumed samples:       467200 | elapsed time per iteration (ms): 269.4 | learning rate: 8.690E-05 | global batch size:    32 | lm loss: 7.380549E-05 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14700/  200000 | consumed samples:       470400 | elapsed time per iteration (ms): 260.6 | learning rate: 8.681E-05 | global batch size:    32 | lm loss: 6.998019E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14800/  200000 | consumed samples:       473600 | elapsed time per iteration (ms): 267.0 | learning rate: 8.672E-05 | global batch size:    32 | lm loss: 6.076205E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14900/  200000 | consumed samples:       476800 | elapsed time per iteration (ms): 256.4 | learning rate: 8.663E-05 | global batch size:    32 | lm loss: 6.932076E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15000/  200000 | consumed samples:       480000 | elapsed time per iteration (ms): 257.4 | learning rate: 8.654E-05 | global batch size:    32 | lm loss: 6.495927E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15100/  200000 | consumed samples:       483200 | elapsed time per iteration (ms): 267.8 | learning rate: 8.644E-05 | global batch size:    32 | lm loss: 6.733441E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15200/  200000 | consumed samples:       486400 | elapsed time per iteration (ms): 258.9 | learning rate: 8.635E-05 | global batch size:    32 | lm loss: 7.175343E-05 | loss scale: 134217728.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15300/  200000 | consumed samples:       489600 | elapsed time per iteration (ms): 257.9 | learning rate: 8.626E-05 | global batch size:    32 | lm loss: 7.123641E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15400/  200000 | consumed samples:       492800 | elapsed time per iteration (ms): 254.0 | learning rate: 8.617E-05 | global batch size:    32 | lm loss: 6.294495E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    15500/  200000 | consumed samples:       496000 | elapsed time per iteration (ms): 257.9 | learning rate: 8.608E-05 | global batch size:    32 | lm loss: 6.720989E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15600/  200000 | consumed samples:       499200 | elapsed time per iteration (ms): 274.7 | learning rate: 8.599E-05 | global batch size:    32 | lm loss: 6.536708E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15700/  200000 | consumed samples:       502400 | elapsed time per iteration (ms): 256.2 | learning rate: 8.590E-05 | global batch size:    32 | lm loss: 7.285119E-05 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15800/  200000 | consumed samples:       505600 | elapsed time per iteration (ms): 258.1 | learning rate: 8.581E-05 | global batch size:    32 | lm loss: 8.534914E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    15900/  200000 | consumed samples:       508800 | elapsed time per iteration (ms): 255.5 | learning rate: 8.572E-05 | global batch size:    32 | lm loss: 6.654515E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16000/  200000 | consumed samples:       512000 | elapsed time per iteration (ms): 257.7 | learning rate: 8.563E-05 | global batch size:    32 | lm loss: 7.090880E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16100/  200000 | consumed samples:       515200 | elapsed time per iteration (ms): 275.4 | learning rate: 8.554E-05 | global batch size:    32 | lm loss: 6.398832E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16200/  200000 | consumed samples:       518400 | elapsed time per iteration (ms): 257.9 | learning rate: 8.544E-05 | global batch size:    32 | lm loss: 6.320606E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16300/  200000 | consumed samples:       521600 | elapsed time per iteration (ms): 267.4 | learning rate: 8.535E-05 | global batch size:    32 | lm loss: 6.068806E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16400/  200000 | consumed samples:       524800 | elapsed time per iteration (ms): 254.9 | learning rate: 8.526E-05 | global batch size:    32 | lm loss: 6.262591E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16500/  200000 | consumed samples:       528000 | elapsed time per iteration (ms): 253.2 | learning rate: 8.517E-05 | global batch size:    32 | lm loss: 6.421274E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16600/  200000 | consumed samples:       531200 | elapsed time per iteration (ms): 266.9 | learning rate: 8.508E-05 | global batch size:    32 | lm loss: 6.641977E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16700/  200000 | consumed samples:       534400 | elapsed time per iteration (ms): 253.9 | learning rate: 8.499E-05 | global batch size:    32 | lm loss: 6.077047E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16800/  200000 | consumed samples:       537600 | elapsed time per iteration (ms): 254.4 | learning rate: 8.490E-05 | global batch size:    32 | lm loss: 6.534823E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16900/  200000 | consumed samples:       540800 | elapsed time per iteration (ms): 257.8 | learning rate: 8.481E-05 | global batch size:    32 | lm loss: 6.468730E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17000/  200000 | consumed samples:       544000 | elapsed time per iteration (ms): 266.3 | learning rate: 8.472E-05 | global batch size:    32 | lm loss: 6.042966E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17100/  200000 | consumed samples:       547200 | elapsed time per iteration (ms): 275.4 | learning rate: 8.462E-05 | global batch size:    32 | lm loss: 6.240158E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17200/  200000 | consumed samples:       550400 | elapsed time per iteration (ms): 258.0 | learning rate: 8.453E-05 | global batch size:    32 | lm loss: 6.069713E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17300/  200000 | consumed samples:       553600 | elapsed time per iteration (ms): 255.6 | learning rate: 8.444E-05 | global batch size:    32 | lm loss: 6.962299E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17400/  200000 | consumed samples:       556800 | elapsed time per iteration (ms): 260.0 | learning rate: 8.435E-05 | global batch size:    32 | lm loss: 6.353446E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    17500/  200000 | consumed samples:       560000 | elapsed time per iteration (ms): 264.7 | learning rate: 8.426E-05 | global batch size:    32 | lm loss: 6.868062E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17600/  200000 | consumed samples:       563200 | elapsed time per iteration (ms): 282.2 | learning rate: 8.417E-05 | global batch size:    32 | lm loss: 5.739539E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17700/  200000 | consumed samples:       566400 | elapsed time per iteration (ms): 263.4 | learning rate: 8.408E-05 | global batch size:    32 | lm loss: 6.001322E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17800/  200000 | consumed samples:       569600 | elapsed time per iteration (ms): 269.9 | learning rate: 8.399E-05 | global batch size:    32 | lm loss: 6.305661E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17900/  200000 | consumed samples:       572800 | elapsed time per iteration (ms): 263.9 | learning rate: 8.390E-05 | global batch size:    32 | lm loss: 5.858616E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18000/  200000 | consumed samples:       576000 | elapsed time per iteration (ms): 259.7 | learning rate: 8.381E-05 | global batch size:    32 | lm loss: 5.964084E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18100/  200000 | consumed samples:       579200 | elapsed time per iteration (ms): 274.1 | learning rate: 8.372E-05 | global batch size:    32 | lm loss: 5.555817E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18200/  200000 | consumed samples:       582400 | elapsed time per iteration (ms): 259.7 | learning rate: 8.362E-05 | global batch size:    32 | lm loss: 5.595219E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18300/  200000 | consumed samples:       585600 | elapsed time per iteration (ms): 256.0 | learning rate: 8.353E-05 | global batch size:    32 | lm loss: 5.792126E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18400/  200000 | consumed samples:       588800 | elapsed time per iteration (ms): 261.2 | learning rate: 8.344E-05 | global batch size:    32 | lm loss: 5.598560E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18500/  200000 | consumed samples:       592000 | elapsed time per iteration (ms): 266.3 | learning rate: 8.335E-05 | global batch size:    32 | lm loss: 6.265325E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18600/  200000 | consumed samples:       595200 | elapsed time per iteration (ms): 269.5 | learning rate: 8.326E-05 | global batch size:    32 | lm loss: 7.057164E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18700/  200000 | consumed samples:       598400 | elapsed time per iteration (ms): 257.1 | learning rate: 8.317E-05 | global batch size:    32 | lm loss: 5.647944E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18800/  200000 | consumed samples:       601600 | elapsed time per iteration (ms): 253.1 | learning rate: 8.308E-05 | global batch size:    32 | lm loss: 6.182975E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    18900/  200000 | consumed samples:       604800 | elapsed time per iteration (ms): 255.6 | learning rate: 8.299E-05 | global batch size:    32 | lm loss: 6.514828E-05 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19000/  200000 | consumed samples:       608000 | elapsed time per iteration (ms): 255.2 | learning rate: 8.290E-05 | global batch size:    32 | lm loss: 6.185324E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19100/  200000 | consumed samples:       611200 | elapsed time per iteration (ms): 272.3 | learning rate: 8.281E-05 | global batch size:    32 | lm loss: 5.628190E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19200/  200000 | consumed samples:       614400 | elapsed time per iteration (ms): 267.8 | learning rate: 8.272E-05 | global batch size:    32 | lm loss: 5.515790E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19300/  200000 | consumed samples:       617600 | elapsed time per iteration (ms): 255.4 | learning rate: 8.262E-05 | global batch size:    32 | lm loss: 5.745310E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19400/  200000 | consumed samples:       620800 | elapsed time per iteration (ms): 256.8 | learning rate: 8.253E-05 | global batch size:    32 | lm loss: 6.439643E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19500/  200000 | consumed samples:       624000 | elapsed time per iteration (ms): 256.4 | learning rate: 8.244E-05 | global batch size:    32 | lm loss: 5.937604E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19600/  200000 | consumed samples:       627200 | elapsed time per iteration (ms): 267.9 | learning rate: 8.235E-05 | global batch size:    32 | lm loss: 5.497758E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19700/  200000 | consumed samples:       630400 | elapsed time per iteration (ms): 255.0 | learning rate: 8.226E-05 | global batch size:    32 | lm loss: 5.162123E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19800/  200000 | consumed samples:       633600 | elapsed time per iteration (ms): 255.6 | learning rate: 8.217E-05 | global batch size:    32 | lm loss: 5.308630E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19900/  200000 | consumed samples:       636800 | elapsed time per iteration (ms): 263.3 | learning rate: 8.208E-05 | global batch size:    32 | lm loss: 5.507422E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20000/  200000 | consumed samples:       640000 | elapsed time per iteration (ms): 265.9 | learning rate: 8.199E-05 | global batch size:    32 | lm loss: 5.129917E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20100/  200000 | consumed samples:       643200 | elapsed time per iteration (ms): 267.5 | learning rate: 8.190E-05 | global batch size:    32 | lm loss: 5.598148E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    20200/  200000 | consumed samples:       646400 | elapsed time per iteration (ms): 252.8 | learning rate: 8.181E-05 | global batch size:    32 | lm loss: 5.668776E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20300/  200000 | consumed samples:       649600 | elapsed time per iteration (ms): 255.1 | learning rate: 8.172E-05 | global batch size:    32 | lm loss: 6.006235E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20400/  200000 | consumed samples:       652800 | elapsed time per iteration (ms): 255.7 | learning rate: 8.162E-05 | global batch size:    32 | lm loss: 5.997133E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20500/  200000 | consumed samples:       656000 | elapsed time per iteration (ms): 255.8 | learning rate: 8.153E-05 | global batch size:    32 | lm loss: 5.806594E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20600/  200000 | consumed samples:       659200 | elapsed time per iteration (ms): 271.7 | learning rate: 8.144E-05 | global batch size:    32 | lm loss: 5.281864E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20700/  200000 | consumed samples:       662400 | elapsed time per iteration (ms): 266.8 | learning rate: 8.135E-05 | global batch size:    32 | lm loss: 5.304739E-05 | loss scale: 67108864.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20800/  200000 | consumed samples:       665600 | elapsed time per iteration (ms): 263.4 | learning rate: 8.126E-05 | global batch size:    32 | lm loss: 5.331791E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20900/  200000 | consumed samples:       668800 | elapsed time per iteration (ms): 259.4 | learning rate: 8.117E-05 | global batch size:    32 | lm loss: 5.156939E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21000/  200000 | consumed samples:       672000 | elapsed time per iteration (ms): 257.0 | learning rate: 8.108E-05 | global batch size:    32 | lm loss: 5.829480E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21100/  200000 | consumed samples:       675200 | elapsed time per iteration (ms): 271.3 | learning rate: 8.099E-05 | global batch size:    32 | lm loss: 5.339563E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21200/  200000 | consumed samples:       678400 | elapsed time per iteration (ms): 255.5 | learning rate: 8.090E-05 | global batch size:    32 | lm loss: 4.789048E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21300/  200000 | consumed samples:       681600 | elapsed time per iteration (ms): 254.0 | learning rate: 8.081E-05 | global batch size:    32 | lm loss: 5.455955E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    21400/  200000 | consumed samples:       684800 | elapsed time per iteration (ms): 267.3 | learning rate: 8.072E-05 | global batch size:    32 | lm loss: 4.961278E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21500/  200000 | consumed samples:       688000 | elapsed time per iteration (ms): 256.8 | learning rate: 8.062E-05 | global batch size:    32 | lm loss: 4.782526E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21600/  200000 | consumed samples:       691200 | elapsed time per iteration (ms): 269.2 | learning rate: 8.053E-05 | global batch size:    32 | lm loss: 4.710309E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21700/  200000 | consumed samples:       694400 | elapsed time per iteration (ms): 258.9 | learning rate: 8.044E-05 | global batch size:    32 | lm loss: 4.770754E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21800/  200000 | consumed samples:       697600 | elapsed time per iteration (ms): 255.3 | learning rate: 8.035E-05 | global batch size:    32 | lm loss: 5.159236E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21900/  200000 | consumed samples:       700800 | elapsed time per iteration (ms): 254.8 | learning rate: 8.026E-05 | global batch size:    32 | lm loss: 4.748707E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22000/  200000 | consumed samples:       704000 | elapsed time per iteration (ms): 254.9 | learning rate: 8.017E-05 | global batch size:    32 | lm loss: 4.974124E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22100/  200000 | consumed samples:       707200 | elapsed time per iteration (ms): 272.7 | learning rate: 8.008E-05 | global batch size:    32 | lm loss: 5.207122E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22200/  200000 | consumed samples:       710400 | elapsed time per iteration (ms): 262.9 | learning rate: 7.999E-05 | global batch size:    32 | lm loss: 6.116937E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22300/  200000 | consumed samples:       713600 | elapsed time per iteration (ms): 254.0 | learning rate: 7.990E-05 | global batch size:    32 | lm loss: 4.934849E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22400/  200000 | consumed samples:       716800 | elapsed time per iteration (ms): 257.0 | learning rate: 7.980E-05 | global batch size:    32 | lm loss: 4.686916E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22500/  200000 | consumed samples:       720000 | elapsed time per iteration (ms): 255.1 | learning rate: 7.971E-05 | global batch size:    32 | lm loss: 4.790605E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22600/  200000 | consumed samples:       723200 | elapsed time per iteration (ms): 268.4 | learning rate: 7.962E-05 | global batch size:    32 | lm loss: 5.382743E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    22700/  200000 | consumed samples:       726400 | elapsed time per iteration (ms): 253.6 | learning rate: 7.953E-05 | global batch size:    32 | lm loss: 4.843843E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22800/  200000 | consumed samples:       729600 | elapsed time per iteration (ms): 256.7 | learning rate: 7.944E-05 | global batch size:    32 | lm loss: 4.904001E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22900/  200000 | consumed samples:       732800 | elapsed time per iteration (ms): 264.4 | learning rate: 7.935E-05 | global batch size:    32 | lm loss: 5.213238E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23000/  200000 | consumed samples:       736000 | elapsed time per iteration (ms): 255.9 | learning rate: 7.926E-05 | global batch size:    32 | lm loss: 4.610702E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23100/  200000 | consumed samples:       739200 | elapsed time per iteration (ms): 265.7 | learning rate: 7.917E-05 | global batch size:    32 | lm loss: 4.489732E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23200/  200000 | consumed samples:       742400 | elapsed time per iteration (ms): 256.6 | learning rate: 7.908E-05 | global batch size:    32 | lm loss: 4.946021E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23300/  200000 | consumed samples:       745600 | elapsed time per iteration (ms): 254.2 | learning rate: 7.899E-05 | global batch size:    32 | lm loss: 4.831385E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23400/  200000 | consumed samples:       748800 | elapsed time per iteration (ms): 254.1 | learning rate: 7.890E-05 | global batch size:    32 | lm loss: 5.311719E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23500/  200000 | consumed samples:       752000 | elapsed time per iteration (ms): 251.8 | learning rate: 7.880E-05 | global batch size:    32 | lm loss: 4.951873E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23600/  200000 | consumed samples:       755200 | elapsed time per iteration (ms): 276.3 | learning rate: 7.871E-05 | global batch size:    32 | lm loss: 4.859340E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    23700/  200000 | consumed samples:       758400 | elapsed time per iteration (ms): 253.7 | learning rate: 7.862E-05 | global batch size:    32 | lm loss: 4.727597E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23800/  200000 | consumed samples:       761600 | elapsed time per iteration (ms): 253.7 | learning rate: 7.853E-05 | global batch size:    32 | lm loss: 4.252710E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23900/  200000 | consumed samples:       764800 | elapsed time per iteration (ms): 256.7 | learning rate: 7.844E-05 | global batch size:    32 | lm loss: 4.404779E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24000/  200000 | consumed samples:       768000 | elapsed time per iteration (ms): 256.2 | learning rate: 7.835E-05 | global batch size:    32 | lm loss: 4.412825E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24100/  200000 | consumed samples:       771200 | elapsed time per iteration (ms): 267.7 | learning rate: 7.826E-05 | global batch size:    32 | lm loss: 4.612754E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24200/  200000 | consumed samples:       774400 | elapsed time per iteration (ms): 254.8 | learning rate: 7.817E-05 | global batch size:    32 | lm loss: 5.519264E-05 | loss scale: 67108864.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24300/  200000 | consumed samples:       777600 | elapsed time per iteration (ms): 256.4 | learning rate: 7.808E-05 | global batch size:    32 | lm loss: 5.715200E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24400/  200000 | consumed samples:       780800 | elapsed time per iteration (ms): 262.7 | learning rate: 7.799E-05 | global batch size:    32 | lm loss: 4.634574E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24500/  200000 | consumed samples:       784000 | elapsed time per iteration (ms): 256.3 | learning rate: 7.789E-05 | global batch size:    32 | lm loss: 4.517197E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24600/  200000 | consumed samples:       787200 | elapsed time per iteration (ms): 273.3 | learning rate: 7.780E-05 | global batch size:    32 | lm loss: 4.418841E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24700/  200000 | consumed samples:       790400 | elapsed time per iteration (ms): 255.1 | learning rate: 7.771E-05 | global batch size:    32 | lm loss: 3.919413E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24800/  200000 | consumed samples:       793600 | elapsed time per iteration (ms): 256.1 | learning rate: 7.762E-05 | global batch size:    32 | lm loss: 4.069051E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24900/  200000 | consumed samples:       796800 | elapsed time per iteration (ms): 257.1 | learning rate: 7.753E-05 | global batch size:    32 | lm loss: 4.507159E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25000/  200000 | consumed samples:       800000 | elapsed time per iteration (ms): 257.6 | learning rate: 7.744E-05 | global batch size:    32 | lm loss: 4.180867E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25100/  200000 | consumed samples:       803200 | elapsed time per iteration (ms): 282.7 | learning rate: 7.735E-05 | global batch size:    32 | lm loss: 4.107833E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25200/  200000 | consumed samples:       806400 | elapsed time per iteration (ms): 255.0 | learning rate: 7.726E-05 | global batch size:    32 | lm loss: 4.152207E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25300/  200000 | consumed samples:       809600 | elapsed time per iteration (ms): 256.2 | learning rate: 7.717E-05 | global batch size:    32 | lm loss: 5.723707E-05 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    25400/  200000 | consumed samples:       812800 | elapsed time per iteration (ms): 265.0 | learning rate: 7.708E-05 | global batch size:    32 | lm loss: 4.302297E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25500/  200000 | consumed samples:       816000 | elapsed time per iteration (ms): 262.9 | learning rate: 7.699E-05 | global batch size:    32 | lm loss: 4.055590E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25600/  200000 | consumed samples:       819200 | elapsed time per iteration (ms): 265.5 | learning rate: 7.689E-05 | global batch size:    32 | lm loss: 4.538171E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25700/  200000 | consumed samples:       822400 | elapsed time per iteration (ms): 255.2 | learning rate: 7.680E-05 | global batch size:    32 | lm loss: 4.581844E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25800/  200000 | consumed samples:       825600 | elapsed time per iteration (ms): 266.5 | learning rate: 7.671E-05 | global batch size:    32 | lm loss: 4.526191E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25900/  200000 | consumed samples:       828800 | elapsed time per iteration (ms): 254.5 | learning rate: 7.662E-05 | global batch size:    32 | lm loss: 3.992010E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26000/  200000 | consumed samples:       832000 | elapsed time per iteration (ms): 256.0 | learning rate: 7.653E-05 | global batch size:    32 | lm loss: 4.226687E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26100/  200000 | consumed samples:       835200 | elapsed time per iteration (ms): 265.8 | learning rate: 7.644E-05 | global batch size:    32 | lm loss: 4.347528E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26200/  200000 | consumed samples:       838400 | elapsed time per iteration (ms): 254.9 | learning rate: 7.635E-05 | global batch size:    32 | lm loss: 4.269677E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26300/  200000 | consumed samples:       841600 | elapsed time per iteration (ms): 258.8 | learning rate: 7.626E-05 | global batch size:    32 | lm loss: 3.984977E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26400/  200000 | consumed samples:       844800 | elapsed time per iteration (ms): 256.9 | learning rate: 7.617E-05 | global batch size:    32 | lm loss: 4.266507E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26500/  200000 | consumed samples:       848000 | elapsed time per iteration (ms): 260.6 | learning rate: 7.608E-05 | global batch size:    32 | lm loss: 4.556951E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    26600/  200000 | consumed samples:       851200 | elapsed time per iteration (ms): 273.1 | learning rate: 7.599E-05 | global batch size:    32 | lm loss: 4.573400E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26700/  200000 | consumed samples:       854400 | elapsed time per iteration (ms): 255.3 | learning rate: 7.589E-05 | global batch size:    32 | lm loss: 4.167315E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26800/  200000 | consumed samples:       857600 | elapsed time per iteration (ms): 253.2 | learning rate: 7.580E-05 | global batch size:    32 | lm loss: 4.136033E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26900/  200000 | consumed samples:       860800 | elapsed time per iteration (ms): 253.7 | learning rate: 7.571E-05 | global batch size:    32 | lm loss: 3.920047E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27000/  200000 | consumed samples:       864000 | elapsed time per iteration (ms): 267.1 | learning rate: 7.562E-05 | global batch size:    32 | lm loss: 4.410219E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27100/  200000 | consumed samples:       867200 | elapsed time per iteration (ms): 266.0 | learning rate: 7.553E-05 | global batch size:    32 | lm loss: 4.201565E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27200/  200000 | consumed samples:       870400 | elapsed time per iteration (ms): 253.9 | learning rate: 7.544E-05 | global batch size:    32 | lm loss: 4.066287E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27300/  200000 | consumed samples:       873600 | elapsed time per iteration (ms): 271.4 | learning rate: 7.535E-05 | global batch size:    32 | lm loss: 3.884232E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27400/  200000 | consumed samples:       876800 | elapsed time per iteration (ms): 257.6 | learning rate: 7.526E-05 | global batch size:    32 | lm loss: 4.126361E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27500/  200000 | consumed samples:       880000 | elapsed time per iteration (ms): 260.7 | learning rate: 7.517E-05 | global batch size:    32 | lm loss: 4.057938E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27600/  200000 | consumed samples:       883200 | elapsed time per iteration (ms): 266.7 | learning rate: 7.507E-05 | global batch size:    32 | lm loss: 4.112982E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27700/  200000 | consumed samples:       886400 | elapsed time per iteration (ms): 257.1 | learning rate: 7.498E-05 | global batch size:    32 | lm loss: 4.318501E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27800/  200000 | consumed samples:       889600 | elapsed time per iteration (ms): 258.9 | learning rate: 7.489E-05 | global batch size:    32 | lm loss: 4.028536E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27900/  200000 | consumed samples:       892800 | elapsed time per iteration (ms): 256.0 | learning rate: 7.480E-05 | global batch size:    32 | lm loss: 3.803995E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28000/  200000 | consumed samples:       896000 | elapsed time per iteration (ms): 265.4 | learning rate: 7.471E-05 | global batch size:    32 | lm loss: 4.132549E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28100/  200000 | consumed samples:       899200 | elapsed time per iteration (ms): 274.9 | learning rate: 7.462E-05 | global batch size:    32 | lm loss: 3.890705E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28200/  200000 | consumed samples:       902400 | elapsed time per iteration (ms): 253.4 | learning rate: 7.453E-05 | global batch size:    32 | lm loss: 3.814301E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28300/  200000 | consumed samples:       905600 | elapsed time per iteration (ms): 254.0 | learning rate: 7.444E-05 | global batch size:    32 | lm loss: 3.452283E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28400/  200000 | consumed samples:       908800 | elapsed time per iteration (ms): 256.7 | learning rate: 7.435E-05 | global batch size:    32 | lm loss: 3.573254E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28500/  200000 | consumed samples:       912000 | elapsed time per iteration (ms): 252.2 | learning rate: 7.426E-05 | global batch size:    32 | lm loss: 3.800385E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    28600/  200000 | consumed samples:       915200 | elapsed time per iteration (ms): 275.0 | learning rate: 7.417E-05 | global batch size:    32 | lm loss: 3.717318E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28700/  200000 | consumed samples:       918400 | elapsed time per iteration (ms): 267.3 | learning rate: 7.407E-05 | global batch size:    32 | lm loss: 3.956180E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28800/  200000 | consumed samples:       921600 | elapsed time per iteration (ms): 257.3 | learning rate: 7.398E-05 | global batch size:    32 | lm loss: 3.853486E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    28900/  200000 | consumed samples:       924800 | elapsed time per iteration (ms): 255.7 | learning rate: 7.389E-05 | global batch size:    32 | lm loss: 4.087412E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29000/  200000 | consumed samples:       928000 | elapsed time per iteration (ms): 253.5 | learning rate: 7.380E-05 | global batch size:    32 | lm loss: 3.724194E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29100/  200000 | consumed samples:       931200 | elapsed time per iteration (ms): 265.7 | learning rate: 7.371E-05 | global batch size:    32 | lm loss: 3.893455E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29200/  200000 | consumed samples:       934400 | elapsed time per iteration (ms): 255.7 | learning rate: 7.362E-05 | global batch size:    32 | lm loss: 3.572672E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29300/  200000 | consumed samples:       937600 | elapsed time per iteration (ms): 253.9 | learning rate: 7.353E-05 | global batch size:    32 | lm loss: 3.573279E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29400/  200000 | consumed samples:       940800 | elapsed time per iteration (ms): 255.5 | learning rate: 7.344E-05 | global batch size:    32 | lm loss: 4.214080E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29500/  200000 | consumed samples:       944000 | elapsed time per iteration (ms): 264.7 | learning rate: 7.335E-05 | global batch size:    32 | lm loss: 3.722520E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29600/  200000 | consumed samples:       947200 | elapsed time per iteration (ms): 271.4 | learning rate: 7.326E-05 | global batch size:    32 | lm loss: 3.462962E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29700/  200000 | consumed samples:       950400 | elapsed time per iteration (ms): 252.3 | learning rate: 7.316E-05 | global batch size:    32 | lm loss: 3.551946E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29800/  200000 | consumed samples:       953600 | elapsed time per iteration (ms): 254.9 | learning rate: 7.307E-05 | global batch size:    32 | lm loss: 3.940863E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29900/  200000 | consumed samples:       956800 | elapsed time per iteration (ms): 252.4 | learning rate: 7.298E-05 | global batch size:    32 | lm loss: 3.847142E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30000/  200000 | consumed samples:       960000 | elapsed time per iteration (ms): 254.8 | learning rate: 7.289E-05 | global batch size:    32 | lm loss: 3.643310E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30100/  200000 | consumed samples:       963200 | elapsed time per iteration (ms): 264.9 | learning rate: 7.280E-05 | global batch size:    32 | lm loss: 3.834319E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30200/  200000 | consumed samples:       966400 | elapsed time per iteration (ms): 262.4 | learning rate: 7.271E-05 | global batch size:    32 | lm loss: 4.030302E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    30300/  200000 | consumed samples:       969600 | elapsed time per iteration (ms): 254.4 | learning rate: 7.262E-05 | global batch size:    32 | lm loss: 3.440072E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30400/  200000 | consumed samples:       972800 | elapsed time per iteration (ms): 253.3 | learning rate: 7.253E-05 | global batch size:    32 | lm loss: 3.595054E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30500/  200000 | consumed samples:       976000 | elapsed time per iteration (ms): 255.0 | learning rate: 7.244E-05 | global batch size:    32 | lm loss: 4.148982E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30600/  200000 | consumed samples:       979200 | elapsed time per iteration (ms): 268.1 | learning rate: 7.235E-05 | global batch size:    32 | lm loss: 3.646320E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
