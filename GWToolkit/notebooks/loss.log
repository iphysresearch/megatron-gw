 iteration      100/  200000 | consumed samples:         3200 | elapsed time per iteration (ms): 303.6 | learning rate: 4.444E-05 | global batch size:    32 | lm loss: 9.706122E-02 | loss scale: 2097152.0 | grad norm: 0.024 | number of skipped iterations:  12 | number of nan iterations:   0 |
 iteration      200/  200000 | consumed samples:         6400 | elapsed time per iteration (ms): 264.3 | learning rate: 9.495E-05 | global batch size:    32 | lm loss: 2.122366E-03 | loss scale: 2097152.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/  200000 | consumed samples:         9600 | elapsed time per iteration (ms): 261.4 | learning rate: 9.992E-05 | global batch size:    32 | lm loss: 1.275565E-03 | loss scale: 2097152.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/  200000 | consumed samples:        12800 | elapsed time per iteration (ms): 262.2 | learning rate: 9.983E-05 | global batch size:    32 | lm loss: 1.008312E-03 | loss scale: 2097152.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/  200000 | consumed samples:        16000 | elapsed time per iteration (ms): 259.3 | learning rate: 9.974E-05 | global batch size:    32 | lm loss: 9.232771E-04 | loss scale: 2097152.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/  200000 | consumed samples:        19200 | elapsed time per iteration (ms): 266.6 | learning rate: 9.964E-05 | global batch size:    32 | lm loss: 6.531002E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/  200000 | consumed samples:        22400 | elapsed time per iteration (ms): 253.1 | learning rate: 9.955E-05 | global batch size:    32 | lm loss: 6.531756E-04 | loss scale: 2097152.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/  200000 | consumed samples:        25600 | elapsed time per iteration (ms): 253.3 | learning rate: 9.946E-05 | global batch size:    32 | lm loss: 6.483161E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/  200000 | consumed samples:        28800 | elapsed time per iteration (ms): 256.7 | learning rate: 9.937E-05 | global batch size:    32 | lm loss: 6.528109E-04 | loss scale: 2097152.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/  200000 | consumed samples:        32000 | elapsed time per iteration (ms): 254.2 | learning rate: 9.928E-05 | global batch size:    32 | lm loss: 6.433538E-04 | loss scale: 2097152.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1100/  200000 | consumed samples:        35200 | elapsed time per iteration (ms): 266.7 | learning rate: 9.919E-05 | global batch size:    32 | lm loss: 6.440675E-04 | loss scale: 4194304.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1200/  200000 | consumed samples:        38400 | elapsed time per iteration (ms): 254.1 | learning rate: 9.910E-05 | global batch size:    32 | lm loss: 6.573156E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1300/  200000 | consumed samples:        41600 | elapsed time per iteration (ms): 254.4 | learning rate: 9.901E-05 | global batch size:    32 | lm loss: 6.447437E-04 | loss scale: 4194304.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1400/  200000 | consumed samples:        44800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.892E-05 | global batch size:    32 | lm loss: 6.527977E-04 | loss scale: 4194304.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1500/  200000 | consumed samples:        48000 | elapsed time per iteration (ms): 254.7 | learning rate: 9.882E-05 | global batch size:    32 | lm loss: 6.486205E-04 | loss scale: 4194304.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1600/  200000 | consumed samples:        51200 | elapsed time per iteration (ms): 264.6 | learning rate: 9.873E-05 | global batch size:    32 | lm loss: 6.633323E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1700/  200000 | consumed samples:        54400 | elapsed time per iteration (ms): 258.4 | learning rate: 9.864E-05 | global batch size:    32 | lm loss: 6.533711E-04 | loss scale: 4194304.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1800/  200000 | consumed samples:        57600 | elapsed time per iteration (ms): 253.8 | learning rate: 9.855E-05 | global batch size:    32 | lm loss: 6.604908E-04 | loss scale: 4194304.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1900/  200000 | consumed samples:        60800 | elapsed time per iteration (ms): 259.0 | learning rate: 9.846E-05 | global batch size:    32 | lm loss: 6.657952E-04 | loss scale: 4194304.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2000/  200000 | consumed samples:        64000 | elapsed time per iteration (ms): 260.7 | learning rate: 9.837E-05 | global batch size:    32 | lm loss: 6.632921E-04 | loss scale: 4194304.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2100/  200000 | consumed samples:        67200 | elapsed time per iteration (ms): 274.5 | learning rate: 9.828E-05 | global batch size:    32 | lm loss: 6.739845E-04 | loss scale: 8388608.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2200/  200000 | consumed samples:        70400 | elapsed time per iteration (ms): 258.3 | learning rate: 9.819E-05 | global batch size:    32 | lm loss: 6.662659E-04 | loss scale: 8388608.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2300/  200000 | consumed samples:        73600 | elapsed time per iteration (ms): 257.1 | learning rate: 9.810E-05 | global batch size:    32 | lm loss: 6.718781E-04 | loss scale: 8388608.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2400/  200000 | consumed samples:        76800 | elapsed time per iteration (ms): 259.0 | learning rate: 9.801E-05 | global batch size:    32 | lm loss: 6.627337E-04 | loss scale: 8388608.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2500/  200000 | consumed samples:        80000 | elapsed time per iteration (ms): 256.1 | learning rate: 9.791E-05 | global batch size:    32 | lm loss: 6.646355E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2600/  200000 | consumed samples:        83200 | elapsed time per iteration (ms): 269.5 | learning rate: 9.782E-05 | global batch size:    32 | lm loss: 6.516803E-04 | loss scale: 8388608.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2700/  200000 | consumed samples:        86400 | elapsed time per iteration (ms): 261.2 | learning rate: 9.773E-05 | global batch size:    32 | lm loss: 6.710421E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2800/  200000 | consumed samples:        89600 | elapsed time per iteration (ms): 255.9 | learning rate: 9.764E-05 | global batch size:    32 | lm loss: 6.740583E-04 | loss scale: 8388608.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2900/  200000 | consumed samples:        92800 | elapsed time per iteration (ms): 257.4 | learning rate: 9.755E-05 | global batch size:    32 | lm loss: 6.590704E-04 | loss scale: 8388608.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3000/  200000 | consumed samples:        96000 | elapsed time per iteration (ms): 257.4 | learning rate: 9.746E-05 | global batch size:    32 | lm loss: 6.700991E-04 | loss scale: 8388608.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3100/  200000 | consumed samples:        99200 | elapsed time per iteration (ms): 274.1 | learning rate: 9.737E-05 | global batch size:    32 | lm loss: 6.570277E-04 | loss scale: 16777216.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3200/  200000 | consumed samples:       102400 | elapsed time per iteration (ms): 257.9 | learning rate: 9.728E-05 | global batch size:    32 | lm loss: 6.794741E-04 | loss scale: 16777216.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3300/  200000 | consumed samples:       105600 | elapsed time per iteration (ms): 259.1 | learning rate: 9.719E-05 | global batch size:    32 | lm loss: 6.458659E-04 | loss scale: 16777216.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3400/  200000 | consumed samples:       108800 | elapsed time per iteration (ms): 257.4 | learning rate: 9.709E-05 | global batch size:    32 | lm loss: 6.754433E-04 | loss scale: 16777216.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3500/  200000 | consumed samples:       112000 | elapsed time per iteration (ms): 257.8 | learning rate: 9.700E-05 | global batch size:    32 | lm loss: 6.659480E-04 | loss scale: 16777216.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3600/  200000 | consumed samples:       115200 | elapsed time per iteration (ms): 273.4 | learning rate: 9.691E-05 | global batch size:    32 | lm loss: 6.666736E-04 | loss scale: 16777216.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3700/  200000 | consumed samples:       118400 | elapsed time per iteration (ms): 256.9 | learning rate: 9.682E-05 | global batch size:    32 | lm loss: 6.585941E-04 | loss scale: 16777216.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3800/  200000 | consumed samples:       121600 | elapsed time per iteration (ms): 263.0 | learning rate: 9.673E-05 | global batch size:    32 | lm loss: 6.816215E-04 | loss scale: 16777216.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3900/  200000 | consumed samples:       124800 | elapsed time per iteration (ms): 257.3 | learning rate: 9.664E-05 | global batch size:    32 | lm loss: 6.839024E-04 | loss scale: 16777216.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4000/  200000 | consumed samples:       128000 | elapsed time per iteration (ms): 252.9 | learning rate: 9.655E-05 | global batch size:    32 | lm loss: 6.417631E-04 | loss scale: 16777216.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4100/  200000 | consumed samples:       131200 | elapsed time per iteration (ms): 270.4 | learning rate: 9.646E-05 | global batch size:    32 | lm loss: 6.542465E-04 | loss scale: 33554432.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4200/  200000 | consumed samples:       134400 | elapsed time per iteration (ms): 254.7 | learning rate: 9.637E-05 | global batch size:    32 | lm loss: 6.580620E-04 | loss scale: 33554432.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4300/  200000 | consumed samples:       137600 | elapsed time per iteration (ms): 252.8 | learning rate: 9.627E-05 | global batch size:    32 | lm loss: 6.576505E-04 | loss scale: 33554432.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4400/  200000 | consumed samples:       140800 | elapsed time per iteration (ms): 255.6 | learning rate: 9.618E-05 | global batch size:    32 | lm loss: 6.230443E-04 | loss scale: 33554432.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4500/  200000 | consumed samples:       144000 | elapsed time per iteration (ms): 262.4 | learning rate: 9.609E-05 | global batch size:    32 | lm loss: 9.362479E-04 | loss scale: 33554432.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4600/  200000 | consumed samples:       147200 | elapsed time per iteration (ms): 270.3 | learning rate: 9.600E-05 | global batch size:    32 | lm loss: 6.850941E-04 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4700/  200000 | consumed samples:       150400 | elapsed time per iteration (ms): 255.9 | learning rate: 9.591E-05 | global batch size:    32 | lm loss: 6.668676E-04 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4800/  200000 | consumed samples:       153600 | elapsed time per iteration (ms): 255.6 | learning rate: 9.582E-05 | global batch size:    32 | lm loss: 6.672812E-04 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4900/  200000 | consumed samples:       156800 | elapsed time per iteration (ms): 256.3 | learning rate: 9.573E-05 | global batch size:    32 | lm loss: 6.636014E-04 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5000/  200000 | consumed samples:       160000 | elapsed time per iteration (ms): 254.9 | learning rate: 9.564E-05 | global batch size:    32 | lm loss: 6.549595E-04 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5100/  200000 | consumed samples:       163200 | elapsed time per iteration (ms): 267.2 | learning rate: 9.555E-05 | global batch size:    32 | lm loss: 6.576794E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5200/  200000 | consumed samples:       166400 | elapsed time per iteration (ms): 249.3 | learning rate: 9.545E-05 | global batch size:    32 | lm loss: 6.704904E-04 | loss scale: 67108864.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5300/  200000 | consumed samples:       169600 | elapsed time per iteration (ms): 258.4 | learning rate: 9.536E-05 | global batch size:    32 | lm loss: 6.583305E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5400/  200000 | consumed samples:       172800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.527E-05 | global batch size:    32 | lm loss: 6.717139E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5500/  200000 | consumed samples:       176000 | elapsed time per iteration (ms): 254.6 | learning rate: 9.518E-05 | global batch size:    32 | lm loss: 7.205898E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5600/  200000 | consumed samples:       179200 | elapsed time per iteration (ms): 265.7 | learning rate: 9.509E-05 | global batch size:    32 | lm loss: 6.694280E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5700/  200000 | consumed samples:       182400 | elapsed time per iteration (ms): 257.8 | learning rate: 9.500E-05 | global batch size:    32 | lm loss: 6.564434E-04 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5800/  200000 | consumed samples:       185600 | elapsed time per iteration (ms): 255.1 | learning rate: 9.491E-05 | global batch size:    32 | lm loss: 6.675154E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5900/  200000 | consumed samples:       188800 | elapsed time per iteration (ms): 253.7 | learning rate: 9.482E-05 | global batch size:    32 | lm loss: 6.914335E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6000/  200000 | consumed samples:       192000 | elapsed time per iteration (ms): 251.8 | learning rate: 9.473E-05 | global batch size:    32 | lm loss: 6.628920E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6100/  200000 | consumed samples:       195200 | elapsed time per iteration (ms): 271.0 | learning rate: 9.463E-05 | global batch size:    32 | lm loss: 6.649253E-04 | loss scale: 134217728.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6200/  200000 | consumed samples:       198400 | elapsed time per iteration (ms): 256.0 | learning rate: 9.454E-05 | global batch size:    32 | lm loss: 6.666468E-04 | loss scale: 134217728.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6300/  200000 | consumed samples:       201600 | elapsed time per iteration (ms): 259.7 | learning rate: 9.445E-05 | global batch size:    32 | lm loss: 6.685780E-04 | loss scale: 134217728.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6400/  200000 | consumed samples:       204800 | elapsed time per iteration (ms): 254.1 | learning rate: 9.436E-05 | global batch size:    32 | lm loss: 6.554129E-04 | loss scale: 134217728.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6500/  200000 | consumed samples:       208000 | elapsed time per iteration (ms): 249.3 | learning rate: 9.427E-05 | global batch size:    32 | lm loss: 6.379052E-04 | loss scale: 67108864.0 | grad norm: 0.021 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration     6600/  200000 | consumed samples:       211200 | elapsed time per iteration (ms): 266.5 | learning rate: 9.418E-05 | global batch size:    32 | lm loss: 6.199125E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6700/  200000 | consumed samples:       214400 | elapsed time per iteration (ms): 253.1 | learning rate: 9.409E-05 | global batch size:    32 | lm loss: 6.038041E-04 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6800/  200000 | consumed samples:       217600 | elapsed time per iteration (ms): 264.5 | learning rate: 9.400E-05 | global batch size:    32 | lm loss: 6.062541E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6900/  200000 | consumed samples:       220800 | elapsed time per iteration (ms): 251.5 | learning rate: 9.391E-05 | global batch size:    32 | lm loss: 6.083208E-04 | loss scale: 67108864.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7000/  200000 | consumed samples:       224000 | elapsed time per iteration (ms): 255.6 | learning rate: 9.382E-05 | global batch size:    32 | lm loss: 5.684185E-04 | loss scale: 67108864.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7100/  200000 | consumed samples:       227200 | elapsed time per iteration (ms): 270.0 | learning rate: 9.373E-05 | global batch size:    32 | lm loss: 5.564332E-04 | loss scale: 67108864.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7200/  200000 | consumed samples:       230400 | elapsed time per iteration (ms): 253.8 | learning rate: 9.363E-05 | global batch size:    32 | lm loss: 5.029616E-04 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7300/  200000 | consumed samples:       233600 | elapsed time per iteration (ms): 253.9 | learning rate: 9.354E-05 | global batch size:    32 | lm loss: 4.911084E-04 | loss scale: 67108864.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7400/  200000 | consumed samples:       236800 | elapsed time per iteration (ms): 253.3 | learning rate: 9.345E-05 | global batch size:    32 | lm loss: 3.637996E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7500/  200000 | consumed samples:       240000 | elapsed time per iteration (ms): 263.7 | learning rate: 9.336E-05 | global batch size:    32 | lm loss: 3.247115E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7600/  200000 | consumed samples:       243200 | elapsed time per iteration (ms): 271.8 | learning rate: 9.327E-05 | global batch size:    32 | lm loss: 2.859428E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7700/  200000 | consumed samples:       246400 | elapsed time per iteration (ms): 259.5 | learning rate: 9.318E-05 | global batch size:    32 | lm loss: 2.435664E-04 | loss scale: 134217728.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7800/  200000 | consumed samples:       249600 | elapsed time per iteration (ms): 254.3 | learning rate: 9.309E-05 | global batch size:    32 | lm loss: 2.313434E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7900/  200000 | consumed samples:       252800 | elapsed time per iteration (ms): 255.8 | learning rate: 9.300E-05 | global batch size:    32 | lm loss: 2.083290E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8000/  200000 | consumed samples:       256000 | elapsed time per iteration (ms): 255.0 | learning rate: 9.291E-05 | global batch size:    32 | lm loss: 1.941747E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8100/  200000 | consumed samples:       259200 | elapsed time per iteration (ms): 269.8 | learning rate: 9.281E-05 | global batch size:    32 | lm loss: 1.974218E-04 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8200/  200000 | consumed samples:       262400 | elapsed time per iteration (ms): 257.0 | learning rate: 9.272E-05 | global batch size:    32 | lm loss: 1.809771E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     8300/  200000 | consumed samples:       265600 | elapsed time per iteration (ms): 256.4 | learning rate: 9.263E-05 | global batch size:    32 | lm loss: 1.720501E-04 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     8400/  200000 | consumed samples:       268800 | elapsed time per iteration (ms): 253.6 | learning rate: 9.254E-05 | global batch size:    32 | lm loss: 1.522172E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8500/  200000 | consumed samples:       272000 | elapsed time per iteration (ms): 254.7 | learning rate: 9.245E-05 | global batch size:    32 | lm loss: 1.474098E-04 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8600/  200000 | consumed samples:       275200 | elapsed time per iteration (ms): 264.1 | learning rate: 9.236E-05 | global batch size:    32 | lm loss: 1.429363E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8700/  200000 | consumed samples:       278400 | elapsed time per iteration (ms): 258.0 | learning rate: 9.227E-05 | global batch size:    32 | lm loss: 1.324781E-04 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8800/  200000 | consumed samples:       281600 | elapsed time per iteration (ms): 264.2 | learning rate: 9.218E-05 | global batch size:    32 | lm loss: 1.364638E-04 | loss scale: 67108864.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8900/  200000 | consumed samples:       284800 | elapsed time per iteration (ms): 255.7 | learning rate: 9.209E-05 | global batch size:    32 | lm loss: 1.339422E-04 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9000/  200000 | consumed samples:       288000 | elapsed time per iteration (ms): 260.8 | learning rate: 9.200E-05 | global batch size:    32 | lm loss: 1.307620E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9100/  200000 | consumed samples:       291200 | elapsed time per iteration (ms): 265.4 | learning rate: 9.191E-05 | global batch size:    32 | lm loss: 1.301183E-04 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9200/  200000 | consumed samples:       294400 | elapsed time per iteration (ms): 256.1 | learning rate: 9.181E-05 | global batch size:    32 | lm loss: 1.142497E-04 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9300/  200000 | consumed samples:       297600 | elapsed time per iteration (ms): 253.7 | learning rate: 9.172E-05 | global batch size:    32 | lm loss: 1.120337E-04 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9400/  200000 | consumed samples:       300800 | elapsed time per iteration (ms): 254.2 | learning rate: 9.163E-05 | global batch size:    32 | lm loss: 1.204555E-04 | loss scale: 134217728.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9500/  200000 | consumed samples:       304000 | elapsed time per iteration (ms): 254.0 | learning rate: 9.154E-05 | global batch size:    32 | lm loss: 1.187519E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9600/  200000 | consumed samples:       307200 | elapsed time per iteration (ms): 266.7 | learning rate: 9.145E-05 | global batch size:    32 | lm loss: 1.095530E-04 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9700/  200000 | consumed samples:       310400 | elapsed time per iteration (ms): 253.7 | learning rate: 9.136E-05 | global batch size:    32 | lm loss: 1.011459E-04 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9800/  200000 | consumed samples:       313600 | elapsed time per iteration (ms): 250.4 | learning rate: 9.127E-05 | global batch size:    32 | lm loss: 1.049916E-04 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     9900/  200000 | consumed samples:       316800 | elapsed time per iteration (ms): 252.2 | learning rate: 9.118E-05 | global batch size:    32 | lm loss: 1.144618E-04 | loss scale: 134217728.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10000/  200000 | consumed samples:       320000 | elapsed time per iteration (ms): 252.4 | learning rate: 9.109E-05 | global batch size:    32 | lm loss: 1.202325E-04 | loss scale: 134217728.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10100/  200000 | consumed samples:       323200 | elapsed time per iteration (ms): 265.2 | learning rate: 9.100E-05 | global batch size:    32 | lm loss: 9.871851E-05 | loss scale: 134217728.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10200/  200000 | consumed samples:       326400 | elapsed time per iteration (ms): 259.5 | learning rate: 9.090E-05 | global batch size:    32 | lm loss: 1.041510E-04 | loss scale: 134217728.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10300/  200000 | consumed samples:       329600 | elapsed time per iteration (ms): 255.1 | learning rate: 9.081E-05 | global batch size:    32 | lm loss: 1.134543E-04 | loss scale: 134217728.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10400/  200000 | consumed samples:       332800 | elapsed time per iteration (ms): 260.4 | learning rate: 9.072E-05 | global batch size:    32 | lm loss: 9.927821E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10500/  200000 | consumed samples:       336000 | elapsed time per iteration (ms): 251.9 | learning rate: 9.063E-05 | global batch size:    32 | lm loss: 9.240475E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10600/  200000 | consumed samples:       339200 | elapsed time per iteration (ms): 274.2 | learning rate: 9.054E-05 | global batch size:    32 | lm loss: 9.571443E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10700/  200000 | consumed samples:       342400 | elapsed time per iteration (ms): 257.5 | learning rate: 9.045E-05 | global batch size:    32 | lm loss: 9.286555E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10800/  200000 | consumed samples:       345600 | elapsed time per iteration (ms): 252.9 | learning rate: 9.036E-05 | global batch size:    32 | lm loss: 1.056184E-04 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    10900/  200000 | consumed samples:       348800 | elapsed time per iteration (ms): 253.2 | learning rate: 9.027E-05 | global batch size:    32 | lm loss: 8.993842E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11000/  200000 | consumed samples:       352000 | elapsed time per iteration (ms): 255.1 | learning rate: 9.018E-05 | global batch size:    32 | lm loss: 9.151815E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11100/  200000 | consumed samples:       355200 | elapsed time per iteration (ms): 270.2 | learning rate: 9.009E-05 | global batch size:    32 | lm loss: 8.987840E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11200/  200000 | consumed samples:       358400 | elapsed time per iteration (ms): 261.9 | learning rate: 8.999E-05 | global batch size:    32 | lm loss: 1.034726E-04 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11300/  200000 | consumed samples:       361600 | elapsed time per iteration (ms): 254.9 | learning rate: 8.990E-05 | global batch size:    32 | lm loss: 9.026983E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11400/  200000 | consumed samples:       364800 | elapsed time per iteration (ms): 254.1 | learning rate: 8.981E-05 | global batch size:    32 | lm loss: 8.876670E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11500/  200000 | consumed samples:       368000 | elapsed time per iteration (ms): 253.7 | learning rate: 8.972E-05 | global batch size:    32 | lm loss: 8.447748E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11600/  200000 | consumed samples:       371200 | elapsed time per iteration (ms): 265.0 | learning rate: 8.963E-05 | global batch size:    32 | lm loss: 8.218158E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11700/  200000 | consumed samples:       374400 | elapsed time per iteration (ms): 251.9 | learning rate: 8.954E-05 | global batch size:    32 | lm loss: 8.542181E-05 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    11800/  200000 | consumed samples:       377600 | elapsed time per iteration (ms): 252.5 | learning rate: 8.945E-05 | global batch size:    32 | lm loss: 8.541317E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11900/  200000 | consumed samples:       380800 | elapsed time per iteration (ms): 263.2 | learning rate: 8.936E-05 | global batch size:    32 | lm loss: 8.118355E-05 | loss scale: 33554432.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12000/  200000 | consumed samples:       384000 | elapsed time per iteration (ms): 253.5 | learning rate: 8.927E-05 | global batch size:    32 | lm loss: 8.654658E-05 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12100/  200000 | consumed samples:       387200 | elapsed time per iteration (ms): 266.7 | learning rate: 8.918E-05 | global batch size:    32 | lm loss: 8.903409E-05 | loss scale: 33554432.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12200/  200000 | consumed samples:       390400 | elapsed time per iteration (ms): 253.7 | learning rate: 8.908E-05 | global batch size:    32 | lm loss: 8.642395E-05 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12300/  200000 | consumed samples:       393600 | elapsed time per iteration (ms): 254.8 | learning rate: 8.899E-05 | global batch size:    32 | lm loss: 8.255916E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12400/  200000 | consumed samples:       396800 | elapsed time per iteration (ms): 254.9 | learning rate: 8.890E-05 | global batch size:    32 | lm loss: 7.565868E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12500/  200000 | consumed samples:       400000 | elapsed time per iteration (ms): 254.1 | learning rate: 8.881E-05 | global batch size:    32 | lm loss: 8.689513E-05 | loss scale: 33554432.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12600/  200000 | consumed samples:       403200 | elapsed time per iteration (ms): 275.9 | learning rate: 8.872E-05 | global batch size:    32 | lm loss: 8.464648E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12700/  200000 | consumed samples:       406400 | elapsed time per iteration (ms): 254.1 | learning rate: 8.863E-05 | global batch size:    32 | lm loss: 7.828865E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12800/  200000 | consumed samples:       409600 | elapsed time per iteration (ms): 261.7 | learning rate: 8.854E-05 | global batch size:    32 | lm loss: 8.274710E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12900/  200000 | consumed samples:       412800 | elapsed time per iteration (ms): 257.5 | learning rate: 8.845E-05 | global batch size:    32 | lm loss: 7.419335E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13000/  200000 | consumed samples:       416000 | elapsed time per iteration (ms): 252.3 | learning rate: 8.836E-05 | global batch size:    32 | lm loss: 7.658334E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13100/  200000 | consumed samples:       419200 | elapsed time per iteration (ms): 266.5 | learning rate: 8.826E-05 | global batch size:    32 | lm loss: 7.449465E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13200/  200000 | consumed samples:       422400 | elapsed time per iteration (ms): 251.7 | learning rate: 8.817E-05 | global batch size:    32 | lm loss: 8.570069E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13300/  200000 | consumed samples:       425600 | elapsed time per iteration (ms): 254.6 | learning rate: 8.808E-05 | global batch size:    32 | lm loss: 7.562949E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13400/  200000 | consumed samples:       428800 | elapsed time per iteration (ms): 261.7 | learning rate: 8.799E-05 | global batch size:    32 | lm loss: 8.011111E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13500/  200000 | consumed samples:       432000 | elapsed time per iteration (ms): 253.6 | learning rate: 8.790E-05 | global batch size:    32 | lm loss: 7.830413E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13600/  200000 | consumed samples:       435200 | elapsed time per iteration (ms): 263.9 | learning rate: 8.781E-05 | global batch size:    32 | lm loss: 8.892001E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13700/  200000 | consumed samples:       438400 | elapsed time per iteration (ms): 254.7 | learning rate: 8.772E-05 | global batch size:    32 | lm loss: 7.455702E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13800/  200000 | consumed samples:       441600 | elapsed time per iteration (ms): 253.6 | learning rate: 8.763E-05 | global batch size:    32 | lm loss: 7.497571E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    13900/  200000 | consumed samples:       444800 | elapsed time per iteration (ms): 254.4 | learning rate: 8.754E-05 | global batch size:    32 | lm loss: 7.445254E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14000/  200000 | consumed samples:       448000 | elapsed time per iteration (ms): 254.4 | learning rate: 8.745E-05 | global batch size:    32 | lm loss: 6.997975E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14100/  200000 | consumed samples:       451200 | elapsed time per iteration (ms): 285.5 | learning rate: 8.736E-05 | global batch size:    32 | lm loss: 8.220960E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    14200/  200000 | consumed samples:       454400 | elapsed time per iteration (ms): 258.4 | learning rate: 8.726E-05 | global batch size:    32 | lm loss: 7.312521E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14300/  200000 | consumed samples:       457600 | elapsed time per iteration (ms): 259.3 | learning rate: 8.717E-05 | global batch size:    32 | lm loss: 7.279892E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14400/  200000 | consumed samples:       460800 | elapsed time per iteration (ms): 264.3 | learning rate: 8.708E-05 | global batch size:    32 | lm loss: 6.783302E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14500/  200000 | consumed samples:       464000 | elapsed time per iteration (ms): 259.8 | learning rate: 8.699E-05 | global batch size:    32 | lm loss: 7.111533E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14600/  200000 | consumed samples:       467200 | elapsed time per iteration (ms): 269.4 | learning rate: 8.690E-05 | global batch size:    32 | lm loss: 7.380549E-05 | loss scale: 67108864.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14700/  200000 | consumed samples:       470400 | elapsed time per iteration (ms): 260.6 | learning rate: 8.681E-05 | global batch size:    32 | lm loss: 6.998019E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14800/  200000 | consumed samples:       473600 | elapsed time per iteration (ms): 267.0 | learning rate: 8.672E-05 | global batch size:    32 | lm loss: 6.076205E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14900/  200000 | consumed samples:       476800 | elapsed time per iteration (ms): 256.4 | learning rate: 8.663E-05 | global batch size:    32 | lm loss: 6.932076E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15000/  200000 | consumed samples:       480000 | elapsed time per iteration (ms): 257.4 | learning rate: 8.654E-05 | global batch size:    32 | lm loss: 6.495927E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15100/  200000 | consumed samples:       483200 | elapsed time per iteration (ms): 267.8 | learning rate: 8.644E-05 | global batch size:    32 | lm loss: 6.733441E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15200/  200000 | consumed samples:       486400 | elapsed time per iteration (ms): 258.9 | learning rate: 8.635E-05 | global batch size:    32 | lm loss: 7.175343E-05 | loss scale: 134217728.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15300/  200000 | consumed samples:       489600 | elapsed time per iteration (ms): 257.9 | learning rate: 8.626E-05 | global batch size:    32 | lm loss: 7.123641E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15400/  200000 | consumed samples:       492800 | elapsed time per iteration (ms): 254.0 | learning rate: 8.617E-05 | global batch size:    32 | lm loss: 6.294495E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    15500/  200000 | consumed samples:       496000 | elapsed time per iteration (ms): 257.9 | learning rate: 8.608E-05 | global batch size:    32 | lm loss: 6.720989E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15600/  200000 | consumed samples:       499200 | elapsed time per iteration (ms): 274.7 | learning rate: 8.599E-05 | global batch size:    32 | lm loss: 6.536708E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15700/  200000 | consumed samples:       502400 | elapsed time per iteration (ms): 256.2 | learning rate: 8.590E-05 | global batch size:    32 | lm loss: 7.285119E-05 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15800/  200000 | consumed samples:       505600 | elapsed time per iteration (ms): 258.1 | learning rate: 8.581E-05 | global batch size:    32 | lm loss: 8.534914E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    15900/  200000 | consumed samples:       508800 | elapsed time per iteration (ms): 255.5 | learning rate: 8.572E-05 | global batch size:    32 | lm loss: 6.654515E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16000/  200000 | consumed samples:       512000 | elapsed time per iteration (ms): 257.7 | learning rate: 8.563E-05 | global batch size:    32 | lm loss: 7.090880E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16100/  200000 | consumed samples:       515200 | elapsed time per iteration (ms): 275.4 | learning rate: 8.554E-05 | global batch size:    32 | lm loss: 6.398832E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16200/  200000 | consumed samples:       518400 | elapsed time per iteration (ms): 257.9 | learning rate: 8.544E-05 | global batch size:    32 | lm loss: 6.320606E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16300/  200000 | consumed samples:       521600 | elapsed time per iteration (ms): 267.4 | learning rate: 8.535E-05 | global batch size:    32 | lm loss: 6.068806E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16400/  200000 | consumed samples:       524800 | elapsed time per iteration (ms): 254.9 | learning rate: 8.526E-05 | global batch size:    32 | lm loss: 6.262591E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16500/  200000 | consumed samples:       528000 | elapsed time per iteration (ms): 253.2 | learning rate: 8.517E-05 | global batch size:    32 | lm loss: 6.421274E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16600/  200000 | consumed samples:       531200 | elapsed time per iteration (ms): 266.9 | learning rate: 8.508E-05 | global batch size:    32 | lm loss: 6.641977E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16700/  200000 | consumed samples:       534400 | elapsed time per iteration (ms): 253.9 | learning rate: 8.499E-05 | global batch size:    32 | lm loss: 6.077047E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16800/  200000 | consumed samples:       537600 | elapsed time per iteration (ms): 254.4 | learning rate: 8.490E-05 | global batch size:    32 | lm loss: 6.534823E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16900/  200000 | consumed samples:       540800 | elapsed time per iteration (ms): 257.8 | learning rate: 8.481E-05 | global batch size:    32 | lm loss: 6.468730E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17000/  200000 | consumed samples:       544000 | elapsed time per iteration (ms): 266.3 | learning rate: 8.472E-05 | global batch size:    32 | lm loss: 6.042966E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17100/  200000 | consumed samples:       547200 | elapsed time per iteration (ms): 275.4 | learning rate: 8.462E-05 | global batch size:    32 | lm loss: 6.240158E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17200/  200000 | consumed samples:       550400 | elapsed time per iteration (ms): 258.0 | learning rate: 8.453E-05 | global batch size:    32 | lm loss: 6.069713E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17300/  200000 | consumed samples:       553600 | elapsed time per iteration (ms): 255.6 | learning rate: 8.444E-05 | global batch size:    32 | lm loss: 6.962299E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17400/  200000 | consumed samples:       556800 | elapsed time per iteration (ms): 260.0 | learning rate: 8.435E-05 | global batch size:    32 | lm loss: 6.353446E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    17500/  200000 | consumed samples:       560000 | elapsed time per iteration (ms): 264.7 | learning rate: 8.426E-05 | global batch size:    32 | lm loss: 6.868062E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17600/  200000 | consumed samples:       563200 | elapsed time per iteration (ms): 282.2 | learning rate: 8.417E-05 | global batch size:    32 | lm loss: 5.739539E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17700/  200000 | consumed samples:       566400 | elapsed time per iteration (ms): 263.4 | learning rate: 8.408E-05 | global batch size:    32 | lm loss: 6.001322E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17800/  200000 | consumed samples:       569600 | elapsed time per iteration (ms): 269.9 | learning rate: 8.399E-05 | global batch size:    32 | lm loss: 6.305661E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17900/  200000 | consumed samples:       572800 | elapsed time per iteration (ms): 263.9 | learning rate: 8.390E-05 | global batch size:    32 | lm loss: 5.858616E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18000/  200000 | consumed samples:       576000 | elapsed time per iteration (ms): 259.7 | learning rate: 8.381E-05 | global batch size:    32 | lm loss: 5.964084E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18100/  200000 | consumed samples:       579200 | elapsed time per iteration (ms): 274.1 | learning rate: 8.372E-05 | global batch size:    32 | lm loss: 5.555817E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18200/  200000 | consumed samples:       582400 | elapsed time per iteration (ms): 259.7 | learning rate: 8.362E-05 | global batch size:    32 | lm loss: 5.595219E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18300/  200000 | consumed samples:       585600 | elapsed time per iteration (ms): 256.0 | learning rate: 8.353E-05 | global batch size:    32 | lm loss: 5.792126E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18400/  200000 | consumed samples:       588800 | elapsed time per iteration (ms): 261.2 | learning rate: 8.344E-05 | global batch size:    32 | lm loss: 5.598560E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18500/  200000 | consumed samples:       592000 | elapsed time per iteration (ms): 266.3 | learning rate: 8.335E-05 | global batch size:    32 | lm loss: 6.265325E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18600/  200000 | consumed samples:       595200 | elapsed time per iteration (ms): 269.5 | learning rate: 8.326E-05 | global batch size:    32 | lm loss: 7.057164E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18700/  200000 | consumed samples:       598400 | elapsed time per iteration (ms): 257.1 | learning rate: 8.317E-05 | global batch size:    32 | lm loss: 5.647944E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18800/  200000 | consumed samples:       601600 | elapsed time per iteration (ms): 253.1 | learning rate: 8.308E-05 | global batch size:    32 | lm loss: 6.182975E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    18900/  200000 | consumed samples:       604800 | elapsed time per iteration (ms): 255.6 | learning rate: 8.299E-05 | global batch size:    32 | lm loss: 6.514828E-05 | loss scale: 67108864.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19000/  200000 | consumed samples:       608000 | elapsed time per iteration (ms): 255.2 | learning rate: 8.290E-05 | global batch size:    32 | lm loss: 6.185324E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19100/  200000 | consumed samples:       611200 | elapsed time per iteration (ms): 272.3 | learning rate: 8.281E-05 | global batch size:    32 | lm loss: 5.628190E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19200/  200000 | consumed samples:       614400 | elapsed time per iteration (ms): 267.8 | learning rate: 8.272E-05 | global batch size:    32 | lm loss: 5.515790E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19300/  200000 | consumed samples:       617600 | elapsed time per iteration (ms): 255.4 | learning rate: 8.262E-05 | global batch size:    32 | lm loss: 5.745310E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19400/  200000 | consumed samples:       620800 | elapsed time per iteration (ms): 256.8 | learning rate: 8.253E-05 | global batch size:    32 | lm loss: 6.439643E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19500/  200000 | consumed samples:       624000 | elapsed time per iteration (ms): 256.4 | learning rate: 8.244E-05 | global batch size:    32 | lm loss: 5.937604E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19600/  200000 | consumed samples:       627200 | elapsed time per iteration (ms): 267.9 | learning rate: 8.235E-05 | global batch size:    32 | lm loss: 5.497758E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19700/  200000 | consumed samples:       630400 | elapsed time per iteration (ms): 255.0 | learning rate: 8.226E-05 | global batch size:    32 | lm loss: 5.162123E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19800/  200000 | consumed samples:       633600 | elapsed time per iteration (ms): 255.6 | learning rate: 8.217E-05 | global batch size:    32 | lm loss: 5.308630E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19900/  200000 | consumed samples:       636800 | elapsed time per iteration (ms): 263.3 | learning rate: 8.208E-05 | global batch size:    32 | lm loss: 5.507422E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20000/  200000 | consumed samples:       640000 | elapsed time per iteration (ms): 265.9 | learning rate: 8.199E-05 | global batch size:    32 | lm loss: 5.129917E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20100/  200000 | consumed samples:       643200 | elapsed time per iteration (ms): 267.5 | learning rate: 8.190E-05 | global batch size:    32 | lm loss: 5.598148E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    20200/  200000 | consumed samples:       646400 | elapsed time per iteration (ms): 252.8 | learning rate: 8.181E-05 | global batch size:    32 | lm loss: 5.668776E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20300/  200000 | consumed samples:       649600 | elapsed time per iteration (ms): 255.1 | learning rate: 8.172E-05 | global batch size:    32 | lm loss: 6.006235E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20400/  200000 | consumed samples:       652800 | elapsed time per iteration (ms): 255.7 | learning rate: 8.162E-05 | global batch size:    32 | lm loss: 5.997133E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20500/  200000 | consumed samples:       656000 | elapsed time per iteration (ms): 255.8 | learning rate: 8.153E-05 | global batch size:    32 | lm loss: 5.806594E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20600/  200000 | consumed samples:       659200 | elapsed time per iteration (ms): 271.7 | learning rate: 8.144E-05 | global batch size:    32 | lm loss: 5.281864E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20700/  200000 | consumed samples:       662400 | elapsed time per iteration (ms): 266.8 | learning rate: 8.135E-05 | global batch size:    32 | lm loss: 5.304739E-05 | loss scale: 67108864.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20800/  200000 | consumed samples:       665600 | elapsed time per iteration (ms): 263.4 | learning rate: 8.126E-05 | global batch size:    32 | lm loss: 5.331791E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20900/  200000 | consumed samples:       668800 | elapsed time per iteration (ms): 259.4 | learning rate: 8.117E-05 | global batch size:    32 | lm loss: 5.156939E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21000/  200000 | consumed samples:       672000 | elapsed time per iteration (ms): 257.0 | learning rate: 8.108E-05 | global batch size:    32 | lm loss: 5.829480E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21100/  200000 | consumed samples:       675200 | elapsed time per iteration (ms): 271.3 | learning rate: 8.099E-05 | global batch size:    32 | lm loss: 5.339563E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21200/  200000 | consumed samples:       678400 | elapsed time per iteration (ms): 255.5 | learning rate: 8.090E-05 | global batch size:    32 | lm loss: 4.789048E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21300/  200000 | consumed samples:       681600 | elapsed time per iteration (ms): 254.0 | learning rate: 8.081E-05 | global batch size:    32 | lm loss: 5.455955E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    21400/  200000 | consumed samples:       684800 | elapsed time per iteration (ms): 267.3 | learning rate: 8.072E-05 | global batch size:    32 | lm loss: 4.961278E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21500/  200000 | consumed samples:       688000 | elapsed time per iteration (ms): 256.8 | learning rate: 8.062E-05 | global batch size:    32 | lm loss: 4.782526E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21600/  200000 | consumed samples:       691200 | elapsed time per iteration (ms): 269.2 | learning rate: 8.053E-05 | global batch size:    32 | lm loss: 4.710309E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21700/  200000 | consumed samples:       694400 | elapsed time per iteration (ms): 258.9 | learning rate: 8.044E-05 | global batch size:    32 | lm loss: 4.770754E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21800/  200000 | consumed samples:       697600 | elapsed time per iteration (ms): 255.3 | learning rate: 8.035E-05 | global batch size:    32 | lm loss: 5.159236E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21900/  200000 | consumed samples:       700800 | elapsed time per iteration (ms): 254.8 | learning rate: 8.026E-05 | global batch size:    32 | lm loss: 4.748707E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22000/  200000 | consumed samples:       704000 | elapsed time per iteration (ms): 254.9 | learning rate: 8.017E-05 | global batch size:    32 | lm loss: 4.974124E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22100/  200000 | consumed samples:       707200 | elapsed time per iteration (ms): 272.7 | learning rate: 8.008E-05 | global batch size:    32 | lm loss: 5.207122E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22200/  200000 | consumed samples:       710400 | elapsed time per iteration (ms): 262.9 | learning rate: 7.999E-05 | global batch size:    32 | lm loss: 6.116937E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22300/  200000 | consumed samples:       713600 | elapsed time per iteration (ms): 254.0 | learning rate: 7.990E-05 | global batch size:    32 | lm loss: 4.934849E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22400/  200000 | consumed samples:       716800 | elapsed time per iteration (ms): 257.0 | learning rate: 7.980E-05 | global batch size:    32 | lm loss: 4.686916E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22500/  200000 | consumed samples:       720000 | elapsed time per iteration (ms): 255.1 | learning rate: 7.971E-05 | global batch size:    32 | lm loss: 4.790605E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22600/  200000 | consumed samples:       723200 | elapsed time per iteration (ms): 268.4 | learning rate: 7.962E-05 | global batch size:    32 | lm loss: 5.382743E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    22700/  200000 | consumed samples:       726400 | elapsed time per iteration (ms): 253.6 | learning rate: 7.953E-05 | global batch size:    32 | lm loss: 4.843843E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22800/  200000 | consumed samples:       729600 | elapsed time per iteration (ms): 256.7 | learning rate: 7.944E-05 | global batch size:    32 | lm loss: 4.904001E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22900/  200000 | consumed samples:       732800 | elapsed time per iteration (ms): 264.4 | learning rate: 7.935E-05 | global batch size:    32 | lm loss: 5.213238E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23000/  200000 | consumed samples:       736000 | elapsed time per iteration (ms): 255.9 | learning rate: 7.926E-05 | global batch size:    32 | lm loss: 4.610702E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23100/  200000 | consumed samples:       739200 | elapsed time per iteration (ms): 265.7 | learning rate: 7.917E-05 | global batch size:    32 | lm loss: 4.489732E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23200/  200000 | consumed samples:       742400 | elapsed time per iteration (ms): 256.6 | learning rate: 7.908E-05 | global batch size:    32 | lm loss: 4.946021E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23300/  200000 | consumed samples:       745600 | elapsed time per iteration (ms): 254.2 | learning rate: 7.899E-05 | global batch size:    32 | lm loss: 4.831385E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23400/  200000 | consumed samples:       748800 | elapsed time per iteration (ms): 254.1 | learning rate: 7.890E-05 | global batch size:    32 | lm loss: 5.311719E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23500/  200000 | consumed samples:       752000 | elapsed time per iteration (ms): 251.8 | learning rate: 7.880E-05 | global batch size:    32 | lm loss: 4.951873E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23600/  200000 | consumed samples:       755200 | elapsed time per iteration (ms): 276.3 | learning rate: 7.871E-05 | global batch size:    32 | lm loss: 4.859340E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    23700/  200000 | consumed samples:       758400 | elapsed time per iteration (ms): 253.7 | learning rate: 7.862E-05 | global batch size:    32 | lm loss: 4.727597E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23800/  200000 | consumed samples:       761600 | elapsed time per iteration (ms): 253.7 | learning rate: 7.853E-05 | global batch size:    32 | lm loss: 4.252710E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23900/  200000 | consumed samples:       764800 | elapsed time per iteration (ms): 256.7 | learning rate: 7.844E-05 | global batch size:    32 | lm loss: 4.404779E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24000/  200000 | consumed samples:       768000 | elapsed time per iteration (ms): 256.2 | learning rate: 7.835E-05 | global batch size:    32 | lm loss: 4.412825E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24100/  200000 | consumed samples:       771200 | elapsed time per iteration (ms): 267.7 | learning rate: 7.826E-05 | global batch size:    32 | lm loss: 4.612754E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24200/  200000 | consumed samples:       774400 | elapsed time per iteration (ms): 254.8 | learning rate: 7.817E-05 | global batch size:    32 | lm loss: 5.519264E-05 | loss scale: 67108864.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24300/  200000 | consumed samples:       777600 | elapsed time per iteration (ms): 256.4 | learning rate: 7.808E-05 | global batch size:    32 | lm loss: 5.715200E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24400/  200000 | consumed samples:       780800 | elapsed time per iteration (ms): 262.7 | learning rate: 7.799E-05 | global batch size:    32 | lm loss: 4.634574E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24500/  200000 | consumed samples:       784000 | elapsed time per iteration (ms): 256.3 | learning rate: 7.789E-05 | global batch size:    32 | lm loss: 4.517197E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24600/  200000 | consumed samples:       787200 | elapsed time per iteration (ms): 273.3 | learning rate: 7.780E-05 | global batch size:    32 | lm loss: 4.418841E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24700/  200000 | consumed samples:       790400 | elapsed time per iteration (ms): 255.1 | learning rate: 7.771E-05 | global batch size:    32 | lm loss: 3.919413E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24800/  200000 | consumed samples:       793600 | elapsed time per iteration (ms): 256.1 | learning rate: 7.762E-05 | global batch size:    32 | lm loss: 4.069051E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24900/  200000 | consumed samples:       796800 | elapsed time per iteration (ms): 257.1 | learning rate: 7.753E-05 | global batch size:    32 | lm loss: 4.507159E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25000/  200000 | consumed samples:       800000 | elapsed time per iteration (ms): 257.6 | learning rate: 7.744E-05 | global batch size:    32 | lm loss: 4.180867E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25100/  200000 | consumed samples:       803200 | elapsed time per iteration (ms): 282.7 | learning rate: 7.735E-05 | global batch size:    32 | lm loss: 4.107833E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25200/  200000 | consumed samples:       806400 | elapsed time per iteration (ms): 255.0 | learning rate: 7.726E-05 | global batch size:    32 | lm loss: 4.152207E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25300/  200000 | consumed samples:       809600 | elapsed time per iteration (ms): 256.2 | learning rate: 7.717E-05 | global batch size:    32 | lm loss: 5.723707E-05 | loss scale: 67108864.0 | grad norm: 0.011 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    25400/  200000 | consumed samples:       812800 | elapsed time per iteration (ms): 265.0 | learning rate: 7.708E-05 | global batch size:    32 | lm loss: 4.302297E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25500/  200000 | consumed samples:       816000 | elapsed time per iteration (ms): 262.9 | learning rate: 7.699E-05 | global batch size:    32 | lm loss: 4.055590E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25600/  200000 | consumed samples:       819200 | elapsed time per iteration (ms): 265.5 | learning rate: 7.689E-05 | global batch size:    32 | lm loss: 4.538171E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25700/  200000 | consumed samples:       822400 | elapsed time per iteration (ms): 255.2 | learning rate: 7.680E-05 | global batch size:    32 | lm loss: 4.581844E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25800/  200000 | consumed samples:       825600 | elapsed time per iteration (ms): 266.5 | learning rate: 7.671E-05 | global batch size:    32 | lm loss: 4.526191E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25900/  200000 | consumed samples:       828800 | elapsed time per iteration (ms): 254.5 | learning rate: 7.662E-05 | global batch size:    32 | lm loss: 3.992010E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26000/  200000 | consumed samples:       832000 | elapsed time per iteration (ms): 256.0 | learning rate: 7.653E-05 | global batch size:    32 | lm loss: 4.226687E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26100/  200000 | consumed samples:       835200 | elapsed time per iteration (ms): 265.8 | learning rate: 7.644E-05 | global batch size:    32 | lm loss: 4.347528E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26200/  200000 | consumed samples:       838400 | elapsed time per iteration (ms): 254.9 | learning rate: 7.635E-05 | global batch size:    32 | lm loss: 4.269677E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26300/  200000 | consumed samples:       841600 | elapsed time per iteration (ms): 258.8 | learning rate: 7.626E-05 | global batch size:    32 | lm loss: 3.984977E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26400/  200000 | consumed samples:       844800 | elapsed time per iteration (ms): 256.9 | learning rate: 7.617E-05 | global batch size:    32 | lm loss: 4.266507E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26500/  200000 | consumed samples:       848000 | elapsed time per iteration (ms): 260.6 | learning rate: 7.608E-05 | global batch size:    32 | lm loss: 4.556951E-05 | loss scale: 67108864.0 | grad norm: 0.010 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    26600/  200000 | consumed samples:       851200 | elapsed time per iteration (ms): 273.1 | learning rate: 7.599E-05 | global batch size:    32 | lm loss: 4.573400E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26700/  200000 | consumed samples:       854400 | elapsed time per iteration (ms): 255.3 | learning rate: 7.589E-05 | global batch size:    32 | lm loss: 4.167315E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26800/  200000 | consumed samples:       857600 | elapsed time per iteration (ms): 253.2 | learning rate: 7.580E-05 | global batch size:    32 | lm loss: 4.136033E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26900/  200000 | consumed samples:       860800 | elapsed time per iteration (ms): 253.7 | learning rate: 7.571E-05 | global batch size:    32 | lm loss: 3.920047E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27000/  200000 | consumed samples:       864000 | elapsed time per iteration (ms): 267.1 | learning rate: 7.562E-05 | global batch size:    32 | lm loss: 4.410219E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27100/  200000 | consumed samples:       867200 | elapsed time per iteration (ms): 266.0 | learning rate: 7.553E-05 | global batch size:    32 | lm loss: 4.201565E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27200/  200000 | consumed samples:       870400 | elapsed time per iteration (ms): 253.9 | learning rate: 7.544E-05 | global batch size:    32 | lm loss: 4.066287E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27300/  200000 | consumed samples:       873600 | elapsed time per iteration (ms): 271.4 | learning rate: 7.535E-05 | global batch size:    32 | lm loss: 3.884232E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27400/  200000 | consumed samples:       876800 | elapsed time per iteration (ms): 257.6 | learning rate: 7.526E-05 | global batch size:    32 | lm loss: 4.126361E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27500/  200000 | consumed samples:       880000 | elapsed time per iteration (ms): 260.7 | learning rate: 7.517E-05 | global batch size:    32 | lm loss: 4.057938E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27600/  200000 | consumed samples:       883200 | elapsed time per iteration (ms): 266.7 | learning rate: 7.507E-05 | global batch size:    32 | lm loss: 4.112982E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27700/  200000 | consumed samples:       886400 | elapsed time per iteration (ms): 257.1 | learning rate: 7.498E-05 | global batch size:    32 | lm loss: 4.318501E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27800/  200000 | consumed samples:       889600 | elapsed time per iteration (ms): 258.9 | learning rate: 7.489E-05 | global batch size:    32 | lm loss: 4.028536E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27900/  200000 | consumed samples:       892800 | elapsed time per iteration (ms): 256.0 | learning rate: 7.480E-05 | global batch size:    32 | lm loss: 3.803995E-05 | loss scale: 134217728.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28000/  200000 | consumed samples:       896000 | elapsed time per iteration (ms): 265.4 | learning rate: 7.471E-05 | global batch size:    32 | lm loss: 4.132549E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28100/  200000 | consumed samples:       899200 | elapsed time per iteration (ms): 274.9 | learning rate: 7.462E-05 | global batch size:    32 | lm loss: 3.890705E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28200/  200000 | consumed samples:       902400 | elapsed time per iteration (ms): 253.4 | learning rate: 7.453E-05 | global batch size:    32 | lm loss: 3.814301E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28300/  200000 | consumed samples:       905600 | elapsed time per iteration (ms): 254.0 | learning rate: 7.444E-05 | global batch size:    32 | lm loss: 3.452283E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28400/  200000 | consumed samples:       908800 | elapsed time per iteration (ms): 256.7 | learning rate: 7.435E-05 | global batch size:    32 | lm loss: 3.573254E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28500/  200000 | consumed samples:       912000 | elapsed time per iteration (ms): 252.2 | learning rate: 7.426E-05 | global batch size:    32 | lm loss: 3.800385E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    28600/  200000 | consumed samples:       915200 | elapsed time per iteration (ms): 275.0 | learning rate: 7.417E-05 | global batch size:    32 | lm loss: 3.717318E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28700/  200000 | consumed samples:       918400 | elapsed time per iteration (ms): 267.3 | learning rate: 7.407E-05 | global batch size:    32 | lm loss: 3.956180E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28800/  200000 | consumed samples:       921600 | elapsed time per iteration (ms): 257.3 | learning rate: 7.398E-05 | global batch size:    32 | lm loss: 3.853486E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    28900/  200000 | consumed samples:       924800 | elapsed time per iteration (ms): 255.7 | learning rate: 7.389E-05 | global batch size:    32 | lm loss: 4.087412E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29000/  200000 | consumed samples:       928000 | elapsed time per iteration (ms): 253.5 | learning rate: 7.380E-05 | global batch size:    32 | lm loss: 3.724194E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29100/  200000 | consumed samples:       931200 | elapsed time per iteration (ms): 265.7 | learning rate: 7.371E-05 | global batch size:    32 | lm loss: 3.893455E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29200/  200000 | consumed samples:       934400 | elapsed time per iteration (ms): 255.7 | learning rate: 7.362E-05 | global batch size:    32 | lm loss: 3.572672E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29300/  200000 | consumed samples:       937600 | elapsed time per iteration (ms): 253.9 | learning rate: 7.353E-05 | global batch size:    32 | lm loss: 3.573279E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29400/  200000 | consumed samples:       940800 | elapsed time per iteration (ms): 255.5 | learning rate: 7.344E-05 | global batch size:    32 | lm loss: 4.214080E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29500/  200000 | consumed samples:       944000 | elapsed time per iteration (ms): 264.7 | learning rate: 7.335E-05 | global batch size:    32 | lm loss: 3.722520E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29600/  200000 | consumed samples:       947200 | elapsed time per iteration (ms): 271.4 | learning rate: 7.326E-05 | global batch size:    32 | lm loss: 3.462962E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29700/  200000 | consumed samples:       950400 | elapsed time per iteration (ms): 252.3 | learning rate: 7.316E-05 | global batch size:    32 | lm loss: 3.551946E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29800/  200000 | consumed samples:       953600 | elapsed time per iteration (ms): 254.9 | learning rate: 7.307E-05 | global batch size:    32 | lm loss: 3.940863E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29900/  200000 | consumed samples:       956800 | elapsed time per iteration (ms): 252.4 | learning rate: 7.298E-05 | global batch size:    32 | lm loss: 3.847142E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30000/  200000 | consumed samples:       960000 | elapsed time per iteration (ms): 254.8 | learning rate: 7.289E-05 | global batch size:    32 | lm loss: 3.643310E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30100/  200000 | consumed samples:       963200 | elapsed time per iteration (ms): 264.9 | learning rate: 7.280E-05 | global batch size:    32 | lm loss: 3.834319E-05 | loss scale: 134217728.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30200/  200000 | consumed samples:       966400 | elapsed time per iteration (ms): 262.4 | learning rate: 7.271E-05 | global batch size:    32 | lm loss: 4.030302E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    30300/  200000 | consumed samples:       969600 | elapsed time per iteration (ms): 254.4 | learning rate: 7.262E-05 | global batch size:    32 | lm loss: 3.440072E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30400/  200000 | consumed samples:       972800 | elapsed time per iteration (ms): 253.3 | learning rate: 7.253E-05 | global batch size:    32 | lm loss: 3.595054E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30500/  200000 | consumed samples:       976000 | elapsed time per iteration (ms): 255.0 | learning rate: 7.244E-05 | global batch size:    32 | lm loss: 4.148982E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30600/  200000 | consumed samples:       979200 | elapsed time per iteration (ms): 268.1 | learning rate: 7.235E-05 | global batch size:    32 | lm loss: 3.646320E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30700/  200000 | consumed samples:       982400 | elapsed time per iteration (ms): 254.2 | learning rate: 7.226E-05 | global batch size:    32 | lm loss: 3.686936E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30800/  200000 | consumed samples:       985600 | elapsed time per iteration (ms): 252.6 | learning rate: 7.216E-05 | global batch size:    32 | lm loss: 3.600029E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30900/  200000 | consumed samples:       988800 | elapsed time per iteration (ms): 264.7 | learning rate: 7.207E-05 | global batch size:    32 | lm loss: 3.801184E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31000/  200000 | consumed samples:       992000 | elapsed time per iteration (ms): 256.4 | learning rate: 7.198E-05 | global batch size:    32 | lm loss: 4.098569E-05 | loss scale: 67108864.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31100/  200000 | consumed samples:       995200 | elapsed time per iteration (ms): 267.2 | learning rate: 7.189E-05 | global batch size:    32 | lm loss: 3.844213E-05 | loss scale: 67108864.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31200/  200000 | consumed samples:       998400 | elapsed time per iteration (ms): 255.4 | learning rate: 7.180E-05 | global batch size:    32 | lm loss: 3.630338E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31300/  200000 | consumed samples:      1001600 | elapsed time per iteration (ms): 254.6 | learning rate: 7.171E-05 | global batch size:    32 | lm loss: 3.559090E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31400/  200000 | consumed samples:      1004800 | elapsed time per iteration (ms): 255.0 | learning rate: 7.162E-05 | global batch size:    32 | lm loss: 3.683938E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31500/  200000 | consumed samples:      1008000 | elapsed time per iteration (ms): 253.9 | learning rate: 7.153E-05 | global batch size:    32 | lm loss: 3.554221E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31600/  200000 | consumed samples:      1011200 | elapsed time per iteration (ms): 281.1 | learning rate: 7.144E-05 | global batch size:    32 | lm loss: 3.142951E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31700/  200000 | consumed samples:      1014400 | elapsed time per iteration (ms): 267.2 | learning rate: 7.134E-05 | global batch size:    32 | lm loss: 3.333776E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31800/  200000 | consumed samples:      1017600 | elapsed time per iteration (ms): 260.3 | learning rate: 7.125E-05 | global batch size:    32 | lm loss: 3.277648E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31900/  200000 | consumed samples:      1020800 | elapsed time per iteration (ms): 254.9 | learning rate: 7.116E-05 | global batch size:    32 | lm loss: 3.294502E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32000/  200000 | consumed samples:      1024000 | elapsed time per iteration (ms): 255.2 | learning rate: 7.107E-05 | global batch size:    32 | lm loss: 3.400393E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32100/  200000 | consumed samples:      1027200 | elapsed time per iteration (ms): 268.5 | learning rate: 7.098E-05 | global batch size:    32 | lm loss: 3.139248E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32200/  200000 | consumed samples:      1030400 | elapsed time per iteration (ms): 264.8 | learning rate: 7.089E-05 | global batch size:    32 | lm loss: 3.152473E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    32300/  200000 | consumed samples:      1033600 | elapsed time per iteration (ms): 257.1 | learning rate: 7.080E-05 | global batch size:    32 | lm loss: 3.371204E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32400/  200000 | consumed samples:      1036800 | elapsed time per iteration (ms): 267.8 | learning rate: 7.071E-05 | global batch size:    32 | lm loss: 3.182555E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32500/  200000 | consumed samples:      1040000 | elapsed time per iteration (ms): 256.2 | learning rate: 7.062E-05 | global batch size:    32 | lm loss: 3.206884E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32600/  200000 | consumed samples:      1043200 | elapsed time per iteration (ms): 266.6 | learning rate: 7.053E-05 | global batch size:    32 | lm loss: 3.220162E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32700/  200000 | consumed samples:      1046400 | elapsed time per iteration (ms): 255.3 | learning rate: 7.044E-05 | global batch size:    32 | lm loss: 3.348765E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32800/  200000 | consumed samples:      1049600 | elapsed time per iteration (ms): 254.6 | learning rate: 7.035E-05 | global batch size:    32 | lm loss: 3.655143E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    32900/  200000 | consumed samples:      1052800 | elapsed time per iteration (ms): 257.5 | learning rate: 7.025E-05 | global batch size:    32 | lm loss: 3.232338E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33000/  200000 | consumed samples:      1056000 | elapsed time per iteration (ms): 255.7 | learning rate: 7.016E-05 | global batch size:    32 | lm loss: 3.219025E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33100/  200000 | consumed samples:      1059200 | elapsed time per iteration (ms): 281.9 | learning rate: 7.007E-05 | global batch size:    32 | lm loss: 3.010757E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33200/  200000 | consumed samples:      1062400 | elapsed time per iteration (ms): 264.6 | learning rate: 6.998E-05 | global batch size:    32 | lm loss: 3.388016E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33300/  200000 | consumed samples:      1065600 | elapsed time per iteration (ms): 256.4 | learning rate: 6.989E-05 | global batch size:    32 | lm loss: 3.351020E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33400/  200000 | consumed samples:      1068800 | elapsed time per iteration (ms): 257.1 | learning rate: 6.980E-05 | global batch size:    32 | lm loss: 3.297861E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33500/  200000 | consumed samples:      1072000 | elapsed time per iteration (ms): 262.1 | learning rate: 6.971E-05 | global batch size:    32 | lm loss: 3.415573E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33600/  200000 | consumed samples:      1075200 | elapsed time per iteration (ms): 265.3 | learning rate: 6.962E-05 | global batch size:    32 | lm loss: 3.224002E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33700/  200000 | consumed samples:      1078400 | elapsed time per iteration (ms): 250.9 | learning rate: 6.953E-05 | global batch size:    32 | lm loss: 3.676066E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33800/  200000 | consumed samples:      1081600 | elapsed time per iteration (ms): 260.2 | learning rate: 6.943E-05 | global batch size:    32 | lm loss: 3.294751E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33900/  200000 | consumed samples:      1084800 | elapsed time per iteration (ms): 263.9 | learning rate: 6.934E-05 | global batch size:    32 | lm loss: 3.527971E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34000/  200000 | consumed samples:      1088000 | elapsed time per iteration (ms): 253.9 | learning rate: 6.925E-05 | global batch size:    32 | lm loss: 3.764044E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    34100/  200000 | consumed samples:      1091200 | elapsed time per iteration (ms): 265.5 | learning rate: 6.916E-05 | global batch size:    32 | lm loss: 3.151519E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34200/  200000 | consumed samples:      1094400 | elapsed time per iteration (ms): 256.6 | learning rate: 6.907E-05 | global batch size:    32 | lm loss: 3.133670E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34300/  200000 | consumed samples:      1097600 | elapsed time per iteration (ms): 252.6 | learning rate: 6.898E-05 | global batch size:    32 | lm loss: 3.148426E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34400/  200000 | consumed samples:      1100800 | elapsed time per iteration (ms): 255.6 | learning rate: 6.889E-05 | global batch size:    32 | lm loss: 3.434450E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34500/  200000 | consumed samples:      1104000 | elapsed time per iteration (ms): 258.8 | learning rate: 6.880E-05 | global batch size:    32 | lm loss: 3.291955E-05 | loss scale: 67108864.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34600/  200000 | consumed samples:      1107200 | elapsed time per iteration (ms): 285.6 | learning rate: 6.871E-05 | global batch size:    32 | lm loss: 3.267798E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34700/  200000 | consumed samples:      1110400 | elapsed time per iteration (ms): 260.3 | learning rate: 6.862E-05 | global batch size:    32 | lm loss: 3.203739E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34800/  200000 | consumed samples:      1113600 | elapsed time per iteration (ms): 256.0 | learning rate: 6.853E-05 | global batch size:    32 | lm loss: 3.439731E-05 | loss scale: 67108864.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34900/  200000 | consumed samples:      1116800 | elapsed time per iteration (ms): 258.3 | learning rate: 6.843E-05 | global batch size:    32 | lm loss: 3.239527E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35000/  200000 | consumed samples:      1120000 | elapsed time per iteration (ms): 255.0 | learning rate: 6.834E-05 | global batch size:    32 | lm loss: 3.434856E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35100/  200000 | consumed samples:      1123200 | elapsed time per iteration (ms): 269.7 | learning rate: 6.825E-05 | global batch size:    32 | lm loss: 3.204944E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35200/  200000 | consumed samples:      1126400 | elapsed time per iteration (ms): 261.0 | learning rate: 6.816E-05 | global batch size:    32 | lm loss: 3.334504E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    35300/  200000 | consumed samples:      1129600 | elapsed time per iteration (ms): 266.5 | learning rate: 6.807E-05 | global batch size:    32 | lm loss: 2.821159E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35400/  200000 | consumed samples:      1132800 | elapsed time per iteration (ms): 253.0 | learning rate: 6.798E-05 | global batch size:    32 | lm loss: 2.959262E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    35500/  200000 | consumed samples:      1136000 | elapsed time per iteration (ms): 256.4 | learning rate: 6.789E-05 | global batch size:    32 | lm loss: 2.736695E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35600/  200000 | consumed samples:      1139200 | elapsed time per iteration (ms): 264.6 | learning rate: 6.780E-05 | global batch size:    32 | lm loss: 3.003228E-05 | loss scale: 33554432.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35700/  200000 | consumed samples:      1142400 | elapsed time per iteration (ms): 255.7 | learning rate: 6.771E-05 | global batch size:    32 | lm loss: 2.854665E-05 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35800/  200000 | consumed samples:      1145600 | elapsed time per iteration (ms): 253.3 | learning rate: 6.762E-05 | global batch size:    32 | lm loss: 2.866581E-05 | loss scale: 33554432.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35900/  200000 | consumed samples:      1148800 | elapsed time per iteration (ms): 258.6 | learning rate: 6.753E-05 | global batch size:    32 | lm loss: 2.845361E-05 | loss scale: 33554432.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36000/  200000 | consumed samples:      1152000 | elapsed time per iteration (ms): 257.7 | learning rate: 6.743E-05 | global batch size:    32 | lm loss: 3.035065E-05 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36100/  200000 | consumed samples:      1155200 | elapsed time per iteration (ms): 275.0 | learning rate: 6.734E-05 | global batch size:    32 | lm loss: 3.062215E-05 | loss scale: 33554432.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36200/  200000 | consumed samples:      1158400 | elapsed time per iteration (ms): 254.5 | learning rate: 6.725E-05 | global batch size:    32 | lm loss: 2.829214E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36300/  200000 | consumed samples:      1161600 | elapsed time per iteration (ms): 254.8 | learning rate: 6.716E-05 | global batch size:    32 | lm loss: 2.944786E-05 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36400/  200000 | consumed samples:      1164800 | elapsed time per iteration (ms): 254.0 | learning rate: 6.707E-05 | global batch size:    32 | lm loss: 3.157380E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36500/  200000 | consumed samples:      1168000 | elapsed time per iteration (ms): 254.2 | learning rate: 6.698E-05 | global batch size:    32 | lm loss: 2.877435E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36600/  200000 | consumed samples:      1171200 | elapsed time per iteration (ms): 264.5 | learning rate: 6.689E-05 | global batch size:    32 | lm loss: 2.784973E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36700/  200000 | consumed samples:      1174400 | elapsed time per iteration (ms): 254.6 | learning rate: 6.680E-05 | global batch size:    32 | lm loss: 2.973009E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36800/  200000 | consumed samples:      1177600 | elapsed time per iteration (ms): 263.5 | learning rate: 6.671E-05 | global batch size:    32 | lm loss: 2.851682E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36900/  200000 | consumed samples:      1180800 | elapsed time per iteration (ms): 258.9 | learning rate: 6.662E-05 | global batch size:    32 | lm loss: 2.942163E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37000/  200000 | consumed samples:      1184000 | elapsed time per iteration (ms): 252.6 | learning rate: 6.652E-05 | global batch size:    32 | lm loss: 2.933144E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37100/  200000 | consumed samples:      1187200 | elapsed time per iteration (ms): 265.2 | learning rate: 6.643E-05 | global batch size:    32 | lm loss: 2.769348E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37200/  200000 | consumed samples:      1190400 | elapsed time per iteration (ms): 256.1 | learning rate: 6.634E-05 | global batch size:    32 | lm loss: 3.136046E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37300/  200000 | consumed samples:      1193600 | elapsed time per iteration (ms): 256.1 | learning rate: 6.625E-05 | global batch size:    32 | lm loss: 2.924608E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37400/  200000 | consumed samples:      1196800 | elapsed time per iteration (ms): 251.8 | learning rate: 6.616E-05 | global batch size:    32 | lm loss: 3.168648E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37500/  200000 | consumed samples:      1200000 | elapsed time per iteration (ms): 266.3 | learning rate: 6.607E-05 | global batch size:    32 | lm loss: 2.820507E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37600/  200000 | consumed samples:      1203200 | elapsed time per iteration (ms): 272.1 | learning rate: 6.598E-05 | global batch size:    32 | lm loss: 2.764961E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37700/  200000 | consumed samples:      1206400 | elapsed time per iteration (ms): 255.5 | learning rate: 6.589E-05 | global batch size:    32 | lm loss: 2.841383E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37800/  200000 | consumed samples:      1209600 | elapsed time per iteration (ms): 256.3 | learning rate: 6.580E-05 | global batch size:    32 | lm loss: 2.871501E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37900/  200000 | consumed samples:      1212800 | elapsed time per iteration (ms): 255.9 | learning rate: 6.570E-05 | global batch size:    32 | lm loss: 2.792990E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38000/  200000 | consumed samples:      1216000 | elapsed time per iteration (ms): 256.5 | learning rate: 6.561E-05 | global batch size:    32 | lm loss: 3.030587E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38100/  200000 | consumed samples:      1219200 | elapsed time per iteration (ms): 267.6 | learning rate: 6.552E-05 | global batch size:    32 | lm loss: 3.230189E-05 | loss scale: 134217728.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38200/  200000 | consumed samples:      1222400 | elapsed time per iteration (ms): 263.0 | learning rate: 6.543E-05 | global batch size:    32 | lm loss: 3.155618E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38300/  200000 | consumed samples:      1225600 | elapsed time per iteration (ms): 259.5 | learning rate: 6.534E-05 | global batch size:    32 | lm loss: 2.806135E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38400/  200000 | consumed samples:      1228800 | elapsed time per iteration (ms): 254.4 | learning rate: 6.525E-05 | global batch size:    32 | lm loss: 2.695119E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    38500/  200000 | consumed samples:      1232000 | elapsed time per iteration (ms): 255.4 | learning rate: 6.516E-05 | global batch size:    32 | lm loss: 2.846983E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38600/  200000 | consumed samples:      1235200 | elapsed time per iteration (ms): 272.0 | learning rate: 6.507E-05 | global batch size:    32 | lm loss: 2.823740E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38700/  200000 | consumed samples:      1238400 | elapsed time per iteration (ms): 252.5 | learning rate: 6.498E-05 | global batch size:    32 | lm loss: 2.669383E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    38800/  200000 | consumed samples:      1241600 | elapsed time per iteration (ms): 256.2 | learning rate: 6.489E-05 | global batch size:    32 | lm loss: 2.642192E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38900/  200000 | consumed samples:      1244800 | elapsed time per iteration (ms): 254.0 | learning rate: 6.480E-05 | global batch size:    32 | lm loss: 2.538231E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39000/  200000 | consumed samples:      1248000 | elapsed time per iteration (ms): 268.6 | learning rate: 6.470E-05 | global batch size:    32 | lm loss: 2.641573E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39100/  200000 | consumed samples:      1251200 | elapsed time per iteration (ms): 272.4 | learning rate: 6.461E-05 | global batch size:    32 | lm loss: 2.586770E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39200/  200000 | consumed samples:      1254400 | elapsed time per iteration (ms): 254.8 | learning rate: 6.452E-05 | global batch size:    32 | lm loss: 2.534346E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39300/  200000 | consumed samples:      1257600 | elapsed time per iteration (ms): 255.1 | learning rate: 6.443E-05 | global batch size:    32 | lm loss: 2.804387E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39400/  200000 | consumed samples:      1260800 | elapsed time per iteration (ms): 255.0 | learning rate: 6.434E-05 | global batch size:    32 | lm loss: 2.587690E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39500/  200000 | consumed samples:      1264000 | elapsed time per iteration (ms): 255.1 | learning rate: 6.425E-05 | global batch size:    32 | lm loss: 2.748725E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39600/  200000 | consumed samples:      1267200 | elapsed time per iteration (ms): 266.6 | learning rate: 6.416E-05 | global batch size:    32 | lm loss: 2.548719E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39700/  200000 | consumed samples:      1270400 | elapsed time per iteration (ms): 267.3 | learning rate: 6.407E-05 | global batch size:    32 | lm loss: 2.740388E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39800/  200000 | consumed samples:      1273600 | elapsed time per iteration (ms): 257.0 | learning rate: 6.398E-05 | global batch size:    32 | lm loss: 2.560274E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39900/  200000 | consumed samples:      1276800 | elapsed time per iteration (ms): 256.5 | learning rate: 6.389E-05 | global batch size:    32 | lm loss: 2.660245E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40000/  200000 | consumed samples:      1280000 | elapsed time per iteration (ms): 254.2 | learning rate: 6.379E-05 | global batch size:    32 | lm loss: 2.546391E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40100/  200000 | consumed samples:      1283200 | elapsed time per iteration (ms): 267.1 | learning rate: 6.370E-05 | global batch size:    32 | lm loss: 2.449156E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40200/  200000 | consumed samples:      1286400 | elapsed time per iteration (ms): 256.6 | learning rate: 6.361E-05 | global batch size:    32 | lm loss: 2.777966E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40300/  200000 | consumed samples:      1289600 | elapsed time per iteration (ms): 253.8 | learning rate: 6.352E-05 | global batch size:    32 | lm loss: 2.678000E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    40400/  200000 | consumed samples:      1292800 | elapsed time per iteration (ms): 262.7 | learning rate: 6.343E-05 | global batch size:    32 | lm loss: 2.685711E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40500/  200000 | consumed samples:      1296000 | elapsed time per iteration (ms): 262.7 | learning rate: 6.334E-05 | global batch size:    32 | lm loss: 2.612896E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40600/  200000 | consumed samples:      1299200 | elapsed time per iteration (ms): 270.8 | learning rate: 6.325E-05 | global batch size:    32 | lm loss: 2.481213E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40700/  200000 | consumed samples:      1302400 | elapsed time per iteration (ms): 253.8 | learning rate: 6.316E-05 | global batch size:    32 | lm loss: 2.576379E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40800/  200000 | consumed samples:      1305600 | elapsed time per iteration (ms): 254.3 | learning rate: 6.307E-05 | global batch size:    32 | lm loss: 2.630770E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40900/  200000 | consumed samples:      1308800 | elapsed time per iteration (ms): 255.5 | learning rate: 6.298E-05 | global batch size:    32 | lm loss: 2.466213E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41000/  200000 | consumed samples:      1312000 | elapsed time per iteration (ms): 258.5 | learning rate: 6.288E-05 | global batch size:    32 | lm loss: 2.877675E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41100/  200000 | consumed samples:      1315200 | elapsed time per iteration (ms): 266.8 | learning rate: 6.279E-05 | global batch size:    32 | lm loss: 2.596077E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41200/  200000 | consumed samples:      1318400 | elapsed time per iteration (ms): 265.7 | learning rate: 6.270E-05 | global batch size:    32 | lm loss: 2.553734E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41300/  200000 | consumed samples:      1321600 | elapsed time per iteration (ms): 255.1 | learning rate: 6.261E-05 | global batch size:    32 | lm loss: 2.662404E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41400/  200000 | consumed samples:      1324800 | elapsed time per iteration (ms): 257.3 | learning rate: 6.252E-05 | global batch size:    32 | lm loss: 2.447345E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41500/  200000 | consumed samples:      1328000 | elapsed time per iteration (ms): 255.8 | learning rate: 6.243E-05 | global batch size:    32 | lm loss: 2.434246E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41600/  200000 | consumed samples:      1331200 | elapsed time per iteration (ms): 267.4 | learning rate: 6.234E-05 | global batch size:    32 | lm loss: 2.507734E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41700/  200000 | consumed samples:      1334400 | elapsed time per iteration (ms): 253.1 | learning rate: 6.225E-05 | global batch size:    32 | lm loss: 2.493916E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41800/  200000 | consumed samples:      1337600 | elapsed time per iteration (ms): 254.6 | learning rate: 6.216E-05 | global batch size:    32 | lm loss: 2.477608E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41900/  200000 | consumed samples:      1340800 | elapsed time per iteration (ms): 265.4 | learning rate: 6.207E-05 | global batch size:    32 | lm loss: 2.540930E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42000/  200000 | consumed samples:      1344000 | elapsed time per iteration (ms): 253.9 | learning rate: 6.197E-05 | global batch size:    32 | lm loss: 2.594449E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    42100/  200000 | consumed samples:      1347200 | elapsed time per iteration (ms): 277.1 | learning rate: 6.188E-05 | global batch size:    32 | lm loss: 2.523232E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42200/  200000 | consumed samples:      1350400 | elapsed time per iteration (ms): 259.4 | learning rate: 6.179E-05 | global batch size:    32 | lm loss: 2.612299E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42300/  200000 | consumed samples:      1353600 | elapsed time per iteration (ms): 265.9 | learning rate: 6.170E-05 | global batch size:    32 | lm loss: 2.291540E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42400/  200000 | consumed samples:      1356800 | elapsed time per iteration (ms): 258.9 | learning rate: 6.161E-05 | global batch size:    32 | lm loss: 2.214965E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42500/  200000 | consumed samples:      1360000 | elapsed time per iteration (ms): 257.4 | learning rate: 6.152E-05 | global batch size:    32 | lm loss: 2.458867E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42600/  200000 | consumed samples:      1363200 | elapsed time per iteration (ms): 274.7 | learning rate: 6.143E-05 | global batch size:    32 | lm loss: 2.986703E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42700/  200000 | consumed samples:      1366400 | elapsed time per iteration (ms): 257.0 | learning rate: 6.134E-05 | global batch size:    32 | lm loss: 2.413318E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42800/  200000 | consumed samples:      1369600 | elapsed time per iteration (ms): 255.4 | learning rate: 6.125E-05 | global batch size:    32 | lm loss: 2.202203E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42900/  200000 | consumed samples:      1372800 | elapsed time per iteration (ms): 255.0 | learning rate: 6.116E-05 | global batch size:    32 | lm loss: 2.257679E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43000/  200000 | consumed samples:      1376000 | elapsed time per iteration (ms): 257.1 | learning rate: 6.106E-05 | global batch size:    32 | lm loss: 2.280255E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43100/  200000 | consumed samples:      1379200 | elapsed time per iteration (ms): 268.0 | learning rate: 6.097E-05 | global batch size:    32 | lm loss: 2.254189E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43200/  200000 | consumed samples:      1382400 | elapsed time per iteration (ms): 258.3 | learning rate: 6.088E-05 | global batch size:    32 | lm loss: 2.515436E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    43300/  200000 | consumed samples:      1385600 | elapsed time per iteration (ms): 258.9 | learning rate: 6.079E-05 | global batch size:    32 | lm loss: 2.379380E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43400/  200000 | consumed samples:      1388800 | elapsed time per iteration (ms): 270.6 | learning rate: 6.070E-05 | global batch size:    32 | lm loss: 2.385991E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43500/  200000 | consumed samples:      1392000 | elapsed time per iteration (ms): 264.4 | learning rate: 6.061E-05 | global batch size:    32 | lm loss: 2.388820E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43600/  200000 | consumed samples:      1395200 | elapsed time per iteration (ms): 266.8 | learning rate: 6.052E-05 | global batch size:    32 | lm loss: 2.312388E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43700/  200000 | consumed samples:      1398400 | elapsed time per iteration (ms): 254.7 | learning rate: 6.043E-05 | global batch size:    32 | lm loss: 2.331275E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43800/  200000 | consumed samples:      1401600 | elapsed time per iteration (ms): 254.4 | learning rate: 6.034E-05 | global batch size:    32 | lm loss: 2.264417E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43900/  200000 | consumed samples:      1404800 | elapsed time per iteration (ms): 252.1 | learning rate: 6.025E-05 | global batch size:    32 | lm loss: 2.255295E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44000/  200000 | consumed samples:      1408000 | elapsed time per iteration (ms): 255.7 | learning rate: 6.015E-05 | global batch size:    32 | lm loss: 2.328490E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44100/  200000 | consumed samples:      1411200 | elapsed time per iteration (ms): 273.3 | learning rate: 6.006E-05 | global batch size:    32 | lm loss: 2.732294E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44200/  200000 | consumed samples:      1414400 | elapsed time per iteration (ms): 255.5 | learning rate: 5.997E-05 | global batch size:    32 | lm loss: 2.459832E-05 | loss scale: 268435456.0 | grad norm: 0.006 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    44300/  200000 | consumed samples:      1417600 | elapsed time per iteration (ms): 254.9 | learning rate: 5.988E-05 | global batch size:    32 | lm loss: 2.550799E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    44400/  200000 | consumed samples:      1420800 | elapsed time per iteration (ms): 254.0 | learning rate: 5.979E-05 | global batch size:    32 | lm loss: 2.636926E-05 | loss scale: 134217728.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44500/  200000 | consumed samples:      1424000 | elapsed time per iteration (ms): 254.1 | learning rate: 5.970E-05 | global batch size:    32 | lm loss: 2.320636E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44600/  200000 | consumed samples:      1427200 | elapsed time per iteration (ms): 266.5 | learning rate: 5.961E-05 | global batch size:    32 | lm loss: 2.195895E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44700/  200000 | consumed samples:      1430400 | elapsed time per iteration (ms): 253.1 | learning rate: 5.952E-05 | global batch size:    32 | lm loss: 2.157882E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44800/  200000 | consumed samples:      1433600 | elapsed time per iteration (ms): 263.9 | learning rate: 5.943E-05 | global batch size:    32 | lm loss: 2.365279E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44900/  200000 | consumed samples:      1436800 | elapsed time per iteration (ms): 257.4 | learning rate: 5.934E-05 | global batch size:    32 | lm loss: 2.398243E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45000/  200000 | consumed samples:      1440000 | elapsed time per iteration (ms): 255.4 | learning rate: 5.925E-05 | global batch size:    32 | lm loss: 2.204650E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45100/  200000 | consumed samples:      1443200 | elapsed time per iteration (ms): 270.9 | learning rate: 5.915E-05 | global batch size:    32 | lm loss: 2.132077E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45200/  200000 | consumed samples:      1446400 | elapsed time per iteration (ms): 254.4 | learning rate: 5.906E-05 | global batch size:    32 | lm loss: 2.377024E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45300/  200000 | consumed samples:      1449600 | elapsed time per iteration (ms): 252.6 | learning rate: 5.897E-05 | global batch size:    32 | lm loss: 2.672298E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    45400/  200000 | consumed samples:      1452800 | elapsed time per iteration (ms): 255.0 | learning rate: 5.888E-05 | global batch size:    32 | lm loss: 2.263797E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45500/  200000 | consumed samples:      1456000 | elapsed time per iteration (ms): 257.5 | learning rate: 5.879E-05 | global batch size:    32 | lm loss: 2.297540E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45600/  200000 | consumed samples:      1459200 | elapsed time per iteration (ms): 283.0 | learning rate: 5.870E-05 | global batch size:    32 | lm loss: 2.258286E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45700/  200000 | consumed samples:      1462400 | elapsed time per iteration (ms): 259.5 | learning rate: 5.861E-05 | global batch size:    32 | lm loss: 2.114647E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45800/  200000 | consumed samples:      1465600 | elapsed time per iteration (ms): 256.0 | learning rate: 5.852E-05 | global batch size:    32 | lm loss: 2.158233E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45900/  200000 | consumed samples:      1468800 | elapsed time per iteration (ms): 257.3 | learning rate: 5.843E-05 | global batch size:    32 | lm loss: 2.141194E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46000/  200000 | consumed samples:      1472000 | elapsed time per iteration (ms): 262.5 | learning rate: 5.834E-05 | global batch size:    32 | lm loss: 2.059853E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46100/  200000 | consumed samples:      1475200 | elapsed time per iteration (ms): 267.6 | learning rate: 5.825E-05 | global batch size:    32 | lm loss: 2.075890E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46200/  200000 | consumed samples:      1478400 | elapsed time per iteration (ms): 256.9 | learning rate: 5.815E-05 | global batch size:    32 | lm loss: 2.322544E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46300/  200000 | consumed samples:      1481600 | elapsed time per iteration (ms): 267.0 | learning rate: 5.806E-05 | global batch size:    32 | lm loss: 2.104132E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46400/  200000 | consumed samples:      1484800 | elapsed time per iteration (ms): 255.4 | learning rate: 5.797E-05 | global batch size:    32 | lm loss: 2.098212E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46500/  200000 | consumed samples:      1488000 | elapsed time per iteration (ms): 256.5 | learning rate: 5.788E-05 | global batch size:    32 | lm loss: 2.105780E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    46600/  200000 | consumed samples:      1491200 | elapsed time per iteration (ms): 265.2 | learning rate: 5.779E-05 | global batch size:    32 | lm loss: 2.101477E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46700/  200000 | consumed samples:      1494400 | elapsed time per iteration (ms): 256.2 | learning rate: 5.770E-05 | global batch size:    32 | lm loss: 2.300920E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46800/  200000 | consumed samples:      1497600 | elapsed time per iteration (ms): 256.0 | learning rate: 5.761E-05 | global batch size:    32 | lm loss: 2.091091E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46900/  200000 | consumed samples:      1500800 | elapsed time per iteration (ms): 254.9 | learning rate: 5.752E-05 | global batch size:    32 | lm loss: 1.981506E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47000/  200000 | consumed samples:      1504000 | elapsed time per iteration (ms): 262.8 | learning rate: 5.743E-05 | global batch size:    32 | lm loss: 2.428154E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47100/  200000 | consumed samples:      1507200 | elapsed time per iteration (ms): 274.1 | learning rate: 5.734E-05 | global batch size:    32 | lm loss: 2.205726E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47200/  200000 | consumed samples:      1510400 | elapsed time per iteration (ms): 255.7 | learning rate: 5.725E-05 | global batch size:    32 | lm loss: 2.170036E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47300/  200000 | consumed samples:      1513600 | elapsed time per iteration (ms): 254.9 | learning rate: 5.715E-05 | global batch size:    32 | lm loss: 2.212700E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47400/  200000 | consumed samples:      1516800 | elapsed time per iteration (ms): 254.1 | learning rate: 5.706E-05 | global batch size:    32 | lm loss: 2.010640E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47500/  200000 | consumed samples:      1520000 | elapsed time per iteration (ms): 253.2 | learning rate: 5.697E-05 | global batch size:    32 | lm loss: 2.354332E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    47600/  200000 | consumed samples:      1523200 | elapsed time per iteration (ms): 267.8 | learning rate: 5.688E-05 | global batch size:    32 | lm loss: 2.142789E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47700/  200000 | consumed samples:      1526400 | elapsed time per iteration (ms): 254.6 | learning rate: 5.679E-05 | global batch size:    32 | lm loss: 2.027735E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47800/  200000 | consumed samples:      1529600 | elapsed time per iteration (ms): 264.6 | learning rate: 5.670E-05 | global batch size:    32 | lm loss: 2.051182E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47900/  200000 | consumed samples:      1532800 | elapsed time per iteration (ms): 253.3 | learning rate: 5.661E-05 | global batch size:    32 | lm loss: 2.069709E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48000/  200000 | consumed samples:      1536000 | elapsed time per iteration (ms): 254.2 | learning rate: 5.652E-05 | global batch size:    32 | lm loss: 2.064754E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48100/  200000 | consumed samples:      1539200 | elapsed time per iteration (ms): 267.3 | learning rate: 5.643E-05 | global batch size:    32 | lm loss: 2.130372E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48200/  200000 | consumed samples:      1542400 | elapsed time per iteration (ms): 254.2 | learning rate: 5.634E-05 | global batch size:    32 | lm loss: 2.109694E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48300/  200000 | consumed samples:      1545600 | elapsed time per iteration (ms): 254.5 | learning rate: 5.625E-05 | global batch size:    32 | lm loss: 2.225612E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48400/  200000 | consumed samples:      1548800 | elapsed time per iteration (ms): 259.8 | learning rate: 5.615E-05 | global batch size:    32 | lm loss: 2.112374E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48500/  200000 | consumed samples:      1552000 | elapsed time per iteration (ms): 267.5 | learning rate: 5.606E-05 | global batch size:    32 | lm loss: 2.171626E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48600/  200000 | consumed samples:      1555200 | elapsed time per iteration (ms): 269.8 | learning rate: 5.597E-05 | global batch size:    32 | lm loss: 2.172049E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    48700/  200000 | consumed samples:      1558400 | elapsed time per iteration (ms): 256.4 | learning rate: 5.588E-05 | global batch size:    32 | lm loss: 2.098429E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48800/  200000 | consumed samples:      1561600 | elapsed time per iteration (ms): 255.9 | learning rate: 5.579E-05 | global batch size:    32 | lm loss: 2.034380E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48900/  200000 | consumed samples:      1564800 | elapsed time per iteration (ms): 254.9 | learning rate: 5.570E-05 | global batch size:    32 | lm loss: 2.123879E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49000/  200000 | consumed samples:      1568000 | elapsed time per iteration (ms): 253.6 | learning rate: 5.561E-05 | global batch size:    32 | lm loss: 2.200196E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    49100/  200000 | consumed samples:      1571200 | elapsed time per iteration (ms): 271.2 | learning rate: 5.552E-05 | global batch size:    32 | lm loss: 2.046403E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49200/  200000 | consumed samples:      1574400 | elapsed time per iteration (ms): 268.0 | learning rate: 5.543E-05 | global batch size:    32 | lm loss: 2.062490E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49300/  200000 | consumed samples:      1577600 | elapsed time per iteration (ms): 256.2 | learning rate: 5.534E-05 | global batch size:    32 | lm loss: 2.163338E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49400/  200000 | consumed samples:      1580800 | elapsed time per iteration (ms): 254.6 | learning rate: 5.525E-05 | global batch size:    32 | lm loss: 1.904020E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49500/  200000 | consumed samples:      1584000 | elapsed time per iteration (ms): 256.7 | learning rate: 5.515E-05 | global batch size:    32 | lm loss: 1.980742E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49600/  200000 | consumed samples:      1587200 | elapsed time per iteration (ms): 265.6 | learning rate: 5.506E-05 | global batch size:    32 | lm loss: 2.024957E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49700/  200000 | consumed samples:      1590400 | elapsed time per iteration (ms): 262.2 | learning rate: 5.497E-05 | global batch size:    32 | lm loss: 1.906841E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49800/  200000 | consumed samples:      1593600 | elapsed time per iteration (ms): 254.7 | learning rate: 5.488E-05 | global batch size:    32 | lm loss: 1.932356E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49900/  200000 | consumed samples:      1596800 | elapsed time per iteration (ms): 259.2 | learning rate: 5.479E-05 | global batch size:    32 | lm loss: 2.023299E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50000/  200000 | consumed samples:      1600000 | elapsed time per iteration (ms): 268.3 | learning rate: 5.470E-05 | global batch size:    32 | lm loss: 2.107168E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50100/  200000 | consumed samples:      1603200 | elapsed time per iteration (ms): 596.6 | learning rate: 5.461E-05 | global batch size:    32 | lm loss: 1.918080E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50200/  200000 | consumed samples:      1606400 | elapsed time per iteration (ms): 253.3 | learning rate: 5.452E-05 | global batch size:    32 | lm loss: 1.869492E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50300/  200000 | consumed samples:      1609600 | elapsed time per iteration (ms): 254.5 | learning rate: 5.443E-05 | global batch size:    32 | lm loss: 1.972165E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    50400/  200000 | consumed samples:      1612800 | elapsed time per iteration (ms): 254.7 | learning rate: 5.434E-05 | global batch size:    32 | lm loss: 1.956498E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50500/  200000 | consumed samples:      1616000 | elapsed time per iteration (ms): 254.8 | learning rate: 5.425E-05 | global batch size:    32 | lm loss: 2.049542E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50600/  200000 | consumed samples:      1619200 | elapsed time per iteration (ms): 266.1 | learning rate: 5.415E-05 | global batch size:    32 | lm loss: 1.966597E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50700/  200000 | consumed samples:      1622400 | elapsed time per iteration (ms): 264.6 | learning rate: 5.406E-05 | global batch size:    32 | lm loss: 1.940590E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50800/  200000 | consumed samples:      1625600 | elapsed time per iteration (ms): 255.4 | learning rate: 5.397E-05 | global batch size:    32 | lm loss: 1.966077E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50100/  200000 | consumed samples:      1603200 | elapsed time per iteration (ms): 318.3 | learning rate: 5.461E-05 | global batch size:    32 | lm loss: 8.123324E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    50200/  200000 | consumed samples:      1606400 | elapsed time per iteration (ms): 263.5 | learning rate: 5.452E-05 | global batch size:    32 | lm loss: 7.488849E-05 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50300/  200000 | consumed samples:      1609600 | elapsed time per iteration (ms): 261.0 | learning rate: 5.443E-05 | global batch size:    32 | lm loss: 6.787899E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50400/  200000 | consumed samples:      1612800 | elapsed time per iteration (ms): 262.3 | learning rate: 5.434E-05 | global batch size:    32 | lm loss: 6.213984E-05 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50500/  200000 | consumed samples:      1616000 | elapsed time per iteration (ms): 263.6 | learning rate: 5.425E-05 | global batch size:    32 | lm loss: 5.875033E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50600/  200000 | consumed samples:      1619200 | elapsed time per iteration (ms): 272.4 | learning rate: 5.415E-05 | global batch size:    32 | lm loss: 3.472134E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50700/  200000 | consumed samples:      1622400 | elapsed time per iteration (ms): 261.1 | learning rate: 5.406E-05 | global batch size:    32 | lm loss: 3.325512E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50800/  200000 | consumed samples:      1625600 | elapsed time per iteration (ms): 257.4 | learning rate: 5.397E-05 | global batch size:    32 | lm loss: 3.433150E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50900/  200000 | consumed samples:      1628800 | elapsed time per iteration (ms): 261.5 | learning rate: 5.388E-05 | global batch size:    32 | lm loss: 3.347510E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51000/  200000 | consumed samples:      1632000 | elapsed time per iteration (ms): 257.2 | learning rate: 5.379E-05 | global batch size:    32 | lm loss: 3.251721E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51100/  200000 | consumed samples:      1635200 | elapsed time per iteration (ms): 271.5 | learning rate: 5.370E-05 | global batch size:    32 | lm loss: 3.246310E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51200/  200000 | consumed samples:      1638400 | elapsed time per iteration (ms): 260.5 | learning rate: 5.361E-05 | global batch size:    32 | lm loss: 3.263063E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51300/  200000 | consumed samples:      1641600 | elapsed time per iteration (ms): 258.6 | learning rate: 5.352E-05 | global batch size:    32 | lm loss: 3.215081E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51400/  200000 | consumed samples:      1644800 | elapsed time per iteration (ms): 258.5 | learning rate: 5.343E-05 | global batch size:    32 | lm loss: 3.282721E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51500/  200000 | consumed samples:      1648000 | elapsed time per iteration (ms): 258.6 | learning rate: 5.333E-05 | global batch size:    32 | lm loss: 3.243678E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51600/  200000 | consumed samples:      1651200 | elapsed time per iteration (ms): 280.6 | learning rate: 5.324E-05 | global batch size:    32 | lm loss: 3.231509E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51700/  200000 | consumed samples:      1654400 | elapsed time per iteration (ms): 260.5 | learning rate: 5.315E-05 | global batch size:    32 | lm loss: 3.162740E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51800/  200000 | consumed samples:      1657600 | elapsed time per iteration (ms): 259.4 | learning rate: 5.306E-05 | global batch size:    32 | lm loss: 3.268739E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51900/  200000 | consumed samples:      1660800 | elapsed time per iteration (ms): 259.0 | learning rate: 5.297E-05 | global batch size:    32 | lm loss: 3.162472E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52000/  200000 | consumed samples:      1664000 | elapsed time per iteration (ms): 257.8 | learning rate: 5.288E-05 | global batch size:    32 | lm loss: 3.314148E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52100/  200000 | consumed samples:      1667200 | elapsed time per iteration (ms): 272.0 | learning rate: 5.279E-05 | global batch size:    32 | lm loss: 3.178449E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52200/  200000 | consumed samples:      1670400 | elapsed time per iteration (ms): 260.4 | learning rate: 5.270E-05 | global batch size:    32 | lm loss: 3.119408E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52300/  200000 | consumed samples:      1673600 | elapsed time per iteration (ms): 265.9 | learning rate: 5.261E-05 | global batch size:    32 | lm loss: 3.109957E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52400/  200000 | consumed samples:      1676800 | elapsed time per iteration (ms): 259.4 | learning rate: 5.252E-05 | global batch size:    32 | lm loss: 3.117760E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52500/  200000 | consumed samples:      1680000 | elapsed time per iteration (ms): 260.1 | learning rate: 5.242E-05 | global batch size:    32 | lm loss: 3.263976E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52600/  200000 | consumed samples:      1683200 | elapsed time per iteration (ms): 272.2 | learning rate: 5.233E-05 | global batch size:    32 | lm loss: 3.230300E-05 | loss scale: 268435456.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52700/  200000 | consumed samples:      1686400 | elapsed time per iteration (ms): 256.3 | learning rate: 5.224E-05 | global batch size:    32 | lm loss: 3.140176E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52800/  200000 | consumed samples:      1689600 | elapsed time per iteration (ms): 259.1 | learning rate: 5.215E-05 | global batch size:    32 | lm loss: 3.099062E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52900/  200000 | consumed samples:      1692800 | elapsed time per iteration (ms): 256.2 | learning rate: 5.206E-05 | global batch size:    32 | lm loss: 3.143043E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53000/  200000 | consumed samples:      1696000 | elapsed time per iteration (ms): 259.6 | learning rate: 5.197E-05 | global batch size:    32 | lm loss: 3.130414E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53100/  200000 | consumed samples:      1699200 | elapsed time per iteration (ms): 280.9 | learning rate: 5.188E-05 | global batch size:    32 | lm loss: 3.465336E-05 | loss scale: 134217728.0 | grad norm: 0.010 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    53200/  200000 | consumed samples:      1702400 | elapsed time per iteration (ms): 266.2 | learning rate: 5.179E-05 | global batch size:    32 | lm loss: 2.903751E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53300/  200000 | consumed samples:      1705600 | elapsed time per iteration (ms): 261.9 | learning rate: 5.170E-05 | global batch size:    32 | lm loss: 2.816673E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53400/  200000 | consumed samples:      1708800 | elapsed time per iteration (ms): 260.5 | learning rate: 5.161E-05 | global batch size:    32 | lm loss: 2.789237E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53500/  200000 | consumed samples:      1712000 | elapsed time per iteration (ms): 260.4 | learning rate: 5.151E-05 | global batch size:    32 | lm loss: 2.757740E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53600/  200000 | consumed samples:      1715200 | elapsed time per iteration (ms): 273.4 | learning rate: 5.142E-05 | global batch size:    32 | lm loss: 2.838440E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53700/  200000 | consumed samples:      1718400 | elapsed time per iteration (ms): 261.0 | learning rate: 5.133E-05 | global batch size:    32 | lm loss: 2.802727E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53800/  200000 | consumed samples:      1721600 | elapsed time per iteration (ms): 268.1 | learning rate: 5.124E-05 | global batch size:    32 | lm loss: 2.865051E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53900/  200000 | consumed samples:      1724800 | elapsed time per iteration (ms): 263.1 | learning rate: 5.115E-05 | global batch size:    32 | lm loss: 2.813182E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54000/  200000 | consumed samples:      1728000 | elapsed time per iteration (ms): 261.8 | learning rate: 5.106E-05 | global batch size:    32 | lm loss: 2.888146E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54100/  200000 | consumed samples:      1731200 | elapsed time per iteration (ms): 274.9 | learning rate: 5.097E-05 | global batch size:    32 | lm loss: 2.894122E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    54200/  200000 | consumed samples:      1734400 | elapsed time per iteration (ms): 259.9 | learning rate: 5.088E-05 | global batch size:    32 | lm loss: 2.813402E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54300/  200000 | consumed samples:      1737600 | elapsed time per iteration (ms): 261.6 | learning rate: 5.079E-05 | global batch size:    32 | lm loss: 2.825975E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54400/  200000 | consumed samples:      1740800 | elapsed time per iteration (ms): 260.7 | learning rate: 5.070E-05 | global batch size:    32 | lm loss: 2.808478E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54500/  200000 | consumed samples:      1744000 | elapsed time per iteration (ms): 270.5 | learning rate: 5.061E-05 | global batch size:    32 | lm loss: 2.943445E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54600/  200000 | consumed samples:      1747200 | elapsed time per iteration (ms): 279.3 | learning rate: 5.051E-05 | global batch size:    32 | lm loss: 2.820653E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54700/  200000 | consumed samples:      1750400 | elapsed time per iteration (ms): 260.8 | learning rate: 5.042E-05 | global batch size:    32 | lm loss: 2.779802E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54800/  200000 | consumed samples:      1753600 | elapsed time per iteration (ms): 262.3 | learning rate: 5.033E-05 | global batch size:    32 | lm loss: 2.797994E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54900/  200000 | consumed samples:      1756800 | elapsed time per iteration (ms): 260.0 | learning rate: 5.024E-05 | global batch size:    32 | lm loss: 2.805470E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55000/  200000 | consumed samples:      1760000 | elapsed time per iteration (ms): 259.6 | learning rate: 5.015E-05 | global batch size:    32 | lm loss: 2.834374E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55100/  200000 | consumed samples:      1763200 | elapsed time per iteration (ms): 273.7 | learning rate: 5.006E-05 | global batch size:    32 | lm loss: 2.962947E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55200/  200000 | consumed samples:      1766400 | elapsed time per iteration (ms): 260.9 | learning rate: 4.997E-05 | global batch size:    32 | lm loss: 2.918822E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55300/  200000 | consumed samples:      1769600 | elapsed time per iteration (ms): 270.1 | learning rate: 4.988E-05 | global batch size:    32 | lm loss: 2.923745E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55400/  200000 | consumed samples:      1772800 | elapsed time per iteration (ms): 259.7 | learning rate: 4.979E-05 | global batch size:    32 | lm loss: 2.844932E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55500/  200000 | consumed samples:      1776000 | elapsed time per iteration (ms): 261.4 | learning rate: 4.969E-05 | global batch size:    32 | lm loss: 2.862107E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55600/  200000 | consumed samples:      1779200 | elapsed time per iteration (ms): 273.5 | learning rate: 4.960E-05 | global batch size:    32 | lm loss: 2.725533E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55700/  200000 | consumed samples:      1782400 | elapsed time per iteration (ms): 262.2 | learning rate: 4.951E-05 | global batch size:    32 | lm loss: 2.792501E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55800/  200000 | consumed samples:      1785600 | elapsed time per iteration (ms): 318.0 | learning rate: 4.942E-05 | global batch size:    32 | lm loss: 2.780663E-05 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    55900/  200000 | consumed samples:      1788800 | elapsed time per iteration (ms): 259.8 | learning rate: 4.933E-05 | global batch size:    32 | lm loss: 2.977312E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    56000/  200000 | consumed samples:      1792000 | elapsed time per iteration (ms): 267.4 | learning rate: 4.924E-05 | global batch size:    32 | lm loss: 2.764676E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56100/  200000 | consumed samples:      1795200 | elapsed time per iteration (ms): 276.1 | learning rate: 4.915E-05 | global batch size:    32 | lm loss: 2.993342E-05 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56200/  200000 | consumed samples:      1798400 | elapsed time per iteration (ms): 258.2 | learning rate: 4.906E-05 | global batch size:    32 | lm loss: 2.982242E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56300/  200000 | consumed samples:      1801600 | elapsed time per iteration (ms): 265.5 | learning rate: 4.897E-05 | global batch size:    32 | lm loss: 2.596006E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56400/  200000 | consumed samples:      1804800 | elapsed time per iteration (ms): 261.8 | learning rate: 4.888E-05 | global batch size:    32 | lm loss: 2.569772E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56500/  200000 | consumed samples:      1808000 | elapsed time per iteration (ms): 259.0 | learning rate: 4.879E-05 | global batch size:    32 | lm loss: 2.591957E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56600/  200000 | consumed samples:      1811200 | elapsed time per iteration (ms): 271.9 | learning rate: 4.869E-05 | global batch size:    32 | lm loss: 2.482409E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56700/  200000 | consumed samples:      1814400 | elapsed time per iteration (ms): 275.0 | learning rate: 4.860E-05 | global batch size:    32 | lm loss: 2.498831E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56800/  200000 | consumed samples:      1817600 | elapsed time per iteration (ms): 260.5 | learning rate: 4.851E-05 | global batch size:    32 | lm loss: 2.493582E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56900/  200000 | consumed samples:      1820800 | elapsed time per iteration (ms): 260.0 | learning rate: 4.842E-05 | global batch size:    32 | lm loss: 2.512801E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57000/  200000 | consumed samples:      1824000 | elapsed time per iteration (ms): 260.0 | learning rate: 4.833E-05 | global batch size:    32 | lm loss: 2.585618E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    57100/  200000 | consumed samples:      1827200 | elapsed time per iteration (ms): 272.8 | learning rate: 4.824E-05 | global batch size:    32 | lm loss: 2.661275E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57200/  200000 | consumed samples:      1830400 | elapsed time per iteration (ms): 261.4 | learning rate: 4.815E-05 | global batch size:    32 | lm loss: 2.510416E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57300/  200000 | consumed samples:      1833600 | elapsed time per iteration (ms): 259.2 | learning rate: 4.806E-05 | global batch size:    32 | lm loss: 2.559251E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57400/  200000 | consumed samples:      1836800 | elapsed time per iteration (ms): 266.8 | learning rate: 4.797E-05 | global batch size:    32 | lm loss: 2.581820E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57500/  200000 | consumed samples:      1840000 | elapsed time per iteration (ms): 264.6 | learning rate: 4.788E-05 | global batch size:    32 | lm loss: 2.932741E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57600/  200000 | consumed samples:      1843200 | elapsed time per iteration (ms): 274.3 | learning rate: 4.778E-05 | global batch size:    32 | lm loss: 2.491346E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57700/  200000 | consumed samples:      1846400 | elapsed time per iteration (ms): 261.1 | learning rate: 4.769E-05 | global batch size:    32 | lm loss: 2.517662E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57800/  200000 | consumed samples:      1849600 | elapsed time per iteration (ms): 259.9 | learning rate: 4.760E-05 | global batch size:    32 | lm loss: 2.551745E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    57900/  200000 | consumed samples:      1852800 | elapsed time per iteration (ms): 260.2 | learning rate: 4.751E-05 | global batch size:    32 | lm loss: 2.634928E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58000/  200000 | consumed samples:      1856000 | elapsed time per iteration (ms): 259.9 | learning rate: 4.742E-05 | global batch size:    32 | lm loss: 2.571857E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58100/  200000 | consumed samples:      1859200 | elapsed time per iteration (ms): 272.1 | learning rate: 4.733E-05 | global batch size:    32 | lm loss: 2.542329E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58200/  200000 | consumed samples:      1862400 | elapsed time per iteration (ms): 272.6 | learning rate: 4.724E-05 | global batch size:    32 | lm loss: 2.507678E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58300/  200000 | consumed samples:      1865600 | elapsed time per iteration (ms): 261.8 | learning rate: 4.715E-05 | global batch size:    32 | lm loss: 2.495010E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58400/  200000 | consumed samples:      1868800 | elapsed time per iteration (ms): 259.4 | learning rate: 4.706E-05 | global batch size:    32 | lm loss: 2.536243E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58500/  200000 | consumed samples:      1872000 | elapsed time per iteration (ms): 257.9 | learning rate: 4.697E-05 | global batch size:    32 | lm loss: 2.535489E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58600/  200000 | consumed samples:      1875200 | elapsed time per iteration (ms): 276.2 | learning rate: 4.688E-05 | global batch size:    32 | lm loss: 2.491993E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58700/  200000 | consumed samples:      1878400 | elapsed time per iteration (ms): 258.8 | learning rate: 4.678E-05 | global batch size:    32 | lm loss: 2.577455E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58800/  200000 | consumed samples:      1881600 | elapsed time per iteration (ms): 258.4 | learning rate: 4.669E-05 | global batch size:    32 | lm loss: 2.729534E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58900/  200000 | consumed samples:      1884800 | elapsed time per iteration (ms): 274.3 | learning rate: 4.660E-05 | global batch size:    32 | lm loss: 2.709678E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59000/  200000 | consumed samples:      1888000 | elapsed time per iteration (ms): 257.2 | learning rate: 4.651E-05 | global batch size:    32 | lm loss: 2.667556E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59100/  200000 | consumed samples:      1891200 | elapsed time per iteration (ms): 276.6 | learning rate: 4.642E-05 | global batch size:    32 | lm loss: 2.617151E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59200/  200000 | consumed samples:      1894400 | elapsed time per iteration (ms): 260.0 | learning rate: 4.633E-05 | global batch size:    32 | lm loss: 2.564677E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59300/  200000 | consumed samples:      1897600 | elapsed time per iteration (ms): 262.3 | learning rate: 4.624E-05 | global batch size:    32 | lm loss: 2.581307E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59400/  200000 | consumed samples:      1900800 | elapsed time per iteration (ms): 266.1 | learning rate: 4.615E-05 | global batch size:    32 | lm loss: 2.512352E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59500/  200000 | consumed samples:      1904000 | elapsed time per iteration (ms): 261.4 | learning rate: 4.606E-05 | global batch size:    32 | lm loss: 2.361006E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59600/  200000 | consumed samples:      1907200 | elapsed time per iteration (ms): 285.8 | learning rate: 4.596E-05 | global batch size:    32 | lm loss: 2.354023E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59700/  200000 | consumed samples:      1910400 | elapsed time per iteration (ms): 259.8 | learning rate: 4.587E-05 | global batch size:    32 | lm loss: 2.315369E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59800/  200000 | consumed samples:      1913600 | elapsed time per iteration (ms): 260.9 | learning rate: 4.578E-05 | global batch size:    32 | lm loss: 2.310093E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59900/  200000 | consumed samples:      1916800 | elapsed time per iteration (ms): 262.3 | learning rate: 4.569E-05 | global batch size:    32 | lm loss: 2.292813E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60000/  200000 | consumed samples:      1920000 | elapsed time per iteration (ms): 261.1 | learning rate: 4.560E-05 | global batch size:    32 | lm loss: 2.340478E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60100/  200000 | consumed samples:      1923200 | elapsed time per iteration (ms): 518.6 | learning rate: 4.551E-05 | global batch size:    32 | lm loss: 2.325891E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60200/  200000 | consumed samples:      1926400 | elapsed time per iteration (ms): 260.3 | learning rate: 4.542E-05 | global batch size:    32 | lm loss: 2.323302E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60300/  200000 | consumed samples:      1929600 | elapsed time per iteration (ms): 260.0 | learning rate: 4.533E-05 | global batch size:    32 | lm loss: 2.350875E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    60400/  200000 | consumed samples:      1932800 | elapsed time per iteration (ms): 270.5 | learning rate: 4.524E-05 | global batch size:    32 | lm loss: 2.389142E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60500/  200000 | consumed samples:      1936000 | elapsed time per iteration (ms): 260.3 | learning rate: 4.515E-05 | global batch size:    32 | lm loss: 2.482510E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60600/  200000 | consumed samples:      1939200 | elapsed time per iteration (ms): 277.6 | learning rate: 4.506E-05 | global batch size:    32 | lm loss: 2.641748E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60700/  200000 | consumed samples:      1942400 | elapsed time per iteration (ms): 260.6 | learning rate: 4.496E-05 | global batch size:    32 | lm loss: 2.294442E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60800/  200000 | consumed samples:      1945600 | elapsed time per iteration (ms): 262.3 | learning rate: 4.487E-05 | global batch size:    32 | lm loss: 2.296686E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60900/  200000 | consumed samples:      1948800 | elapsed time per iteration (ms): 259.7 | learning rate: 4.478E-05 | global batch size:    32 | lm loss: 2.342934E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61000/  200000 | consumed samples:      1952000 | elapsed time per iteration (ms): 258.3 | learning rate: 4.469E-05 | global batch size:    32 | lm loss: 2.308835E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61100/  200000 | consumed samples:      1955200 | elapsed time per iteration (ms): 282.9 | learning rate: 4.460E-05 | global batch size:    32 | lm loss: 2.367272E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61200/  200000 | consumed samples:      1958400 | elapsed time per iteration (ms): 261.1 | learning rate: 4.451E-05 | global batch size:    32 | lm loss: 2.322854E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61300/  200000 | consumed samples:      1961600 | elapsed time per iteration (ms): 260.3 | learning rate: 4.442E-05 | global batch size:    32 | lm loss: 2.465101E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    61400/  200000 | consumed samples:      1964800 | elapsed time per iteration (ms): 260.1 | learning rate: 4.433E-05 | global batch size:    32 | lm loss: 2.337756E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61500/  200000 | consumed samples:      1968000 | elapsed time per iteration (ms): 260.3 | learning rate: 4.424E-05 | global batch size:    32 | lm loss: 2.322491E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61600/  200000 | consumed samples:      1971200 | elapsed time per iteration (ms): 273.8 | learning rate: 4.415E-05 | global batch size:    32 | lm loss: 2.327957E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61700/  200000 | consumed samples:      1974400 | elapsed time per iteration (ms): 259.5 | learning rate: 4.406E-05 | global batch size:    32 | lm loss: 2.383987E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61800/  200000 | consumed samples:      1977600 | elapsed time per iteration (ms): 269.9 | learning rate: 4.396E-05 | global batch size:    32 | lm loss: 2.620535E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61900/  200000 | consumed samples:      1980800 | elapsed time per iteration (ms): 259.1 | learning rate: 4.387E-05 | global batch size:    32 | lm loss: 2.322281E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62000/  200000 | consumed samples:      1984000 | elapsed time per iteration (ms): 258.3 | learning rate: 4.378E-05 | global batch size:    32 | lm loss: 2.327476E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62100/  200000 | consumed samples:      1987200 | elapsed time per iteration (ms): 271.5 | learning rate: 4.369E-05 | global batch size:    32 | lm loss: 2.342999E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62200/  200000 | consumed samples:      1990400 | elapsed time per iteration (ms): 262.7 | learning rate: 4.360E-05 | global batch size:    32 | lm loss: 2.389905E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62300/  200000 | consumed samples:      1993600 | elapsed time per iteration (ms): 258.8 | learning rate: 4.351E-05 | global batch size:    32 | lm loss: 2.363089E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62400/  200000 | consumed samples:      1996800 | elapsed time per iteration (ms): 261.3 | learning rate: 4.342E-05 | global batch size:    32 | lm loss: 2.343121E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62500/  200000 | consumed samples:      2000000 | elapsed time per iteration (ms): 259.9 | learning rate: 4.333E-05 | global batch size:    32 | lm loss: 2.342746E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62600/  200000 | consumed samples:      2003200 | elapsed time per iteration (ms): 291.5 | learning rate: 4.324E-05 | global batch size:    32 | lm loss: 2.086816E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62700/  200000 | consumed samples:      2006400 | elapsed time per iteration (ms): 256.4 | learning rate: 4.315E-05 | global batch size:    32 | lm loss: 2.096928E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    62800/  200000 | consumed samples:      2009600 | elapsed time per iteration (ms): 260.6 | learning rate: 4.306E-05 | global batch size:    32 | lm loss: 2.249669E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62900/  200000 | consumed samples:      2012800 | elapsed time per iteration (ms): 261.3 | learning rate: 4.296E-05 | global batch size:    32 | lm loss: 2.136679E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63000/  200000 | consumed samples:      2016000 | elapsed time per iteration (ms): 261.2 | learning rate: 4.287E-05 | global batch size:    32 | lm loss: 2.119223E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63100/  200000 | consumed samples:      2019200 | elapsed time per iteration (ms): 272.7 | learning rate: 4.278E-05 | global batch size:    32 | lm loss: 2.109770E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    63200/  200000 | consumed samples:      2022400 | elapsed time per iteration (ms): 260.9 | learning rate: 4.269E-05 | global batch size:    32 | lm loss: 2.125927E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63300/  200000 | consumed samples:      2025600 | elapsed time per iteration (ms): 267.6 | learning rate: 4.260E-05 | global batch size:    32 | lm loss: 2.105846E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63400/  200000 | consumed samples:      2028800 | elapsed time per iteration (ms): 259.4 | learning rate: 4.251E-05 | global batch size:    32 | lm loss: 2.216850E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63500/  200000 | consumed samples:      2032000 | elapsed time per iteration (ms): 258.7 | learning rate: 4.242E-05 | global batch size:    32 | lm loss: 3.045109E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63600/  200000 | consumed samples:      2035200 | elapsed time per iteration (ms): 271.3 | learning rate: 4.233E-05 | global batch size:    32 | lm loss: 2.186522E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63700/  200000 | consumed samples:      2038400 | elapsed time per iteration (ms): 259.0 | learning rate: 4.224E-05 | global batch size:    32 | lm loss: 2.096179E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63800/  200000 | consumed samples:      2041600 | elapsed time per iteration (ms): 261.7 | learning rate: 4.215E-05 | global batch size:    32 | lm loss: 2.105513E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63900/  200000 | consumed samples:      2044800 | elapsed time per iteration (ms): 260.9 | learning rate: 4.205E-05 | global batch size:    32 | lm loss: 2.109443E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64000/  200000 | consumed samples:      2048000 | elapsed time per iteration (ms): 270.6 | learning rate: 4.196E-05 | global batch size:    32 | lm loss: 2.108086E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64100/  200000 | consumed samples:      2051200 | elapsed time per iteration (ms): 278.0 | learning rate: 4.187E-05 | global batch size:    32 | lm loss: 2.133687E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64200/  200000 | consumed samples:      2054400 | elapsed time per iteration (ms): 316.0 | learning rate: 4.178E-05 | global batch size:    32 | lm loss: 2.152659E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64300/  200000 | consumed samples:      2057600 | elapsed time per iteration (ms): 261.1 | learning rate: 4.169E-05 | global batch size:    32 | lm loss: 2.138970E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64400/  200000 | consumed samples:      2060800 | elapsed time per iteration (ms): 263.0 | learning rate: 4.160E-05 | global batch size:    32 | lm loss: 2.131275E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64500/  200000 | consumed samples:      2064000 | elapsed time per iteration (ms): 261.5 | learning rate: 4.151E-05 | global batch size:    32 | lm loss: 2.125519E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64600/  200000 | consumed samples:      2067200 | elapsed time per iteration (ms): 270.0 | learning rate: 4.142E-05 | global batch size:    32 | lm loss: 2.172010E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64700/  200000 | consumed samples:      2070400 | elapsed time per iteration (ms): 259.3 | learning rate: 4.133E-05 | global batch size:    32 | lm loss: 2.215667E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64800/  200000 | consumed samples:      2073600 | elapsed time per iteration (ms): 266.8 | learning rate: 4.123E-05 | global batch size:    32 | lm loss: 2.149902E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64900/  200000 | consumed samples:      2076800 | elapsed time per iteration (ms): 258.9 | learning rate: 4.114E-05 | global batch size:    32 | lm loss: 2.179006E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65000/  200000 | consumed samples:      2080000 | elapsed time per iteration (ms): 259.8 | learning rate: 4.105E-05 | global batch size:    32 | lm loss: 2.188279E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65100/  200000 | consumed samples:      2083200 | elapsed time per iteration (ms): 270.0 | learning rate: 4.096E-05 | global batch size:    32 | lm loss: 2.209616E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65200/  200000 | consumed samples:      2086400 | elapsed time per iteration (ms): 258.7 | learning rate: 4.087E-05 | global batch size:    32 | lm loss: 2.238227E-05 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    65300/  200000 | consumed samples:      2089600 | elapsed time per iteration (ms): 258.5 | learning rate: 4.078E-05 | global batch size:    32 | lm loss: 2.224753E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    65400/  200000 | consumed samples:      2092800 | elapsed time per iteration (ms): 257.4 | learning rate: 4.069E-05 | global batch size:    32 | lm loss: 2.175291E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65500/  200000 | consumed samples:      2096000 | elapsed time per iteration (ms): 266.1 | learning rate: 4.060E-05 | global batch size:    32 | lm loss: 2.172250E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65600/  200000 | consumed samples:      2099200 | elapsed time per iteration (ms): 274.3 | learning rate: 4.051E-05 | global batch size:    32 | lm loss: 2.172253E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65700/  200000 | consumed samples:      2102400 | elapsed time per iteration (ms): 266.2 | learning rate: 4.042E-05 | global batch size:    32 | lm loss: 1.998038E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65800/  200000 | consumed samples:      2105600 | elapsed time per iteration (ms): 262.5 | learning rate: 4.033E-05 | global batch size:    32 | lm loss: 1.945800E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65900/  200000 | consumed samples:      2108800 | elapsed time per iteration (ms): 260.0 | learning rate: 4.023E-05 | global batch size:    32 | lm loss: 1.989139E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66000/  200000 | consumed samples:      2112000 | elapsed time per iteration (ms): 262.9 | learning rate: 4.014E-05 | global batch size:    32 | lm loss: 1.971383E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66100/  200000 | consumed samples:      2115200 | elapsed time per iteration (ms): 273.6 | learning rate: 4.005E-05 | global batch size:    32 | lm loss: 1.929818E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66200/  200000 | consumed samples:      2118400 | elapsed time per iteration (ms): 271.5 | learning rate: 3.996E-05 | global batch size:    32 | lm loss: 1.960383E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66300/  200000 | consumed samples:      2121600 | elapsed time per iteration (ms): 259.9 | learning rate: 3.987E-05 | global batch size:    32 | lm loss: 1.955840E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66400/  200000 | consumed samples:      2124800 | elapsed time per iteration (ms): 260.8 | learning rate: 3.978E-05 | global batch size:    32 | lm loss: 1.932245E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66500/  200000 | consumed samples:      2128000 | elapsed time per iteration (ms): 259.8 | learning rate: 3.969E-05 | global batch size:    32 | lm loss: 1.991286E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66600/  200000 | consumed samples:      2131200 | elapsed time per iteration (ms): 273.6 | learning rate: 3.960E-05 | global batch size:    32 | lm loss: 1.965008E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66700/  200000 | consumed samples:      2134400 | elapsed time per iteration (ms): 259.4 | learning rate: 3.951E-05 | global batch size:    32 | lm loss: 2.031946E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66800/  200000 | consumed samples:      2137600 | elapsed time per iteration (ms): 259.2 | learning rate: 3.941E-05 | global batch size:    32 | lm loss: 2.012395E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66900/  200000 | consumed samples:      2140800 | elapsed time per iteration (ms): 265.6 | learning rate: 3.932E-05 | global batch size:    32 | lm loss: 2.067143E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67000/  200000 | consumed samples:      2144000 | elapsed time per iteration (ms): 263.8 | learning rate: 3.923E-05 | global batch size:    32 | lm loss: 2.003870E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67100/  200000 | consumed samples:      2147200 | elapsed time per iteration (ms): 274.4 | learning rate: 3.914E-05 | global batch size:    32 | lm loss: 1.995670E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67200/  200000 | consumed samples:      2150400 | elapsed time per iteration (ms): 261.1 | learning rate: 3.905E-05 | global batch size:    32 | lm loss: 1.953064E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67300/  200000 | consumed samples:      2153600 | elapsed time per iteration (ms): 259.0 | learning rate: 3.896E-05 | global batch size:    32 | lm loss: 1.972827E-05 | loss scale: 536870912.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67400/  200000 | consumed samples:      2156800 | elapsed time per iteration (ms): 257.9 | learning rate: 3.887E-05 | global batch size:    32 | lm loss: 1.999813E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    67500/  200000 | consumed samples:      2160000 | elapsed time per iteration (ms): 260.3 | learning rate: 3.878E-05 | global batch size:    32 | lm loss: 2.029142E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67600/  200000 | consumed samples:      2163200 | elapsed time per iteration (ms): 271.0 | learning rate: 3.869E-05 | global batch size:    32 | lm loss: 2.069764E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67700/  200000 | consumed samples:      2166400 | elapsed time per iteration (ms): 271.7 | learning rate: 3.860E-05 | global batch size:    32 | lm loss: 2.002415E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67800/  200000 | consumed samples:      2169600 | elapsed time per iteration (ms): 259.3 | learning rate: 3.851E-05 | global batch size:    32 | lm loss: 2.046265E-05 | loss scale: 268435456.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67900/  200000 | consumed samples:      2172800 | elapsed time per iteration (ms): 259.5 | learning rate: 3.842E-05 | global batch size:    32 | lm loss: 2.237202E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    68000/  200000 | consumed samples:      2176000 | elapsed time per iteration (ms): 260.1 | learning rate: 3.832E-05 | global batch size:    32 | lm loss: 2.020336E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68100/  200000 | consumed samples:      2179200 | elapsed time per iteration (ms): 271.0 | learning rate: 3.823E-05 | global batch size:    32 | lm loss: 1.993208E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68200/  200000 | consumed samples:      2182400 | elapsed time per iteration (ms): 262.9 | learning rate: 3.814E-05 | global batch size:    32 | lm loss: 2.007221E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68300/  200000 | consumed samples:      2185600 | elapsed time per iteration (ms): 258.6 | learning rate: 3.805E-05 | global batch size:    32 | lm loss: 1.994406E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68400/  200000 | consumed samples:      2188800 | elapsed time per iteration (ms): 270.7 | learning rate: 3.796E-05 | global batch size:    32 | lm loss: 2.003538E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68500/  200000 | consumed samples:      2192000 | elapsed time per iteration (ms): 260.3 | learning rate: 3.787E-05 | global batch size:    32 | lm loss: 2.003283E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68600/  200000 | consumed samples:      2195200 | elapsed time per iteration (ms): 274.4 | learning rate: 3.778E-05 | global batch size:    32 | lm loss: 2.012900E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68700/  200000 | consumed samples:      2198400 | elapsed time per iteration (ms): 258.6 | learning rate: 3.769E-05 | global batch size:    32 | lm loss: 2.016122E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68800/  200000 | consumed samples:      2201600 | elapsed time per iteration (ms): 265.8 | learning rate: 3.760E-05 | global batch size:    32 | lm loss: 1.899425E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68900/  200000 | consumed samples:      2204800 | elapsed time per iteration (ms): 260.6 | learning rate: 3.750E-05 | global batch size:    32 | lm loss: 1.821964E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69000/  200000 | consumed samples:      2208000 | elapsed time per iteration (ms): 261.6 | learning rate: 3.741E-05 | global batch size:    32 | lm loss: 1.820068E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69100/  200000 | consumed samples:      2211200 | elapsed time per iteration (ms): 283.8 | learning rate: 3.732E-05 | global batch size:    32 | lm loss: 1.837271E-05 | loss scale: 268435456.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69200/  200000 | consumed samples:      2214400 | elapsed time per iteration (ms): 262.6 | learning rate: 3.723E-05 | global batch size:    32 | lm loss: 1.830768E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69300/  200000 | consumed samples:      2217600 | elapsed time per iteration (ms): 261.2 | learning rate: 3.714E-05 | global batch size:    32 | lm loss: 1.794778E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69400/  200000 | consumed samples:      2220800 | elapsed time per iteration (ms): 260.8 | learning rate: 3.705E-05 | global batch size:    32 | lm loss: 1.789028E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69500/  200000 | consumed samples:      2224000 | elapsed time per iteration (ms): 260.9 | learning rate: 3.696E-05 | global batch size:    32 | lm loss: 1.789166E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69600/  200000 | consumed samples:      2227200 | elapsed time per iteration (ms): 274.4 | learning rate: 3.687E-05 | global batch size:    32 | lm loss: 1.811014E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69700/  200000 | consumed samples:      2230400 | elapsed time per iteration (ms): 259.2 | learning rate: 3.678E-05 | global batch size:    32 | lm loss: 1.809375E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    69800/  200000 | consumed samples:      2233600 | elapsed time per iteration (ms): 259.7 | learning rate: 3.669E-05 | global batch size:    32 | lm loss: 1.849156E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69900/  200000 | consumed samples:      2236800 | elapsed time per iteration (ms): 274.8 | learning rate: 3.660E-05 | global batch size:    32 | lm loss: 1.852069E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70000/  200000 | consumed samples:      2240000 | elapsed time per iteration (ms): 260.1 | learning rate: 3.650E-05 | global batch size:    32 | lm loss: 2.031122E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70100/  200000 | consumed samples:      2243200 | elapsed time per iteration (ms): 276.4 | learning rate: 3.641E-05 | global batch size:    32 | lm loss: 1.841026E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70200/  200000 | consumed samples:      2246400 | elapsed time per iteration (ms): 259.1 | learning rate: 3.632E-05 | global batch size:    32 | lm loss: 1.818016E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70300/  200000 | consumed samples:      2249600 | elapsed time per iteration (ms): 258.1 | learning rate: 3.623E-05 | global batch size:    32 | lm loss: 1.865057E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70400/  200000 | consumed samples:      2252800 | elapsed time per iteration (ms): 259.9 | learning rate: 3.614E-05 | global batch size:    32 | lm loss: 1.829233E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70500/  200000 | consumed samples:      2256000 | elapsed time per iteration (ms): 259.5 | learning rate: 3.605E-05 | global batch size:    32 | lm loss: 1.833366E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70600/  200000 | consumed samples:      2259200 | elapsed time per iteration (ms): 287.2 | learning rate: 3.596E-05 | global batch size:    32 | lm loss: 1.872492E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70700/  200000 | consumed samples:      2262400 | elapsed time per iteration (ms): 259.9 | learning rate: 3.587E-05 | global batch size:    32 | lm loss: 1.878351E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70800/  200000 | consumed samples:      2265600 | elapsed time per iteration (ms): 261.3 | learning rate: 3.578E-05 | global batch size:    32 | lm loss: 1.838334E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70900/  200000 | consumed samples:      2268800 | elapsed time per iteration (ms): 262.4 | learning rate: 3.568E-05 | global batch size:    32 | lm loss: 1.840315E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71000/  200000 | consumed samples:      2272000 | elapsed time per iteration (ms): 259.9 | learning rate: 3.559E-05 | global batch size:    32 | lm loss: 1.846827E-05 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    71100/  200000 | consumed samples:      2275200 | elapsed time per iteration (ms): 274.9 | learning rate: 3.550E-05 | global batch size:    32 | lm loss: 1.883873E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    71200/  200000 | consumed samples:      2278400 | elapsed time per iteration (ms): 259.8 | learning rate: 3.541E-05 | global batch size:    32 | lm loss: 1.858866E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71300/  200000 | consumed samples:      2281600 | elapsed time per iteration (ms): 271.5 | learning rate: 3.532E-05 | global batch size:    32 | lm loss: 1.887027E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71400/  200000 | consumed samples:      2284800 | elapsed time per iteration (ms): 265.4 | learning rate: 3.523E-05 | global batch size:    32 | lm loss: 1.921660E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71500/  200000 | consumed samples:      2288000 | elapsed time per iteration (ms): 258.8 | learning rate: 3.514E-05 | global batch size:    32 | lm loss: 1.848199E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71600/  200000 | consumed samples:      2291200 | elapsed time per iteration (ms): 276.7 | learning rate: 3.505E-05 | global batch size:    32 | lm loss: 1.921345E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71700/  200000 | consumed samples:      2294400 | elapsed time per iteration (ms): 258.1 | learning rate: 3.496E-05 | global batch size:    32 | lm loss: 1.930100E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71800/  200000 | consumed samples:      2297600 | elapsed time per iteration (ms): 261.1 | learning rate: 3.487E-05 | global batch size:    32 | lm loss: 1.843644E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71900/  200000 | consumed samples:      2300800 | elapsed time per iteration (ms): 267.6 | learning rate: 3.478E-05 | global batch size:    32 | lm loss: 1.842766E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72000/  200000 | consumed samples:      2304000 | elapsed time per iteration (ms): 262.5 | learning rate: 3.468E-05 | global batch size:    32 | lm loss: 1.727141E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72100/  200000 | consumed samples:      2307200 | elapsed time per iteration (ms): 288.1 | learning rate: 3.459E-05 | global batch size:    32 | lm loss: 1.709724E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72200/  200000 | consumed samples:      2310400 | elapsed time per iteration (ms): 260.1 | learning rate: 3.450E-05 | global batch size:    32 | lm loss: 1.666485E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72300/  200000 | consumed samples:      2313600 | elapsed time per iteration (ms): 261.5 | learning rate: 3.441E-05 | global batch size:    32 | lm loss: 1.677853E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72400/  200000 | consumed samples:      2316800 | elapsed time per iteration (ms): 263.3 | learning rate: 3.432E-05 | global batch size:    32 | lm loss: 1.655460E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72500/  200000 | consumed samples:      2320000 | elapsed time per iteration (ms): 261.7 | learning rate: 3.423E-05 | global batch size:    32 | lm loss: 1.696475E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72600/  200000 | consumed samples:      2323200 | elapsed time per iteration (ms): 274.0 | learning rate: 3.414E-05 | global batch size:    32 | lm loss: 1.731229E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72700/  200000 | consumed samples:      2326400 | elapsed time per iteration (ms): 325.6 | learning rate: 3.405E-05 | global batch size:    32 | lm loss: 1.739082E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72800/  200000 | consumed samples:      2329600 | elapsed time per iteration (ms): 276.4 | learning rate: 3.396E-05 | global batch size:    32 | lm loss: 1.693563E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72900/  200000 | consumed samples:      2332800 | elapsed time per iteration (ms): 263.4 | learning rate: 3.386E-05 | global batch size:    32 | lm loss: 1.705076E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73000/  200000 | consumed samples:      2336000 | elapsed time per iteration (ms): 261.2 | learning rate: 3.377E-05 | global batch size:    32 | lm loss: 1.707205E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73100/  200000 | consumed samples:      2339200 | elapsed time per iteration (ms): 274.8 | learning rate: 3.368E-05 | global batch size:    32 | lm loss: 1.738409E-05 | loss scale: 536870912.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    73200/  200000 | consumed samples:      2342400 | elapsed time per iteration (ms): 257.2 | learning rate: 3.359E-05 | global batch size:    32 | lm loss: 1.781793E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    73300/  200000 | consumed samples:      2345600 | elapsed time per iteration (ms): 258.3 | learning rate: 3.350E-05 | global batch size:    32 | lm loss: 1.722175E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73400/  200000 | consumed samples:      2348800 | elapsed time per iteration (ms): 260.2 | learning rate: 3.341E-05 | global batch size:    32 | lm loss: 1.691673E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73500/  200000 | consumed samples:      2352000 | elapsed time per iteration (ms): 270.4 | learning rate: 3.332E-05 | global batch size:    32 | lm loss: 1.746073E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73600/  200000 | consumed samples:      2355200 | elapsed time per iteration (ms): 272.6 | learning rate: 3.323E-05 | global batch size:    32 | lm loss: 1.724582E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73700/  200000 | consumed samples:      2358400 | elapsed time per iteration (ms): 258.5 | learning rate: 3.314E-05 | global batch size:    32 | lm loss: 1.746459E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73800/  200000 | consumed samples:      2361600 | elapsed time per iteration (ms): 257.7 | learning rate: 3.305E-05 | global batch size:    32 | lm loss: 1.736285E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73900/  200000 | consumed samples:      2364800 | elapsed time per iteration (ms): 260.5 | learning rate: 3.296E-05 | global batch size:    32 | lm loss: 1.724613E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74000/  200000 | consumed samples:      2368000 | elapsed time per iteration (ms): 259.2 | learning rate: 3.286E-05 | global batch size:    32 | lm loss: 1.753299E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74100/  200000 | consumed samples:      2371200 | elapsed time per iteration (ms): 270.3 | learning rate: 3.277E-05 | global batch size:    32 | lm loss: 1.743801E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74200/  200000 | consumed samples:      2374400 | elapsed time per iteration (ms): 259.0 | learning rate: 3.268E-05 | global batch size:    32 | lm loss: 1.707047E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74300/  200000 | consumed samples:      2377600 | elapsed time per iteration (ms): 268.2 | learning rate: 3.259E-05 | global batch size:    32 | lm loss: 1.755707E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration    74400/  200000 | consumed samples:      2380800 | elapsed time per iteration (ms): 258.7 | learning rate: 3.250E-05 | global batch size:    32 | lm loss: 1.790091E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74500/  200000 | consumed samples:      2384000 | elapsed time per iteration (ms): 258.5 | learning rate: 3.241E-05 | global batch size:    32 | lm loss: 1.733845E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74600/  200000 | consumed samples:      2387200 | elapsed time per iteration (ms): 276.0 | learning rate: 3.232E-05 | global batch size:    32 | lm loss: 1.754904E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74700/  200000 | consumed samples:      2390400 | elapsed time per iteration (ms): 258.4 | learning rate: 3.223E-05 | global batch size:    32 | lm loss: 1.729652E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74800/  200000 | consumed samples:      2393600 | elapsed time per iteration (ms): 259.1 | learning rate: 3.214E-05 | global batch size:    32 | lm loss: 1.802608E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74900/  200000 | consumed samples:      2396800 | elapsed time per iteration (ms): 260.6 | learning rate: 3.205E-05 | global batch size:    32 | lm loss: 1.752080E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75000/  200000 | consumed samples:      2400000 | elapsed time per iteration (ms): 273.4 | learning rate: 3.196E-05 | global batch size:    32 | lm loss: 1.753238E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75100/  200000 | consumed samples:      2403200 | elapsed time per iteration (ms): 277.7 | learning rate: 3.187E-05 | global batch size:    32 | lm loss: 1.598863E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75200/  200000 | consumed samples:      2406400 | elapsed time per iteration (ms): 261.1 | learning rate: 3.177E-05 | global batch size:    32 | lm loss: 1.581117E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75300/  200000 | consumed samples:      2409600 | elapsed time per iteration (ms): 260.2 | learning rate: 3.168E-05 | global batch size:    32 | lm loss: 1.604954E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75400/  200000 | consumed samples:      2412800 | elapsed time per iteration (ms): 262.4 | learning rate: 3.159E-05 | global batch size:    32 | lm loss: 1.612693E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75500/  200000 | consumed samples:      2416000 | elapsed time per iteration (ms): 260.5 | learning rate: 3.150E-05 | global batch size:    32 | lm loss: 1.629030E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75600/  200000 | consumed samples:      2419200 | elapsed time per iteration (ms): 272.6 | learning rate: 3.141E-05 | global batch size:    32 | lm loss: 1.630870E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75700/  200000 | consumed samples:      2422400 | elapsed time per iteration (ms): 272.9 | learning rate: 3.132E-05 | global batch size:    32 | lm loss: 1.598837E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75800/  200000 | consumed samples:      2425600 | elapsed time per iteration (ms): 261.7 | learning rate: 3.123E-05 | global batch size:    32 | lm loss: 1.607432E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75900/  200000 | consumed samples:      2428800 | elapsed time per iteration (ms): 259.3 | learning rate: 3.114E-05 | global batch size:    32 | lm loss: 1.622850E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76000/  200000 | consumed samples:      2432000 | elapsed time per iteration (ms): 261.7 | learning rate: 3.105E-05 | global batch size:    32 | lm loss: 1.613420E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76100/  200000 | consumed samples:      2435200 | elapsed time per iteration (ms): 279.0 | learning rate: 3.095E-05 | global batch size:    32 | lm loss: 1.612121E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76200/  200000 | consumed samples:      2438400 | elapsed time per iteration (ms): 258.7 | learning rate: 3.086E-05 | global batch size:    32 | lm loss: 1.627041E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76300/  200000 | consumed samples:      2441600 | elapsed time per iteration (ms): 261.2 | learning rate: 3.077E-05 | global batch size:    32 | lm loss: 1.608487E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76400/  200000 | consumed samples:      2444800 | elapsed time per iteration (ms): 265.2 | learning rate: 3.068E-05 | global batch size:    32 | lm loss: 1.658253E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76500/  200000 | consumed samples:      2448000 | elapsed time per iteration (ms): 273.7 | learning rate: 3.059E-05 | global batch size:    32 | lm loss: 1.619986E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76600/  200000 | consumed samples:      2451200 | elapsed time per iteration (ms): 272.3 | learning rate: 3.050E-05 | global batch size:    32 | lm loss: 1.629920E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76700/  200000 | consumed samples:      2454400 | elapsed time per iteration (ms): 258.6 | learning rate: 3.041E-05 | global batch size:    32 | lm loss: 1.596725E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76800/  200000 | consumed samples:      2457600 | elapsed time per iteration (ms): 257.5 | learning rate: 3.032E-05 | global batch size:    32 | lm loss: 1.611324E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76900/  200000 | consumed samples:      2460800 | elapsed time per iteration (ms): 260.1 | learning rate: 3.023E-05 | global batch size:    32 | lm loss: 1.652926E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77000/  200000 | consumed samples:      2464000 | elapsed time per iteration (ms): 257.4 | learning rate: 3.013E-05 | global batch size:    32 | lm loss: 1.618204E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77100/  200000 | consumed samples:      2467200 | elapsed time per iteration (ms): 270.5 | learning rate: 3.004E-05 | global batch size:    32 | lm loss: 1.641608E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77200/  200000 | consumed samples:      2470400 | elapsed time per iteration (ms): 273.0 | learning rate: 2.995E-05 | global batch size:    32 | lm loss: 1.633260E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77300/  200000 | consumed samples:      2473600 | elapsed time per iteration (ms): 257.9 | learning rate: 2.986E-05 | global batch size:    32 | lm loss: 1.657921E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    77400/  200000 | consumed samples:      2476800 | elapsed time per iteration (ms): 260.2 | learning rate: 2.977E-05 | global batch size:    32 | lm loss: 1.655027E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77500/  200000 | consumed samples:      2480000 | elapsed time per iteration (ms): 258.8 | learning rate: 2.968E-05 | global batch size:    32 | lm loss: 1.646396E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77600/  200000 | consumed samples:      2483200 | elapsed time per iteration (ms): 273.4 | learning rate: 2.959E-05 | global batch size:    32 | lm loss: 1.636918E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77700/  200000 | consumed samples:      2486400 | elapsed time per iteration (ms): 259.7 | learning rate: 2.950E-05 | global batch size:    32 | lm loss: 1.635204E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77800/  200000 | consumed samples:      2489600 | elapsed time per iteration (ms): 260.4 | learning rate: 2.941E-05 | global batch size:    32 | lm loss: 1.624195E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77900/  200000 | consumed samples:      2492800 | elapsed time per iteration (ms): 271.8 | learning rate: 2.932E-05 | global batch size:    32 | lm loss: 1.646724E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78000/  200000 | consumed samples:      2496000 | elapsed time per iteration (ms): 262.6 | learning rate: 2.923E-05 | global batch size:    32 | lm loss: 1.673829E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78100/  200000 | consumed samples:      2499200 | elapsed time per iteration (ms): 278.9 | learning rate: 2.913E-05 | global batch size:    32 | lm loss: 1.657897E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78200/  200000 | consumed samples:      2502400 | elapsed time per iteration (ms): 266.5 | learning rate: 2.904E-05 | global batch size:    32 | lm loss: 1.592202E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78300/  200000 | consumed samples:      2505600 | elapsed time per iteration (ms): 260.4 | learning rate: 2.895E-05 | global batch size:    32 | lm loss: 1.502782E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78400/  200000 | consumed samples:      2508800 | elapsed time per iteration (ms): 261.6 | learning rate: 2.886E-05 | global batch size:    32 | lm loss: 1.503649E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78500/  200000 | consumed samples:      2512000 | elapsed time per iteration (ms): 260.8 | learning rate: 2.877E-05 | global batch size:    32 | lm loss: 1.495466E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78600/  200000 | consumed samples:      2515200 | elapsed time per iteration (ms): 284.2 | learning rate: 2.868E-05 | global batch size:    32 | lm loss: 1.502138E-05 | loss scale: 536870912.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78700/  200000 | consumed samples:      2518400 | elapsed time per iteration (ms): 265.6 | learning rate: 2.859E-05 | global batch size:    32 | lm loss: 1.510725E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78800/  200000 | consumed samples:      2521600 | elapsed time per iteration (ms): 261.1 | learning rate: 2.850E-05 | global batch size:    32 | lm loss: 1.536814E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78900/  200000 | consumed samples:      2524800 | elapsed time per iteration (ms): 261.5 | learning rate: 2.841E-05 | global batch size:    32 | lm loss: 1.510202E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79000/  200000 | consumed samples:      2528000 | elapsed time per iteration (ms): 259.9 | learning rate: 2.831E-05 | global batch size:    32 | lm loss: 1.512289E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79100/  200000 | consumed samples:      2531200 | elapsed time per iteration (ms): 276.1 | learning rate: 2.822E-05 | global batch size:    32 | lm loss: 1.518106E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79200/  200000 | consumed samples:      2534400 | elapsed time per iteration (ms): 257.8 | learning rate: 2.813E-05 | global batch size:    32 | lm loss: 1.531391E-05 | loss scale: 268435456.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    79300/  200000 | consumed samples:      2537600 | elapsed time per iteration (ms): 259.7 | learning rate: 2.804E-05 | global batch size:    32 | lm loss: 1.565326E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    79400/  200000 | consumed samples:      2540800 | elapsed time per iteration (ms): 275.1 | learning rate: 2.795E-05 | global batch size:    32 | lm loss: 1.540708E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79500/  200000 | consumed samples:      2544000 | elapsed time per iteration (ms): 261.0 | learning rate: 2.786E-05 | global batch size:    32 | lm loss: 1.540930E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79600/  200000 | consumed samples:      2547200 | elapsed time per iteration (ms): 279.4 | learning rate: 2.777E-05 | global batch size:    32 | lm loss: 1.565508E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79700/  200000 | consumed samples:      2550400 | elapsed time per iteration (ms): 259.0 | learning rate: 2.768E-05 | global batch size:    32 | lm loss: 1.551625E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79800/  200000 | consumed samples:      2553600 | elapsed time per iteration (ms): 260.1 | learning rate: 2.759E-05 | global batch size:    32 | lm loss: 1.564778E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79900/  200000 | consumed samples:      2556800 | elapsed time per iteration (ms): 260.0 | learning rate: 2.750E-05 | global batch size:    32 | lm loss: 1.555386E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80000/  200000 | consumed samples:      2560000 | elapsed time per iteration (ms): 259.1 | learning rate: 2.741E-05 | global batch size:    32 | lm loss: 1.591875E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80100/  200000 | consumed samples:      2563200 | elapsed time per iteration (ms): 531.9 | learning rate: 2.732E-05 | global batch size:    32 | lm loss: 1.563462E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80200/  200000 | consumed samples:      2566400 | elapsed time per iteration (ms): 260.6 | learning rate: 2.722E-05 | global batch size:    32 | lm loss: 1.560429E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80300/  200000 | consumed samples:      2569600 | elapsed time per iteration (ms): 261.4 | learning rate: 2.713E-05 | global batch size:    32 | lm loss: 1.547657E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80400/  200000 | consumed samples:      2572800 | elapsed time per iteration (ms): 259.0 | learning rate: 2.704E-05 | global batch size:    32 | lm loss: 1.608594E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    80500/  200000 | consumed samples:      2576000 | elapsed time per iteration (ms): 261.2 | learning rate: 2.695E-05 | global batch size:    32 | lm loss: 1.581461E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80600/  200000 | consumed samples:      2579200 | elapsed time per iteration (ms): 273.6 | learning rate: 2.686E-05 | global batch size:    32 | lm loss: 1.567597E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80700/  200000 | consumed samples:      2582400 | elapsed time per iteration (ms): 258.9 | learning rate: 2.677E-05 | global batch size:    32 | lm loss: 1.552638E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80800/  200000 | consumed samples:      2585600 | elapsed time per iteration (ms): 268.9 | learning rate: 2.668E-05 | global batch size:    32 | lm loss: 1.573817E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80900/  200000 | consumed samples:      2588800 | elapsed time per iteration (ms): 268.7 | learning rate: 2.659E-05 | global batch size:    32 | lm loss: 1.562637E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81000/  200000 | consumed samples:      2592000 | elapsed time per iteration (ms): 261.0 | learning rate: 2.650E-05 | global batch size:    32 | lm loss: 1.571589E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81100/  200000 | consumed samples:      2595200 | elapsed time per iteration (ms): 340.1 | learning rate: 2.641E-05 | global batch size:    32 | lm loss: 1.581101E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81200/  200000 | consumed samples:      2598400 | elapsed time per iteration (ms): 260.6 | learning rate: 2.632E-05 | global batch size:    32 | lm loss: 1.560698E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81300/  200000 | consumed samples:      2601600 | elapsed time per iteration (ms): 267.6 | learning rate: 2.622E-05 | global batch size:    32 | lm loss: 1.519933E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81400/  200000 | consumed samples:      2604800 | elapsed time per iteration (ms): 263.9 | learning rate: 2.613E-05 | global batch size:    32 | lm loss: 1.457819E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81500/  200000 | consumed samples:      2608000 | elapsed time per iteration (ms): 262.0 | learning rate: 2.604E-05 | global batch size:    32 | lm loss: 1.469014E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81600/  200000 | consumed samples:      2611200 | elapsed time per iteration (ms): 282.8 | learning rate: 2.595E-05 | global batch size:    32 | lm loss: 1.452785E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81700/  200000 | consumed samples:      2614400 | elapsed time per iteration (ms): 260.5 | learning rate: 2.586E-05 | global batch size:    32 | lm loss: 1.490067E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81800/  200000 | consumed samples:      2617600 | elapsed time per iteration (ms): 260.7 | learning rate: 2.577E-05 | global batch size:    32 | lm loss: 1.467630E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81900/  200000 | consumed samples:      2620800 | elapsed time per iteration (ms): 259.8 | learning rate: 2.568E-05 | global batch size:    32 | lm loss: 1.465540E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82000/  200000 | consumed samples:      2624000 | elapsed time per iteration (ms): 259.7 | learning rate: 2.559E-05 | global batch size:    32 | lm loss: 1.464891E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82100/  200000 | consumed samples:      2627200 | elapsed time per iteration (ms): 272.5 | learning rate: 2.550E-05 | global batch size:    32 | lm loss: 1.446060E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82200/  200000 | consumed samples:      2630400 | elapsed time per iteration (ms): 260.5 | learning rate: 2.540E-05 | global batch size:    32 | lm loss: 1.472184E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82300/  200000 | consumed samples:      2633600 | elapsed time per iteration (ms): 270.2 | learning rate: 2.531E-05 | global batch size:    32 | lm loss: 1.484627E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82400/  200000 | consumed samples:      2636800 | elapsed time per iteration (ms): 260.6 | learning rate: 2.522E-05 | global batch size:    32 | lm loss: 1.473388E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82500/  200000 | consumed samples:      2640000 | elapsed time per iteration (ms): 260.2 | learning rate: 2.513E-05 | global batch size:    32 | lm loss: 1.476903E-05 | loss scale: 536870912.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82600/  200000 | consumed samples:      2643200 | elapsed time per iteration (ms): 276.3 | learning rate: 2.504E-05 | global batch size:    32 | lm loss: 1.540304E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    82700/  200000 | consumed samples:      2646400 | elapsed time per iteration (ms): 258.0 | learning rate: 2.495E-05 | global batch size:    32 | lm loss: 1.540469E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    82800/  200000 | consumed samples:      2649600 | elapsed time per iteration (ms): 259.8 | learning rate: 2.486E-05 | global batch size:    32 | lm loss: 1.511832E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82900/  200000 | consumed samples:      2652800 | elapsed time per iteration (ms): 261.4 | learning rate: 2.477E-05 | global batch size:    32 | lm loss: 1.477263E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83000/  200000 | consumed samples:      2656000 | elapsed time per iteration (ms): 266.0 | learning rate: 2.468E-05 | global batch size:    32 | lm loss: 1.488248E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83100/  200000 | consumed samples:      2659200 | elapsed time per iteration (ms): 277.3 | learning rate: 2.459E-05 | global batch size:    32 | lm loss: 1.481252E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83200/  200000 | consumed samples:      2662400 | elapsed time per iteration (ms): 260.3 | learning rate: 2.450E-05 | global batch size:    32 | lm loss: 1.468373E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83300/  200000 | consumed samples:      2665600 | elapsed time per iteration (ms): 259.7 | learning rate: 2.441E-05 | global batch size:    32 | lm loss: 1.484490E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83400/  200000 | consumed samples:      2668800 | elapsed time per iteration (ms): 259.3 | learning rate: 2.431E-05 | global batch size:    32 | lm loss: 1.479196E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83500/  200000 | consumed samples:      2672000 | elapsed time per iteration (ms): 258.9 | learning rate: 2.422E-05 | global batch size:    32 | lm loss: 1.498100E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83600/  200000 | consumed samples:      2675200 | elapsed time per iteration (ms): 274.4 | learning rate: 2.413E-05 | global batch size:    32 | lm loss: 1.496260E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83700/  200000 | consumed samples:      2678400 | elapsed time per iteration (ms): 260.0 | learning rate: 2.404E-05 | global batch size:    32 | lm loss: 1.514173E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83800/  200000 | consumed samples:      2681600 | elapsed time per iteration (ms): 270.2 | learning rate: 2.395E-05 | global batch size:    32 | lm loss: 1.499125E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83900/  200000 | consumed samples:      2684800 | elapsed time per iteration (ms): 261.2 | learning rate: 2.386E-05 | global batch size:    32 | lm loss: 1.510536E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84000/  200000 | consumed samples:      2688000 | elapsed time per iteration (ms): 258.0 | learning rate: 2.377E-05 | global batch size:    32 | lm loss: 1.531550E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84100/  200000 | consumed samples:      2691200 | elapsed time per iteration (ms): 276.3 | learning rate: 2.368E-05 | global batch size:    32 | lm loss: 1.504557E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84200/  200000 | consumed samples:      2694400 | elapsed time per iteration (ms): 259.6 | learning rate: 2.359E-05 | global batch size:    32 | lm loss: 1.495691E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84300/  200000 | consumed samples:      2697600 | elapsed time per iteration (ms): 257.9 | learning rate: 2.350E-05 | global batch size:    32 | lm loss: 1.517591E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84400/  200000 | consumed samples:      2700800 | elapsed time per iteration (ms): 265.7 | learning rate: 2.340E-05 | global batch size:    32 | lm loss: 1.479697E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84500/  200000 | consumed samples:      2704000 | elapsed time per iteration (ms): 269.1 | learning rate: 2.331E-05 | global batch size:    32 | lm loss: 1.407563E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84600/  200000 | consumed samples:      2707200 | elapsed time per iteration (ms): 270.7 | learning rate: 2.322E-05 | global batch size:    32 | lm loss: 1.398917E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84700/  200000 | consumed samples:      2710400 | elapsed time per iteration (ms): 258.9 | learning rate: 2.313E-05 | global batch size:    32 | lm loss: 1.406295E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84800/  200000 | consumed samples:      2713600 | elapsed time per iteration (ms): 259.1 | learning rate: 2.304E-05 | global batch size:    32 | lm loss: 1.410733E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84900/  200000 | consumed samples:      2716800 | elapsed time per iteration (ms): 259.8 | learning rate: 2.295E-05 | global batch size:    32 | lm loss: 1.411197E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85000/  200000 | consumed samples:      2720000 | elapsed time per iteration (ms): 259.7 | learning rate: 2.286E-05 | global batch size:    32 | lm loss: 1.410131E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85100/  200000 | consumed samples:      2723200 | elapsed time per iteration (ms): 270.4 | learning rate: 2.277E-05 | global batch size:    32 | lm loss: 1.461842E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85200/  200000 | consumed samples:      2726400 | elapsed time per iteration (ms): 266.7 | learning rate: 2.268E-05 | global batch size:    32 | lm loss: 1.477179E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85300/  200000 | consumed samples:      2729600 | elapsed time per iteration (ms): 264.7 | learning rate: 2.258E-05 | global batch size:    32 | lm loss: 1.458710E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85400/  200000 | consumed samples:      2732800 | elapsed time per iteration (ms): 259.1 | learning rate: 2.249E-05 | global batch size:    32 | lm loss: 1.411726E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85500/  200000 | consumed samples:      2736000 | elapsed time per iteration (ms): 258.5 | learning rate: 2.240E-05 | global batch size:    32 | lm loss: 1.400463E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85600/  200000 | consumed samples:      2739200 | elapsed time per iteration (ms): 273.9 | learning rate: 2.231E-05 | global batch size:    32 | lm loss: 1.427013E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85700/  200000 | consumed samples:      2742400 | elapsed time per iteration (ms): 260.7 | learning rate: 2.222E-05 | global batch size:    32 | lm loss: 1.417646E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85800/  200000 | consumed samples:      2745600 | elapsed time per iteration (ms): 260.2 | learning rate: 2.213E-05 | global batch size:    32 | lm loss: 1.436988E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85900/  200000 | consumed samples:      2748800 | elapsed time per iteration (ms): 260.9 | learning rate: 2.204E-05 | global batch size:    32 | lm loss: 1.432129E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86000/  200000 | consumed samples:      2752000 | elapsed time per iteration (ms): 271.2 | learning rate: 2.195E-05 | global batch size:    32 | lm loss: 1.454325E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    86100/  200000 | consumed samples:      2755200 | elapsed time per iteration (ms): 272.9 | learning rate: 2.186E-05 | global batch size:    32 | lm loss: 1.443415E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86200/  200000 | consumed samples:      2758400 | elapsed time per iteration (ms): 259.7 | learning rate: 2.177E-05 | global batch size:    32 | lm loss: 1.443964E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86300/  200000 | consumed samples:      2761600 | elapsed time per iteration (ms): 258.9 | learning rate: 2.168E-05 | global batch size:    32 | lm loss: 1.441948E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86400/  200000 | consumed samples:      2764800 | elapsed time per iteration (ms): 258.4 | learning rate: 2.158E-05 | global batch size:    32 | lm loss: 1.422852E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86500/  200000 | consumed samples:      2768000 | elapsed time per iteration (ms): 258.9 | learning rate: 2.149E-05 | global batch size:    32 | lm loss: 1.430744E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86600/  200000 | consumed samples:      2771200 | elapsed time per iteration (ms): 273.4 | learning rate: 2.140E-05 | global batch size:    32 | lm loss: 1.436559E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86700/  200000 | consumed samples:      2774400 | elapsed time per iteration (ms): 277.5 | learning rate: 2.131E-05 | global batch size:    32 | lm loss: 1.452949E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86800/  200000 | consumed samples:      2777600 | elapsed time per iteration (ms): 260.6 | learning rate: 2.122E-05 | global batch size:    32 | lm loss: 1.442820E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86900/  200000 | consumed samples:      2780800 | elapsed time per iteration (ms): 259.5 | learning rate: 2.113E-05 | global batch size:    32 | lm loss: 1.430228E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87000/  200000 | consumed samples:      2784000 | elapsed time per iteration (ms): 260.4 | learning rate: 2.104E-05 | global batch size:    32 | lm loss: 1.445076E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87100/  200000 | consumed samples:      2787200 | elapsed time per iteration (ms): 275.6 | learning rate: 2.095E-05 | global batch size:    32 | lm loss: 1.445870E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87200/  200000 | consumed samples:      2790400 | elapsed time per iteration (ms): 259.8 | learning rate: 2.086E-05 | global batch size:    32 | lm loss: 1.469345E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    87300/  200000 | consumed samples:      2793600 | elapsed time per iteration (ms): 259.2 | learning rate: 2.077E-05 | global batch size:    32 | lm loss: 1.455107E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    87400/  200000 | consumed samples:      2796800 | elapsed time per iteration (ms): 267.3 | learning rate: 2.067E-05 | global batch size:    32 | lm loss: 1.450875E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87500/  200000 | consumed samples:      2800000 | elapsed time per iteration (ms): 265.3 | learning rate: 2.058E-05 | global batch size:    32 | lm loss: 1.453837E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87600/  200000 | consumed samples:      2803200 | elapsed time per iteration (ms): 279.0 | learning rate: 2.049E-05 | global batch size:    32 | lm loss: 1.358689E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87700/  200000 | consumed samples:      2806400 | elapsed time per iteration (ms): 261.3 | learning rate: 2.040E-05 | global batch size:    32 | lm loss: 1.376768E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87800/  200000 | consumed samples:      2809600 | elapsed time per iteration (ms): 259.2 | learning rate: 2.031E-05 | global batch size:    32 | lm loss: 1.365495E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87900/  200000 | consumed samples:      2812800 | elapsed time per iteration (ms): 258.3 | learning rate: 2.022E-05 | global batch size:    32 | lm loss: 1.359282E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88000/  200000 | consumed samples:      2816000 | elapsed time per iteration (ms): 261.4 | learning rate: 2.013E-05 | global batch size:    32 | lm loss: 1.375467E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88100/  200000 | consumed samples:      2819200 | elapsed time per iteration (ms): 273.7 | learning rate: 2.004E-05 | global batch size:    32 | lm loss: 1.373446E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88200/  200000 | consumed samples:      2822400 | elapsed time per iteration (ms): 273.3 | learning rate: 1.995E-05 | global batch size:    32 | lm loss: 1.394810E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88300/  200000 | consumed samples:      2825600 | elapsed time per iteration (ms): 259.5 | learning rate: 1.986E-05 | global batch size:    32 | lm loss: 1.379010E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88400/  200000 | consumed samples:      2828800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.976E-05 | global batch size:    32 | lm loss: 1.366860E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88500/  200000 | consumed samples:      2832000 | elapsed time per iteration (ms): 260.7 | learning rate: 1.967E-05 | global batch size:    32 | lm loss: 1.373977E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88600/  200000 | consumed samples:      2835200 | elapsed time per iteration (ms): 279.8 | learning rate: 1.958E-05 | global batch size:    32 | lm loss: 1.395343E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88700/  200000 | consumed samples:      2838400 | elapsed time per iteration (ms): 259.2 | learning rate: 1.949E-05 | global batch size:    32 | lm loss: 1.402384E-05 | loss scale: 536870912.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88800/  200000 | consumed samples:      2841600 | elapsed time per iteration (ms): 259.0 | learning rate: 1.940E-05 | global batch size:    32 | lm loss: 1.378922E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88900/  200000 | consumed samples:      2844800 | elapsed time per iteration (ms): 272.9 | learning rate: 1.931E-05 | global batch size:    32 | lm loss: 1.393608E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89000/  200000 | consumed samples:      2848000 | elapsed time per iteration (ms): 258.2 | learning rate: 1.922E-05 | global batch size:    32 | lm loss: 1.407268E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89100/  200000 | consumed samples:      2851200 | elapsed time per iteration (ms): 273.0 | learning rate: 1.913E-05 | global batch size:    32 | lm loss: 1.401280E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89200/  200000 | consumed samples:      2854400 | elapsed time per iteration (ms): 260.4 | learning rate: 1.904E-05 | global batch size:    32 | lm loss: 1.399967E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89300/  200000 | consumed samples:      2857600 | elapsed time per iteration (ms): 259.3 | learning rate: 1.895E-05 | global batch size:    32 | lm loss: 1.391883E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    89400/  200000 | consumed samples:      2860800 | elapsed time per iteration (ms): 262.7 | learning rate: 1.885E-05 | global batch size:    32 | lm loss: 1.403464E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89500/  200000 | consumed samples:      2864000 | elapsed time per iteration (ms): 263.2 | learning rate: 1.876E-05 | global batch size:    32 | lm loss: 1.419039E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89600/  200000 | consumed samples:      2867200 | elapsed time per iteration (ms): 348.8 | learning rate: 1.867E-05 | global batch size:    32 | lm loss: 1.397039E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89700/  200000 | consumed samples:      2870400 | elapsed time per iteration (ms): 262.8 | learning rate: 1.858E-05 | global batch size:    32 | lm loss: 1.413533E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89800/  200000 | consumed samples:      2873600 | elapsed time per iteration (ms): 260.3 | learning rate: 1.849E-05 | global batch size:    32 | lm loss: 1.401097E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89900/  200000 | consumed samples:      2876800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.840E-05 | global batch size:    32 | lm loss: 1.390569E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90000/  200000 | consumed samples:      2880000 | elapsed time per iteration (ms): 259.1 | learning rate: 1.831E-05 | global batch size:    32 | lm loss: 1.414711E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90100/  200000 | consumed samples:      2883200 | elapsed time per iteration (ms): 274.7 | learning rate: 1.822E-05 | global batch size:    32 | lm loss: 1.409888E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90200/  200000 | consumed samples:      2886400 | elapsed time per iteration (ms): 259.1 | learning rate: 1.813E-05 | global batch size:    32 | lm loss: 1.402505E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90300/  200000 | consumed samples:      2889600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.804E-05 | global batch size:    32 | lm loss: 1.399434E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90400/  200000 | consumed samples:      2892800 | elapsed time per iteration (ms): 265.9 | learning rate: 1.795E-05 | global batch size:    32 | lm loss: 1.429855E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    90500/  200000 | consumed samples:      2896000 | elapsed time per iteration (ms): 261.5 | learning rate: 1.785E-05 | global batch size:    32 | lm loss: 1.405735E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90600/  200000 | consumed samples:      2899200 | elapsed time per iteration (ms): 270.2 | learning rate: 1.776E-05 | global batch size:    32 | lm loss: 1.396069E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90700/  200000 | consumed samples:      2902400 | elapsed time per iteration (ms): 266.8 | learning rate: 1.767E-05 | global batch size:    32 | lm loss: 1.361072E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90800/  200000 | consumed samples:      2905600 | elapsed time per iteration (ms): 256.8 | learning rate: 1.758E-05 | global batch size:    32 | lm loss: 1.327860E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90900/  200000 | consumed samples:      2908800 | elapsed time per iteration (ms): 258.3 | learning rate: 1.749E-05 | global batch size:    32 | lm loss: 1.334406E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91000/  200000 | consumed samples:      2912000 | elapsed time per iteration (ms): 259.7 | learning rate: 1.740E-05 | global batch size:    32 | lm loss: 1.322632E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91100/  200000 | consumed samples:      2915200 | elapsed time per iteration (ms): 277.5 | learning rate: 1.731E-05 | global batch size:    32 | lm loss: 1.322617E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91200/  200000 | consumed samples:      2918400 | elapsed time per iteration (ms): 257.7 | learning rate: 1.722E-05 | global batch size:    32 | lm loss: 1.345237E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91300/  200000 | consumed samples:      2921600 | elapsed time per iteration (ms): 259.0 | learning rate: 1.713E-05 | global batch size:    32 | lm loss: 1.340361E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91400/  200000 | consumed samples:      2924800 | elapsed time per iteration (ms): 257.8 | learning rate: 1.703E-05 | global batch size:    32 | lm loss: 1.345419E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91500/  200000 | consumed samples:      2928000 | elapsed time per iteration (ms): 258.9 | learning rate: 1.694E-05 | global batch size:    32 | lm loss: 1.362418E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91600/  200000 | consumed samples:      2931200 | elapsed time per iteration (ms): 270.1 | learning rate: 1.686E-05 | global batch size:    32 | lm loss: 1.342512E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration    91700/  200000 | consumed samples:      2934400 | elapsed time per iteration (ms): 257.8 | learning rate: 1.677E-05 | global batch size:    32 | lm loss: 1.358289E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91800/  200000 | consumed samples:      2937600 | elapsed time per iteration (ms): 263.8 | learning rate: 1.667E-05 | global batch size:    32 | lm loss: 1.346010E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91900/  200000 | consumed samples:      2940800 | elapsed time per iteration (ms): 259.8 | learning rate: 1.658E-05 | global batch size:    32 | lm loss: 1.358130E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92000/  200000 | consumed samples:      2944000 | elapsed time per iteration (ms): 255.8 | learning rate: 1.649E-05 | global batch size:    32 | lm loss: 1.357473E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92100/  200000 | consumed samples:      2947200 | elapsed time per iteration (ms): 267.6 | learning rate: 1.640E-05 | global batch size:    32 | lm loss: 1.363758E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92200/  200000 | consumed samples:      2950400 | elapsed time per iteration (ms): 257.4 | learning rate: 1.631E-05 | global batch size:    32 | lm loss: 1.338309E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92300/  200000 | consumed samples:      2953600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.622E-05 | global batch size:    32 | lm loss: 1.378083E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92400/  200000 | consumed samples:      2956800 | elapsed time per iteration (ms): 258.0 | learning rate: 1.613E-05 | global batch size:    32 | lm loss: 1.364478E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92500/  200000 | consumed samples:      2960000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.604E-05 | global batch size:    32 | lm loss: 1.382854E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92600/  200000 | consumed samples:      2963200 | elapsed time per iteration (ms): 280.2 | learning rate: 1.595E-05 | global batch size:    32 | lm loss: 1.362254E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92700/  200000 | consumed samples:      2966400 | elapsed time per iteration (ms): 259.7 | learning rate: 1.585E-05 | global batch size:    32 | lm loss: 1.370559E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92800/  200000 | consumed samples:      2969600 | elapsed time per iteration (ms): 260.6 | learning rate: 1.576E-05 | global batch size:    32 | lm loss: 1.375185E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92900/  200000 | consumed samples:      2972800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.567E-05 | global batch size:    32 | lm loss: 1.366939E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93000/  200000 | consumed samples:      2976000 | elapsed time per iteration (ms): 258.2 | learning rate: 1.558E-05 | global batch size:    32 | lm loss: 1.378624E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93100/  200000 | consumed samples:      2979200 | elapsed time per iteration (ms): 275.2 | learning rate: 1.549E-05 | global batch size:    32 | lm loss: 1.369348E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93200/  200000 | consumed samples:      2982400 | elapsed time per iteration (ms): 261.2 | learning rate: 1.540E-05 | global batch size:    32 | lm loss: 1.371874E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93300/  200000 | consumed samples:      2985600 | elapsed time per iteration (ms): 271.5 | learning rate: 1.531E-05 | global batch size:    32 | lm loss: 1.375430E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93400/  200000 | consumed samples:      2988800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.522E-05 | global batch size:    32 | lm loss: 1.377629E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93500/  200000 | consumed samples:      2992000 | elapsed time per iteration (ms): 258.7 | learning rate: 1.513E-05 | global batch size:    32 | lm loss: 1.369208E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93600/  200000 | consumed samples:      2995200 | elapsed time per iteration (ms): 277.6 | learning rate: 1.503E-05 | global batch size:    32 | lm loss: 1.382594E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93700/  200000 | consumed samples:      2998400 | elapsed time per iteration (ms): 259.3 | learning rate: 1.494E-05 | global batch size:    32 | lm loss: 1.371921E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93800/  200000 | consumed samples:      3001600 | elapsed time per iteration (ms): 264.9 | learning rate: 1.485E-05 | global batch size:    32 | lm loss: 1.350406E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93900/  200000 | consumed samples:      3004800 | elapsed time per iteration (ms): 261.8 | learning rate: 1.476E-05 | global batch size:    32 | lm loss: 1.312964E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94000/  200000 | consumed samples:      3008000 | elapsed time per iteration (ms): 270.5 | learning rate: 1.467E-05 | global batch size:    32 | lm loss: 1.306763E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94100/  200000 | consumed samples:      3011200 | elapsed time per iteration (ms): 277.0 | learning rate: 1.458E-05 | global batch size:    32 | lm loss: 1.285491E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94200/  200000 | consumed samples:      3014400 | elapsed time per iteration (ms): 260.7 | learning rate: 1.449E-05 | global batch size:    32 | lm loss: 1.321644E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94300/  200000 | consumed samples:      3017600 | elapsed time per iteration (ms): 256.3 | learning rate: 1.440E-05 | global batch size:    32 | lm loss: 1.319265E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94400/  200000 | consumed samples:      3020800 | elapsed time per iteration (ms): 259.4 | learning rate: 1.431E-05 | global batch size:    32 | lm loss: 1.313851E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94500/  200000 | consumed samples:      3024000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.421E-05 | global batch size:    32 | lm loss: 1.303485E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94600/  200000 | consumed samples:      3027200 | elapsed time per iteration (ms): 272.2 | learning rate: 1.412E-05 | global batch size:    32 | lm loss: 1.328143E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    94700/  200000 | consumed samples:      3030400 | elapsed time per iteration (ms): 261.7 | learning rate: 1.403E-05 | global batch size:    32 | lm loss: 1.329060E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94800/  200000 | consumed samples:      3033600 | elapsed time per iteration (ms): 272.3 | learning rate: 1.394E-05 | global batch size:    32 | lm loss: 1.327691E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94900/  200000 | consumed samples:      3036800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.385E-05 | global batch size:    32 | lm loss: 1.326200E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95000/  200000 | consumed samples:      3040000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.376E-05 | global batch size:    32 | lm loss: 1.328410E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95100/  200000 | consumed samples:      3043200 | elapsed time per iteration (ms): 279.5 | learning rate: 1.367E-05 | global batch size:    32 | lm loss: 1.317586E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95200/  200000 | consumed samples:      3046400 | elapsed time per iteration (ms): 258.7 | learning rate: 1.358E-05 | global batch size:    32 | lm loss: 1.333104E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    95300/  200000 | consumed samples:      3049600 | elapsed time per iteration (ms): 263.4 | learning rate: 1.349E-05 | global batch size:    32 | lm loss: 1.333647E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95400/  200000 | consumed samples:      3052800 | elapsed time per iteration (ms): 258.3 | learning rate: 1.340E-05 | global batch size:    32 | lm loss: 1.345802E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95500/  200000 | consumed samples:      3056000 | elapsed time per iteration (ms): 270.7 | learning rate: 1.331E-05 | global batch size:    32 | lm loss: 1.350127E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95600/  200000 | consumed samples:      3059200 | elapsed time per iteration (ms): 271.9 | learning rate: 1.322E-05 | global batch size:    32 | lm loss: 1.348082E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95700/  200000 | consumed samples:      3062400 | elapsed time per iteration (ms): 259.4 | learning rate: 1.312E-05 | global batch size:    32 | lm loss: 1.341784E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95800/  200000 | consumed samples:      3065600 | elapsed time per iteration (ms): 261.0 | learning rate: 1.303E-05 | global batch size:    32 | lm loss: 1.342463E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95900/  200000 | consumed samples:      3068800 | elapsed time per iteration (ms): 261.9 | learning rate: 1.294E-05 | global batch size:    32 | lm loss: 1.341485E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96000/  200000 | consumed samples:      3072000 | elapsed time per iteration (ms): 260.8 | learning rate: 1.285E-05 | global batch size:    32 | lm loss: 1.345103E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96100/  200000 | consumed samples:      3075200 | elapsed time per iteration (ms): 274.5 | learning rate: 1.276E-05 | global batch size:    32 | lm loss: 1.341692E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96200/  200000 | consumed samples:      3078400 | elapsed time per iteration (ms): 270.0 | learning rate: 1.267E-05 | global batch size:    32 | lm loss: 1.370889E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96300/  200000 | consumed samples:      3081600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.258E-05 | global batch size:    32 | lm loss: 1.351955E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96400/  200000 | consumed samples:      3084800 | elapsed time per iteration (ms): 258.3 | learning rate: 1.249E-05 | global batch size:    32 | lm loss: 1.353477E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96500/  200000 | consumed samples:      3088000 | elapsed time per iteration (ms): 260.7 | learning rate: 1.240E-05 | global batch size:    32 | lm loss: 1.342731E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    96600/  200000 | consumed samples:      3091200 | elapsed time per iteration (ms): 277.3 | learning rate: 1.231E-05 | global batch size:    32 | lm loss: 1.363274E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96700/  200000 | consumed samples:      3094400 | elapsed time per iteration (ms): 258.7 | learning rate: 1.222E-05 | global batch size:    32 | lm loss: 1.362763E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96800/  200000 | consumed samples:      3097600 | elapsed time per iteration (ms): 259.1 | learning rate: 1.212E-05 | global batch size:    32 | lm loss: 1.356725E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96900/  200000 | consumed samples:      3100800 | elapsed time per iteration (ms): 271.7 | learning rate: 1.203E-05 | global batch size:    32 | lm loss: 1.331273E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97000/  200000 | consumed samples:      3104000 | elapsed time per iteration (ms): 269.7 | learning rate: 1.194E-05 | global batch size:    32 | lm loss: 1.304543E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97100/  200000 | consumed samples:      3107200 | elapsed time per iteration (ms): 277.7 | learning rate: 1.185E-05 | global batch size:    32 | lm loss: 1.305344E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97200/  200000 | consumed samples:      3110400 | elapsed time per iteration (ms): 260.7 | learning rate: 1.176E-05 | global batch size:    32 | lm loss: 1.313159E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97300/  200000 | consumed samples:      3113600 | elapsed time per iteration (ms): 257.7 | learning rate: 1.167E-05 | global batch size:    32 | lm loss: 1.295754E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97400/  200000 | consumed samples:      3116800 | elapsed time per iteration (ms): 257.9 | learning rate: 1.158E-05 | global batch size:    32 | lm loss: 1.283193E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97500/  200000 | consumed samples:      3120000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.149E-05 | global batch size:    32 | lm loss: 1.287127E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97600/  200000 | consumed samples:      3123200 | elapsed time per iteration (ms): 276.3 | learning rate: 1.140E-05 | global batch size:    32 | lm loss: 1.297465E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97700/  200000 | consumed samples:      3126400 | elapsed time per iteration (ms): 274.6 | learning rate: 1.130E-05 | global batch size:    32 | lm loss: 1.305673E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97800/  200000 | consumed samples:      3129600 | elapsed time per iteration (ms): 263.9 | learning rate: 1.121E-05 | global batch size:    32 | lm loss: 1.306831E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97900/  200000 | consumed samples:      3132800 | elapsed time per iteration (ms): 262.3 | learning rate: 1.112E-05 | global batch size:    32 | lm loss: 1.307747E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98000/  200000 | consumed samples:      3136000 | elapsed time per iteration (ms): 261.1 | learning rate: 1.103E-05 | global batch size:    32 | lm loss: 1.320754E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98100/  200000 | consumed samples:      3139200 | elapsed time per iteration (ms): 344.0 | learning rate: 1.094E-05 | global batch size:    32 | lm loss: 1.330210E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98200/  200000 | consumed samples:      3142400 | elapsed time per iteration (ms): 263.6 | learning rate: 1.085E-05 | global batch size:    32 | lm loss: 1.314115E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98300/  200000 | consumed samples:      3145600 | elapsed time per iteration (ms): 261.6 | learning rate: 1.076E-05 | global batch size:    32 | lm loss: 1.341839E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98400/  200000 | consumed samples:      3148800 | elapsed time per iteration (ms): 271.8 | learning rate: 1.067E-05 | global batch size:    32 | lm loss: 1.304024E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98500/  200000 | consumed samples:      3152000 | elapsed time per iteration (ms): 261.1 | learning rate: 1.058E-05 | global batch size:    32 | lm loss: 1.307332E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98600/  200000 | consumed samples:      3155200 | elapsed time per iteration (ms): 272.1 | learning rate: 1.048E-05 | global batch size:    32 | lm loss: 1.328465E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98700/  200000 | consumed samples:      3158400 | elapsed time per iteration (ms): 261.0 | learning rate: 1.039E-05 | global batch size:    32 | lm loss: 1.327464E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98800/  200000 | consumed samples:      3161600 | elapsed time per iteration (ms): 258.9 | learning rate: 1.030E-05 | global batch size:    32 | lm loss: 1.328734E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98900/  200000 | consumed samples:      3164800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.021E-05 | global batch size:    32 | lm loss: 1.330378E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    99000/  200000 | consumed samples:      3168000 | elapsed time per iteration (ms): 263.6 | learning rate: 1.012E-05 | global batch size:    32 | lm loss: 1.338589E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99100/  200000 | consumed samples:      3171200 | elapsed time per iteration (ms): 274.7 | learning rate: 1.003E-05 | global batch size:    32 | lm loss: 1.313564E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99200/  200000 | consumed samples:      3174400 | elapsed time per iteration (ms): 265.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.328619E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99300/  200000 | consumed samples:      3177600 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307379E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99400/  200000 | consumed samples:      3180800 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.325023E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99500/  200000 | consumed samples:      3184000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.331627E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99600/  200000 | consumed samples:      3187200 | elapsed time per iteration (ms): 276.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.332578E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99700/  200000 | consumed samples:      3190400 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321546E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99800/  200000 | consumed samples:      3193600 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.346510E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99900/  200000 | consumed samples:      3196800 | elapsed time per iteration (ms): 266.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.326507E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   100000/  200000 | consumed samples:      3200000 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.343776E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100100/  200000 | consumed samples:      3203200 | elapsed time per iteration (ms): 502.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302470E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100200/  200000 | consumed samples:      3206400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292432E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100300/  200000 | consumed samples:      3209600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275902E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100400/  200000 | consumed samples:      3212800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278028E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100500/  200000 | consumed samples:      3216000 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.285568E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100600/  200000 | consumed samples:      3219200 | elapsed time per iteration (ms): 280.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277689E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100700/  200000 | consumed samples:      3222400 | elapsed time per iteration (ms): 260.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296174E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100800/  200000 | consumed samples:      3225600 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292238E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100900/  200000 | consumed samples:      3228800 | elapsed time per iteration (ms): 257.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283246E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   101000/  200000 | consumed samples:      3232000 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292983E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101100/  200000 | consumed samples:      3235200 | elapsed time per iteration (ms): 273.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311599E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101200/  200000 | consumed samples:      3238400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308514E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101300/  200000 | consumed samples:      3241600 | elapsed time per iteration (ms): 268.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315253E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101400/  200000 | consumed samples:      3244800 | elapsed time per iteration (ms): 265.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307280E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101500/  200000 | consumed samples:      3248000 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308524E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101600/  200000 | consumed samples:      3251200 | elapsed time per iteration (ms): 269.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314032E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101700/  200000 | consumed samples:      3254400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305406E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101800/  200000 | consumed samples:      3257600 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305385E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101900/  200000 | consumed samples:      3260800 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304221E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   102000/  200000 | consumed samples:      3264000 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321595E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102100/  200000 | consumed samples:      3267200 | elapsed time per iteration (ms): 284.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.320529E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102200/  200000 | consumed samples:      3270400 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.320541E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102300/  200000 | consumed samples:      3273600 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.334513E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102400/  200000 | consumed samples:      3276800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.338614E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   102500/  200000 | consumed samples:      3280000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.338165E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102600/  200000 | consumed samples:      3283200 | elapsed time per iteration (ms): 275.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.344919E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102700/  200000 | consumed samples:      3286400 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.346631E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102800/  200000 | consumed samples:      3289600 | elapsed time per iteration (ms): 271.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.350935E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102900/  200000 | consumed samples:      3292800 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.333869E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   103000/  200000 | consumed samples:      3296000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.347387E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103100/  200000 | consumed samples:      3299200 | elapsed time per iteration (ms): 272.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.361884E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103200/  200000 | consumed samples:      3302400 | elapsed time per iteration (ms): 264.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308867E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103300/  200000 | consumed samples:      3305600 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.287388E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   103400/  200000 | consumed samples:      3308800 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.282588E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103500/  200000 | consumed samples:      3312000 | elapsed time per iteration (ms): 269.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.266990E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103600/  200000 | consumed samples:      3315200 | elapsed time per iteration (ms): 283.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284962E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103700/  200000 | consumed samples:      3318400 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293795E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103800/  200000 | consumed samples:      3321600 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300173E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103900/  200000 | consumed samples:      3324800 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276873E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104000/  200000 | consumed samples:      3328000 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.297061E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104100/  200000 | consumed samples:      3331200 | elapsed time per iteration (ms): 277.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315220E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104200/  200000 | consumed samples:      3334400 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304487E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104300/  200000 | consumed samples:      3337600 | elapsed time per iteration (ms): 278.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.312046E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104400/  200000 | consumed samples:      3340800 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.322329E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104500/  200000 | consumed samples:      3344000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.322826E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104600/  200000 | consumed samples:      3347200 | elapsed time per iteration (ms): 271.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.319833E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104700/  200000 | consumed samples:      3350400 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310767E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104800/  200000 | consumed samples:      3353600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.313269E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104900/  200000 | consumed samples:      3356800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321965E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105000/  200000 | consumed samples:      3360000 | elapsed time per iteration (ms): 275.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.324094E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105100/  200000 | consumed samples:      3363200 | elapsed time per iteration (ms): 275.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.322023E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105200/  200000 | consumed samples:      3366400 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.347745E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105300/  200000 | consumed samples:      3369600 | elapsed time per iteration (ms): 257.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.332518E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105400/  200000 | consumed samples:      3372800 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321244E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105500/  200000 | consumed samples:      3376000 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.328525E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105600/  200000 | consumed samples:      3379200 | elapsed time per iteration (ms): 276.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.329386E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105700/  200000 | consumed samples:      3382400 | elapsed time per iteration (ms): 270.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.318587E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105800/  200000 | consumed samples:      3385600 | elapsed time per iteration (ms): 265.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.332139E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105900/  200000 | consumed samples:      3388800 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.352162E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106000/  200000 | consumed samples:      3392000 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.346363E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106100/  200000 | consumed samples:      3395200 | elapsed time per iteration (ms): 271.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.336227E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106200/  200000 | consumed samples:      3398400 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321433E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106300/  200000 | consumed samples:      3401600 | elapsed time per iteration (ms): 267.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295019E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106400/  200000 | consumed samples:      3404800 | elapsed time per iteration (ms): 264.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.286377E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106500/  200000 | consumed samples:      3408000 | elapsed time per iteration (ms): 342.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.282768E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106600/  200000 | consumed samples:      3411200 | elapsed time per iteration (ms): 274.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293969E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106700/  200000 | consumed samples:      3414400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276157E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106800/  200000 | consumed samples:      3417600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301008E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106900/  200000 | consumed samples:      3420800 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302686E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   107000/  200000 | consumed samples:      3424000 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277852E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107100/  200000 | consumed samples:      3427200 | elapsed time per iteration (ms): 275.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301398E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107200/  200000 | consumed samples:      3430400 | elapsed time per iteration (ms): 270.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306414E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107300/  200000 | consumed samples:      3433600 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300716E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   107400/  200000 | consumed samples:      3436800 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.320762E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107500/  200000 | consumed samples:      3440000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309658E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107600/  200000 | consumed samples:      3443200 | elapsed time per iteration (ms): 268.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300843E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107700/  200000 | consumed samples:      3446400 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.313847E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107800/  200000 | consumed samples:      3449600 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.328890E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107900/  200000 | consumed samples:      3452800 | elapsed time per iteration (ms): 266.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310781E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108000/  200000 | consumed samples:      3456000 | elapsed time per iteration (ms): 263.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.322409E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108100/  200000 | consumed samples:      3459200 | elapsed time per iteration (ms): 270.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314614E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108200/  200000 | consumed samples:      3462400 | elapsed time per iteration (ms): 257.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.330443E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108300/  200000 | consumed samples:      3465600 | elapsed time per iteration (ms): 257.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.338690E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   108400/  200000 | consumed samples:      3468800 | elapsed time per iteration (ms): 256.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.333239E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108500/  200000 | consumed samples:      3472000 | elapsed time per iteration (ms): 257.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305825E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108600/  200000 | consumed samples:      3475200 | elapsed time per iteration (ms): 271.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.324040E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108700/  200000 | consumed samples:      3478400 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.317121E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108800/  200000 | consumed samples:      3481600 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.344471E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108900/  200000 | consumed samples:      3484800 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.326355E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109000/  200000 | consumed samples:      3488000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.330991E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109100/  200000 | consumed samples:      3491200 | elapsed time per iteration (ms): 276.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.331954E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109200/  200000 | consumed samples:      3494400 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.320492E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109300/  200000 | consumed samples:      3497600 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.336065E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   109400/  200000 | consumed samples:      3500800 | elapsed time per iteration (ms): 277.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.322586E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109500/  200000 | consumed samples:      3504000 | elapsed time per iteration (ms): 265.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284646E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109600/  200000 | consumed samples:      3507200 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281842E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109700/  200000 | consumed samples:      3510400 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293372E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109800/  200000 | consumed samples:      3513600 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.299940E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109900/  200000 | consumed samples:      3516800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.285234E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110000/  200000 | consumed samples:      3520000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276800E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   110100/  200000 | consumed samples:      3523200 | elapsed time per iteration (ms): 285.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283854E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110200/  200000 | consumed samples:      3526400 | elapsed time per iteration (ms): 265.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302261E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110300/  200000 | consumed samples:      3529600 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.297510E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110400/  200000 | consumed samples:      3532800 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284969E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110500/  200000 | consumed samples:      3536000 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296623E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110600/  200000 | consumed samples:      3539200 | elapsed time per iteration (ms): 276.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302666E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110700/  200000 | consumed samples:      3542400 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307837E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110800/  200000 | consumed samples:      3545600 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311082E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110900/  200000 | consumed samples:      3548800 | elapsed time per iteration (ms): 273.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306677E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111000/  200000 | consumed samples:      3552000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310384E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111100/  200000 | consumed samples:      3555200 | elapsed time per iteration (ms): 271.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309484E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111200/  200000 | consumed samples:      3558400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309432E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111300/  200000 | consumed samples:      3561600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305337E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111400/  200000 | consumed samples:      3564800 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.334699E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111500/  200000 | consumed samples:      3568000 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314901E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111600/  200000 | consumed samples:      3571200 | elapsed time per iteration (ms): 285.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.332053E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111700/  200000 | consumed samples:      3574400 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.333008E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111800/  200000 | consumed samples:      3577600 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311893E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration   111900/  200000 | consumed samples:      3580800 | elapsed time per iteration (ms): 256.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.333605E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112000/  200000 | consumed samples:      3584000 | elapsed time per iteration (ms): 256.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.318608E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112100/  200000 | consumed samples:      3587200 | elapsed time per iteration (ms): 276.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.334807E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112200/  200000 | consumed samples:      3590400 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.338489E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112300/  200000 | consumed samples:      3593600 | elapsed time per iteration (ms): 268.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.341239E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112400/  200000 | consumed samples:      3596800 | elapsed time per iteration (ms): 266.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.343318E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112500/  200000 | consumed samples:      3600000 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.346754E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112600/  200000 | consumed samples:      3603200 | elapsed time per iteration (ms): 277.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284554E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112700/  200000 | consumed samples:      3606400 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.290563E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112800/  200000 | consumed samples:      3609600 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272558E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112900/  200000 | consumed samples:      3612800 | elapsed time per iteration (ms): 262.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275968E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113000/  200000 | consumed samples:      3616000 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275549E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113100/  200000 | consumed samples:      3619200 | elapsed time per iteration (ms): 287.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270932E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113200/  200000 | consumed samples:      3622400 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261381E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113300/  200000 | consumed samples:      3625600 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293390E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113400/  200000 | consumed samples:      3628800 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274364E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113500/  200000 | consumed samples:      3632000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298208E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113600/  200000 | consumed samples:      3635200 | elapsed time per iteration (ms): 276.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281285E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113700/  200000 | consumed samples:      3638400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296230E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113800/  200000 | consumed samples:      3641600 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293501E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113900/  200000 | consumed samples:      3644800 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.297405E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114000/  200000 | consumed samples:      3648000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310530E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114100/  200000 | consumed samples:      3651200 | elapsed time per iteration (ms): 273.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.317066E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114200/  200000 | consumed samples:      3654400 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.318503E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114300/  200000 | consumed samples:      3657600 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304580E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114400/  200000 | consumed samples:      3660800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308534E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114500/  200000 | consumed samples:      3664000 | elapsed time per iteration (ms): 271.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307513E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114600/  200000 | consumed samples:      3667200 | elapsed time per iteration (ms): 278.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315941E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114700/  200000 | consumed samples:      3670400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314087E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114800/  200000 | consumed samples:      3673600 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300761E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114900/  200000 | consumed samples:      3676800 | elapsed time per iteration (ms): 262.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304695E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115000/  200000 | consumed samples:      3680000 | elapsed time per iteration (ms): 256.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321451E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration   115100/  200000 | consumed samples:      3683200 | elapsed time per iteration (ms): 333.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.335643E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115200/  200000 | consumed samples:      3686400 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.331065E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115300/  200000 | consumed samples:      3689600 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.325671E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115400/  200000 | consumed samples:      3692800 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.345392E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115500/  200000 | consumed samples:      3696000 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.344679E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115600/  200000 | consumed samples:      3699200 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.334039E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115700/  200000 | consumed samples:      3702400 | elapsed time per iteration (ms): 268.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284110E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115800/  200000 | consumed samples:      3705600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.245741E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115900/  200000 | consumed samples:      3708800 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268548E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116000/  200000 | consumed samples:      3712000 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.279891E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116100/  200000 | consumed samples:      3715200 | elapsed time per iteration (ms): 270.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278122E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116200/  200000 | consumed samples:      3718400 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272623E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116300/  200000 | consumed samples:      3721600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284872E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116400/  200000 | consumed samples:      3724800 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295840E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116500/  200000 | consumed samples:      3728000 | elapsed time per iteration (ms): 257.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276847E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116600/  200000 | consumed samples:      3731200 | elapsed time per iteration (ms): 275.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295268E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116700/  200000 | consumed samples:      3734400 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292630E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116800/  200000 | consumed samples:      3737600 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288359E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116900/  200000 | consumed samples:      3740800 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274489E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117000/  200000 | consumed samples:      3744000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307365E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117100/  200000 | consumed samples:      3747200 | elapsed time per iteration (ms): 271.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306382E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117200/  200000 | consumed samples:      3750400 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.290820E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117300/  200000 | consumed samples:      3753600 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293185E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117400/  200000 | consumed samples:      3756800 | elapsed time per iteration (ms): 261.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306224E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117500/  200000 | consumed samples:      3760000 | elapsed time per iteration (ms): 269.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.303178E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   117600/  200000 | consumed samples:      3763200 | elapsed time per iteration (ms): 267.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.303742E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   117700/  200000 | consumed samples:      3766400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.326057E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117800/  200000 | consumed samples:      3769600 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289525E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117900/  200000 | consumed samples:      3772800 | elapsed time per iteration (ms): 256.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315488E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118000/  200000 | consumed samples:      3776000 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307519E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118100/  200000 | consumed samples:      3779200 | elapsed time per iteration (ms): 273.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314167E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118200/  200000 | consumed samples:      3782400 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310967E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118300/  200000 | consumed samples:      3785600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311481E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118400/  200000 | consumed samples:      3788800 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.332829E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   118500/  200000 | consumed samples:      3792000 | elapsed time per iteration (ms): 257.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.320137E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118600/  200000 | consumed samples:      3795200 | elapsed time per iteration (ms): 270.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.327950E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118700/  200000 | consumed samples:      3798400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.313561E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118800/  200000 | consumed samples:      3801600 | elapsed time per iteration (ms): 264.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300469E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118900/  200000 | consumed samples:      3804800 | elapsed time per iteration (ms): 273.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261094E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119000/  200000 | consumed samples:      3808000 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270238E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119100/  200000 | consumed samples:      3811200 | elapsed time per iteration (ms): 272.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284743E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119200/  200000 | consumed samples:      3814400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267909E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119300/  200000 | consumed samples:      3817600 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.273216E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119400/  200000 | consumed samples:      3820800 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268731E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119500/  200000 | consumed samples:      3824000 | elapsed time per iteration (ms): 262.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264674E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119600/  200000 | consumed samples:      3827200 | elapsed time per iteration (ms): 281.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.266097E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119700/  200000 | consumed samples:      3830400 | elapsed time per iteration (ms): 274.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261279E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119800/  200000 | consumed samples:      3833600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283129E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119900/  200000 | consumed samples:      3836800 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265670E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120000/  200000 | consumed samples:      3840000 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283703E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120100/  200000 | consumed samples:      3843200 | elapsed time per iteration (ms): 525.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300626E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120200/  200000 | consumed samples:      3846400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295080E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120300/  200000 | consumed samples:      3849600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.280798E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120400/  200000 | consumed samples:      3852800 | elapsed time per iteration (ms): 275.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.313214E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120500/  200000 | consumed samples:      3856000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301099E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120600/  200000 | consumed samples:      3859200 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293548E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120700/  200000 | consumed samples:      3862400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310259E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120800/  200000 | consumed samples:      3865600 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307032E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120900/  200000 | consumed samples:      3868800 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306473E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121000/  200000 | consumed samples:      3872000 | elapsed time per iteration (ms): 256.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305799E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121100/  200000 | consumed samples:      3875200 | elapsed time per iteration (ms): 290.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298829E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121200/  200000 | consumed samples:      3878400 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314839E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121300/  200000 | consumed samples:      3881600 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309939E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121400/  200000 | consumed samples:      3884800 | elapsed time per iteration (ms): 257.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308580E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   121500/  200000 | consumed samples:      3888000 | elapsed time per iteration (ms): 256.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.328717E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   121600/  200000 | consumed samples:      3891200 | elapsed time per iteration (ms): 271.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314268E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121700/  200000 | consumed samples:      3894400 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309185E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121800/  200000 | consumed samples:      3897600 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.331000E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121900/  200000 | consumed samples:      3900800 | elapsed time per iteration (ms): 276.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311786E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122000/  200000 | consumed samples:      3904000 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264720E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122100/  200000 | consumed samples:      3907200 | elapsed time per iteration (ms): 271.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265085E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122200/  200000 | consumed samples:      3910400 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268030E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122300/  200000 | consumed samples:      3913600 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.258812E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122400/  200000 | consumed samples:      3916800 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253050E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122500/  200000 | consumed samples:      3920000 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254072E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122600/  200000 | consumed samples:      3923200 | elapsed time per iteration (ms): 292.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260124E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122700/  200000 | consumed samples:      3926400 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254923E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122800/  200000 | consumed samples:      3929600 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268511E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122900/  200000 | consumed samples:      3932800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283466E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123000/  200000 | consumed samples:      3936000 | elapsed time per iteration (ms): 260.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.310157E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123100/  200000 | consumed samples:      3939200 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276814E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123200/  200000 | consumed samples:      3942400 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.279616E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123300/  200000 | consumed samples:      3945600 | elapsed time per iteration (ms): 275.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278558E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123400/  200000 | consumed samples:      3948800 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295152E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123500/  200000 | consumed samples:      3952000 | elapsed time per iteration (ms): 331.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278414E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123600/  200000 | consumed samples:      3955200 | elapsed time per iteration (ms): 270.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.312717E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   123700/  200000 | consumed samples:      3958400 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274206E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123800/  200000 | consumed samples:      3961600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302311E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123900/  200000 | consumed samples:      3964800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311155E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124000/  200000 | consumed samples:      3968000 | elapsed time per iteration (ms): 265.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289638E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124100/  200000 | consumed samples:      3971200 | elapsed time per iteration (ms): 278.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300376E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124200/  200000 | consumed samples:      3974400 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305835E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124300/  200000 | consumed samples:      3977600 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308074E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124400/  200000 | consumed samples:      3980800 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305531E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124500/  200000 | consumed samples:      3984000 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.316787E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124600/  200000 | consumed samples:      3987200 | elapsed time per iteration (ms): 276.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315009E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124700/  200000 | consumed samples:      3990400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.326234E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124800/  200000 | consumed samples:      3993600 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315939E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124900/  200000 | consumed samples:      3996800 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315853E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125000/  200000 | consumed samples:      4000000 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.326341E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125100/  200000 | consumed samples:      4003200 | elapsed time per iteration (ms): 277.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.251957E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   125200/  200000 | consumed samples:      4006400 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260733E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125300/  200000 | consumed samples:      4009600 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250541E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125400/  200000 | consumed samples:      4012800 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.258280E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125500/  200000 | consumed samples:      4016000 | elapsed time per iteration (ms): 268.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256207E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125600/  200000 | consumed samples:      4019200 | elapsed time per iteration (ms): 269.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253681E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   125700/  200000 | consumed samples:      4022400 | elapsed time per iteration (ms): 257.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269508E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125800/  200000 | consumed samples:      4025600 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253410E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125900/  200000 | consumed samples:      4028800 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265722E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126000/  200000 | consumed samples:      4032000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274034E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126100/  200000 | consumed samples:      4035200 | elapsed time per iteration (ms): 276.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272234E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126200/  200000 | consumed samples:      4038400 | elapsed time per iteration (ms): 266.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.287900E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126300/  200000 | consumed samples:      4041600 | elapsed time per iteration (ms): 266.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.266283E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126400/  200000 | consumed samples:      4044800 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.280166E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126500/  200000 | consumed samples:      4048000 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288531E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126600/  200000 | consumed samples:      4051200 | elapsed time per iteration (ms): 272.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278959E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126700/  200000 | consumed samples:      4054400 | elapsed time per iteration (ms): 261.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274369E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126800/  200000 | consumed samples:      4057600 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309648E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126900/  200000 | consumed samples:      4060800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288285E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127000/  200000 | consumed samples:      4064000 | elapsed time per iteration (ms): 276.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.291156E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127100/  200000 | consumed samples:      4067200 | elapsed time per iteration (ms): 272.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298073E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127200/  200000 | consumed samples:      4070400 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.291467E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127300/  200000 | consumed samples:      4073600 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.317723E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   127400/  200000 | consumed samples:      4076800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.323703E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   127500/  200000 | consumed samples:      4080000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.323787E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127600/  200000 | consumed samples:      4083200 | elapsed time per iteration (ms): 277.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300943E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127700/  200000 | consumed samples:      4086400 | elapsed time per iteration (ms): 274.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302558E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127800/  200000 | consumed samples:      4089600 | elapsed time per iteration (ms): 263.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.303011E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127900/  200000 | consumed samples:      4092800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.315674E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128000/  200000 | consumed samples:      4096000 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308709E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128100/  200000 | consumed samples:      4099200 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321316E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128200/  200000 | consumed samples:      4102400 | elapsed time per iteration (ms): 267.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267932E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128300/  200000 | consumed samples:      4105600 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243545E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128400/  200000 | consumed samples:      4108800 | elapsed time per iteration (ms): 268.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250149E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128500/  200000 | consumed samples:      4112000 | elapsed time per iteration (ms): 267.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.247511E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   128600/  200000 | consumed samples:      4115200 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263601E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128700/  200000 | consumed samples:      4118400 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.258482E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128800/  200000 | consumed samples:      4121600 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270172E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128900/  200000 | consumed samples:      4124800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261279E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129000/  200000 | consumed samples:      4128000 | elapsed time per iteration (ms): 257.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270944E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129100/  200000 | consumed samples:      4131200 | elapsed time per iteration (ms): 277.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270701E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129200/  200000 | consumed samples:      4134400 | elapsed time per iteration (ms): 277.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277421E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129300/  200000 | consumed samples:      4137600 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281478E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129400/  200000 | consumed samples:      4140800 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.266121E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129500/  200000 | consumed samples:      4144000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274621E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   129600/  200000 | consumed samples:      4147200 | elapsed time per iteration (ms): 272.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288871E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129700/  200000 | consumed samples:      4150400 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.286457E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129800/  200000 | consumed samples:      4153600 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277335E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129900/  200000 | consumed samples:      4156800 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293073E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130000/  200000 | consumed samples:      4160000 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289173E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130100/  200000 | consumed samples:      4163200 | elapsed time per iteration (ms): 271.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.286097E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130200/  200000 | consumed samples:      4166400 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302307E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   130300/  200000 | consumed samples:      4169600 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311326E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130400/  200000 | consumed samples:      4172800 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.294303E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130500/  200000 | consumed samples:      4176000 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305698E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130600/  200000 | consumed samples:      4179200 | elapsed time per iteration (ms): 282.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.291264E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130700/  200000 | consumed samples:      4182400 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.318421E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130800/  200000 | consumed samples:      4185600 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292134E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130900/  200000 | consumed samples:      4188800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.309119E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131000/  200000 | consumed samples:      4192000 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.333372E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131100/  200000 | consumed samples:      4195200 | elapsed time per iteration (ms): 271.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.299787E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   131200/  200000 | consumed samples:      4198400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311641E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131300/  200000 | consumed samples:      4201600 | elapsed time per iteration (ms): 266.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277848E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131400/  200000 | consumed samples:      4204800 | elapsed time per iteration (ms): 277.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243439E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131500/  200000 | consumed samples:      4208000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.238119E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131600/  200000 | consumed samples:      4211200 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257540E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131700/  200000 | consumed samples:      4214400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.244064E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131800/  200000 | consumed samples:      4217600 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.247124E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131900/  200000 | consumed samples:      4220800 | elapsed time per iteration (ms): 262.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253017E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132000/  200000 | consumed samples:      4224000 | elapsed time per iteration (ms): 336.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.251730E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132100/  200000 | consumed samples:      4227200 | elapsed time per iteration (ms): 292.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255516E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132200/  200000 | consumed samples:      4230400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278761E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132300/  200000 | consumed samples:      4233600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274719E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132400/  200000 | consumed samples:      4236800 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265139E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132500/  200000 | consumed samples:      4240000 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276770E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132600/  200000 | consumed samples:      4243200 | elapsed time per iteration (ms): 272.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275546E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132700/  200000 | consumed samples:      4246400 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278997E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132800/  200000 | consumed samples:      4249600 | elapsed time per iteration (ms): 269.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284530E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132900/  200000 | consumed samples:      4252800 | elapsed time per iteration (ms): 264.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265592E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133000/  200000 | consumed samples:      4256000 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.294373E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133100/  200000 | consumed samples:      4259200 | elapsed time per iteration (ms): 268.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288563E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration   133200/  200000 | consumed samples:      4262400 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301981E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133300/  200000 | consumed samples:      4265600 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.314586E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133400/  200000 | consumed samples:      4268800 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305898E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133500/  200000 | consumed samples:      4272000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.306515E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133600/  200000 | consumed samples:      4275200 | elapsed time per iteration (ms): 290.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302325E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133700/  200000 | consumed samples:      4278400 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.312084E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133800/  200000 | consumed samples:      4281600 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293769E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133900/  200000 | consumed samples:      4284800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292979E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134000/  200000 | consumed samples:      4288000 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.291772E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134100/  200000 | consumed samples:      4291200 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296151E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134200/  200000 | consumed samples:      4294400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302675E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134300/  200000 | consumed samples:      4297600 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307473E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134400/  200000 | consumed samples:      4300800 | elapsed time per iteration (ms): 265.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.305756E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134500/  200000 | consumed samples:      4304000 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.227917E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134600/  200000 | consumed samples:      4307200 | elapsed time per iteration (ms): 272.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241027E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134700/  200000 | consumed samples:      4310400 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264752E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134800/  200000 | consumed samples:      4313600 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250745E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134900/  200000 | consumed samples:      4316800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263693E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135000/  200000 | consumed samples:      4320000 | elapsed time per iteration (ms): 271.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243463E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135100/  200000 | consumed samples:      4323200 | elapsed time per iteration (ms): 276.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.239717E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135200/  200000 | consumed samples:      4326400 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254557E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135300/  200000 | consumed samples:      4329600 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270778E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135400/  200000 | consumed samples:      4332800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.262703E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135500/  200000 | consumed samples:      4336000 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254197E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135600/  200000 | consumed samples:      4339200 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257092E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135700/  200000 | consumed samples:      4342400 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264330E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135800/  200000 | consumed samples:      4345600 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268241E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135900/  200000 | consumed samples:      4348800 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.286760E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136000/  200000 | consumed samples:      4352000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277471E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136100/  200000 | consumed samples:      4355200 | elapsed time per iteration (ms): 271.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268336E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136200/  200000 | consumed samples:      4358400 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270696E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136300/  200000 | consumed samples:      4361600 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260179E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136400/  200000 | consumed samples:      4364800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281250E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136500/  200000 | consumed samples:      4368000 | elapsed time per iteration (ms): 274.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283951E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136600/  200000 | consumed samples:      4371200 | elapsed time per iteration (ms): 277.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283480E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136700/  200000 | consumed samples:      4374400 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298100E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136800/  200000 | consumed samples:      4377600 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.271347E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136900/  200000 | consumed samples:      4380800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.311765E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   137000/  200000 | consumed samples:      4384000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.297856E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137100/  200000 | consumed samples:      4387200 | elapsed time per iteration (ms): 275.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301109E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137200/  200000 | consumed samples:      4390400 | elapsed time per iteration (ms): 272.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300190E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137300/  200000 | consumed samples:      4393600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.302778E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137400/  200000 | consumed samples:      4396800 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307323E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   137500/  200000 | consumed samples:      4400000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.321306E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137600/  200000 | consumed samples:      4403200 | elapsed time per iteration (ms): 278.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.228525E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137700/  200000 | consumed samples:      4406400 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230353E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137800/  200000 | consumed samples:      4409600 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.232276E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137900/  200000 | consumed samples:      4412800 | elapsed time per iteration (ms): 262.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.238766E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138000/  200000 | consumed samples:      4416000 | elapsed time per iteration (ms): 274.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.245513E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138100/  200000 | consumed samples:      4419200 | elapsed time per iteration (ms): 277.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.249034E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138200/  200000 | consumed samples:      4422400 | elapsed time per iteration (ms): 263.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255566E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138300/  200000 | consumed samples:      4425600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250583E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138400/  200000 | consumed samples:      4428800 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257740E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138500/  200000 | consumed samples:      4432000 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268896E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   138600/  200000 | consumed samples:      4435200 | elapsed time per iteration (ms): 269.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257422E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   138700/  200000 | consumed samples:      4438400 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265859E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   138800/  200000 | consumed samples:      4441600 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259040E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138900/  200000 | consumed samples:      4444800 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270734E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139000/  200000 | consumed samples:      4448000 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284140E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139100/  200000 | consumed samples:      4451200 | elapsed time per iteration (ms): 272.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281647E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139200/  200000 | consumed samples:      4454400 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283052E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139300/  200000 | consumed samples:      4457600 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283821E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139400/  200000 | consumed samples:      4460800 | elapsed time per iteration (ms): 273.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275625E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139500/  200000 | consumed samples:      4464000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281568E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139600/  200000 | consumed samples:      4467200 | elapsed time per iteration (ms): 270.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288243E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139700/  200000 | consumed samples:      4470400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.297066E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139800/  200000 | consumed samples:      4473600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304355E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139900/  200000 | consumed samples:      4476800 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.290132E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140000/  200000 | consumed samples:      4480000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.294306E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140100/  200000 | consumed samples:      4483200 | elapsed time per iteration (ms): 517.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295996E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140200/  200000 | consumed samples:      4486400 | elapsed time per iteration (ms): 272.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.292445E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140300/  200000 | consumed samples:      4489600 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298661E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140400/  200000 | consumed samples:      4492800 | elapsed time per iteration (ms): 338.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.307845E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140500/  200000 | consumed samples:      4496000 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.304831E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140600/  200000 | consumed samples:      4499200 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.325665E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140700/  200000 | consumed samples:      4502400 | elapsed time per iteration (ms): 264.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265235E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140800/  200000 | consumed samples:      4505600 | elapsed time per iteration (ms): 264.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.235678E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140900/  200000 | consumed samples:      4508800 | elapsed time per iteration (ms): 271.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.237945E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141000/  200000 | consumed samples:      4512000 | elapsed time per iteration (ms): 261.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.232173E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141100/  200000 | consumed samples:      4515200 | elapsed time per iteration (ms): 273.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.248765E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141200/  200000 | consumed samples:      4518400 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253100E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141300/  200000 | consumed samples:      4521600 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.242789E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141400/  200000 | consumed samples:      4524800 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259124E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141500/  200000 | consumed samples:      4528000 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241848E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141600/  200000 | consumed samples:      4531200 | elapsed time per iteration (ms): 291.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259468E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141700/  200000 | consumed samples:      4534400 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.252126E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   141800/  200000 | consumed samples:      4537600 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.248506E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   141900/  200000 | consumed samples:      4540800 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.258545E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142000/  200000 | consumed samples:      4544000 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257805E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142100/  200000 | consumed samples:      4547200 | elapsed time per iteration (ms): 269.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270593E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142200/  200000 | consumed samples:      4550400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.287931E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142300/  200000 | consumed samples:      4553600 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.273840E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142400/  200000 | consumed samples:      4556800 | elapsed time per iteration (ms): 270.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263175E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142500/  200000 | consumed samples:      4560000 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.280384E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142600/  200000 | consumed samples:      4563200 | elapsed time per iteration (ms): 270.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.285507E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142700/  200000 | consumed samples:      4566400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272741E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142800/  200000 | consumed samples:      4569600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276713E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142900/  200000 | consumed samples:      4572800 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.282727E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143000/  200000 | consumed samples:      4576000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301895E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   143100/  200000 | consumed samples:      4579200 | elapsed time per iteration (ms): 286.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289964E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143200/  200000 | consumed samples:      4582400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293504E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143300/  200000 | consumed samples:      4585600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.279029E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143400/  200000 | consumed samples:      4588800 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296953E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143500/  200000 | consumed samples:      4592000 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.308035E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143600/  200000 | consumed samples:      4595200 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.291767E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143700/  200000 | consumed samples:      4598400 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301012E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   143800/  200000 | consumed samples:      4601600 | elapsed time per iteration (ms): 276.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255346E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143900/  200000 | consumed samples:      4604800 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.233854E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144000/  200000 | consumed samples:      4608000 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.244823E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144100/  200000 | consumed samples:      4611200 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.240600E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144200/  200000 | consumed samples:      4614400 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.218267E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144300/  200000 | consumed samples:      4617600 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.247921E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144400/  200000 | consumed samples:      4620800 | elapsed time per iteration (ms): 262.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.235679E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144500/  200000 | consumed samples:      4624000 | elapsed time per iteration (ms): 266.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241366E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144600/  200000 | consumed samples:      4627200 | elapsed time per iteration (ms): 288.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.234152E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144700/  200000 | consumed samples:      4630400 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.239995E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144800/  200000 | consumed samples:      4633600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.236668E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144900/  200000 | consumed samples:      4636800 | elapsed time per iteration (ms): 263.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261583E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145000/  200000 | consumed samples:      4640000 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260321E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145100/  200000 | consumed samples:      4643200 | elapsed time per iteration (ms): 275.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.266643E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   145200/  200000 | consumed samples:      4646400 | elapsed time per iteration (ms): 263.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.252836E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145300/  200000 | consumed samples:      4649600 | elapsed time per iteration (ms): 273.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274765E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145400/  200000 | consumed samples:      4652800 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260892E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145500/  200000 | consumed samples:      4656000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.280263E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145600/  200000 | consumed samples:      4659200 | elapsed time per iteration (ms): 275.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283062E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145700/  200000 | consumed samples:      4662400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267813E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145800/  200000 | consumed samples:      4665600 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.288657E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   145900/  200000 | consumed samples:      4668800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267426E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146000/  200000 | consumed samples:      4672000 | elapsed time per iteration (ms): 272.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300549E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146100/  200000 | consumed samples:      4675200 | elapsed time per iteration (ms): 279.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.278495E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146200/  200000 | consumed samples:      4678400 | elapsed time per iteration (ms): 262.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.284317E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146300/  200000 | consumed samples:      4681600 | elapsed time per iteration (ms): 262.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275240E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146400/  200000 | consumed samples:      4684800 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.301234E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146500/  200000 | consumed samples:      4688000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295234E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146600/  200000 | consumed samples:      4691200 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.296298E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146700/  200000 | consumed samples:      4694400 | elapsed time per iteration (ms): 265.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289994E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146800/  200000 | consumed samples:      4697600 | elapsed time per iteration (ms): 270.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298320E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146900/  200000 | consumed samples:      4700800 | elapsed time per iteration (ms): 265.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269016E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147000/  200000 | consumed samples:      4704000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.219096E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147100/  200000 | consumed samples:      4707200 | elapsed time per iteration (ms): 273.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.223444E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147200/  200000 | consumed samples:      4710400 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.249241E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147300/  200000 | consumed samples:      4713600 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.240355E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147400/  200000 | consumed samples:      4716800 | elapsed time per iteration (ms): 265.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.238547E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147500/  200000 | consumed samples:      4720000 | elapsed time per iteration (ms): 276.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.229972E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147600/  200000 | consumed samples:      4723200 | elapsed time per iteration (ms): 275.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.229701E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147700/  200000 | consumed samples:      4726400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243550E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147800/  200000 | consumed samples:      4729600 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.248390E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147900/  200000 | consumed samples:      4732800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243514E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148000/  200000 | consumed samples:      4736000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274376E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148100/  200000 | consumed samples:      4739200 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260820E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148200/  200000 | consumed samples:      4742400 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246045E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148300/  200000 | consumed samples:      4745600 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268275E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148400/  200000 | consumed samples:      4748800 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246073E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148500/  200000 | consumed samples:      4752000 | elapsed time per iteration (ms): 257.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260129E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148600/  200000 | consumed samples:      4755200 | elapsed time per iteration (ms): 273.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.261604E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148700/  200000 | consumed samples:      4758400 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.271515E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148800/  200000 | consumed samples:      4761600 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268732E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   148900/  200000 | consumed samples:      4764800 | elapsed time per iteration (ms): 346.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289065E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149000/  200000 | consumed samples:      4768000 | elapsed time per iteration (ms): 268.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.262849E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   149100/  200000 | consumed samples:      4771200 | elapsed time per iteration (ms): 276.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272240E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149200/  200000 | consumed samples:      4774400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277317E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149300/  200000 | consumed samples:      4777600 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269621E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149400/  200000 | consumed samples:      4780800 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.283091E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149500/  200000 | consumed samples:      4784000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281565E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149600/  200000 | consumed samples:      4787200 | elapsed time per iteration (ms): 269.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.281508E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149700/  200000 | consumed samples:      4790400 | elapsed time per iteration (ms): 269.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268571E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149800/  200000 | consumed samples:      4793600 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268338E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149900/  200000 | consumed samples:      4796800 | elapsed time per iteration (ms): 257.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.282138E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150000/  200000 | consumed samples:      4800000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.287811E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150100/  200000 | consumed samples:      4803200 | elapsed time per iteration (ms): 275.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230918E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150200/  200000 | consumed samples:      4806400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230886E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150300/  200000 | consumed samples:      4809600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.225736E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150400/  200000 | consumed samples:      4812800 | elapsed time per iteration (ms): 269.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.225662E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150500/  200000 | consumed samples:      4816000 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.229158E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150600/  200000 | consumed samples:      4819200 | elapsed time per iteration (ms): 276.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.231188E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150700/  200000 | consumed samples:      4822400 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.239235E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150800/  200000 | consumed samples:      4825600 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.234962E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150900/  200000 | consumed samples:      4828800 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.223402E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151000/  200000 | consumed samples:      4832000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250361E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151100/  200000 | consumed samples:      4835200 | elapsed time per iteration (ms): 279.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241185E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151200/  200000 | consumed samples:      4838400 | elapsed time per iteration (ms): 265.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246981E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   151300/  200000 | consumed samples:      4841600 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.222535E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151400/  200000 | consumed samples:      4844800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253492E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   151500/  200000 | consumed samples:      4848000 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.247277E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151600/  200000 | consumed samples:      4851200 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256529E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151700/  200000 | consumed samples:      4854400 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254355E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151800/  200000 | consumed samples:      4857600 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.265709E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151900/  200000 | consumed samples:      4860800 | elapsed time per iteration (ms): 270.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.274287E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152000/  200000 | consumed samples:      4864000 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246864E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152100/  200000 | consumed samples:      4867200 | elapsed time per iteration (ms): 274.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264120E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152200/  200000 | consumed samples:      4870400 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259987E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152300/  200000 | consumed samples:      4873600 | elapsed time per iteration (ms): 256.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269020E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152400/  200000 | consumed samples:      4876800 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.254416E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152500/  200000 | consumed samples:      4880000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277009E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152600/  200000 | consumed samples:      4883200 | elapsed time per iteration (ms): 280.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272333E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152700/  200000 | consumed samples:      4886400 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267603E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   152800/  200000 | consumed samples:      4889600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.289123E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152900/  200000 | consumed samples:      4892800 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.295189E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153000/  200000 | consumed samples:      4896000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272424E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153100/  200000 | consumed samples:      4899200 | elapsed time per iteration (ms): 272.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.300478E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153200/  200000 | consumed samples:      4902400 | elapsed time per iteration (ms): 266.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241463E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153300/  200000 | consumed samples:      4905600 | elapsed time per iteration (ms): 268.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.219276E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153400/  200000 | consumed samples:      4908800 | elapsed time per iteration (ms): 268.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.227735E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153500/  200000 | consumed samples:      4912000 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.229997E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153600/  200000 | consumed samples:      4915200 | elapsed time per iteration (ms): 280.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.215859E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153700/  200000 | consumed samples:      4918400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.222169E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   153800/  200000 | consumed samples:      4921600 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.240519E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153900/  200000 | consumed samples:      4924800 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.234311E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154000/  200000 | consumed samples:      4928000 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.232383E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154100/  200000 | consumed samples:      4931200 | elapsed time per iteration (ms): 286.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.232243E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154200/  200000 | consumed samples:      4934400 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256179E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154300/  200000 | consumed samples:      4937600 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255256E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154400/  200000 | consumed samples:      4940800 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.258312E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154500/  200000 | consumed samples:      4944000 | elapsed time per iteration (ms): 257.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246642E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   154600/  200000 | consumed samples:      4947200 | elapsed time per iteration (ms): 274.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.249681E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154700/  200000 | consumed samples:      4950400 | elapsed time per iteration (ms): 263.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.252349E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154800/  200000 | consumed samples:      4953600 | elapsed time per iteration (ms): 271.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.251328E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154900/  200000 | consumed samples:      4956800 | elapsed time per iteration (ms): 261.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267425E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155000/  200000 | consumed samples:      4960000 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256491E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155100/  200000 | consumed samples:      4963200 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256013E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155200/  200000 | consumed samples:      4966400 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272479E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155300/  200000 | consumed samples:      4969600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.253224E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155400/  200000 | consumed samples:      4972800 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263961E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   155500/  200000 | consumed samples:      4976000 | elapsed time per iteration (ms): 266.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263263E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155600/  200000 | consumed samples:      4979200 | elapsed time per iteration (ms): 285.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259435E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155700/  200000 | consumed samples:      4982400 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277752E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155800/  200000 | consumed samples:      4985600 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.298561E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155900/  200000 | consumed samples:      4988800 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.276287E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156000/  200000 | consumed samples:      4992000 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268461E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156100/  200000 | consumed samples:      4995200 | elapsed time per iteration (ms): 273.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270556E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156200/  200000 | consumed samples:      4998400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.275432E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156300/  200000 | consumed samples:      5001600 | elapsed time per iteration (ms): 282.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260223E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156400/  200000 | consumed samples:      5004800 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.218551E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156500/  200000 | consumed samples:      5008000 | elapsed time per iteration (ms): 262.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.208749E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156600/  200000 | consumed samples:      5011200 | elapsed time per iteration (ms): 271.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.221626E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156700/  200000 | consumed samples:      5014400 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.227851E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156800/  200000 | consumed samples:      5017600 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.214450E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156900/  200000 | consumed samples:      5020800 | elapsed time per iteration (ms): 260.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.234057E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157000/  200000 | consumed samples:      5024000 | elapsed time per iteration (ms): 271.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.228744E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157100/  200000 | consumed samples:      5027200 | elapsed time per iteration (ms): 280.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.228694E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157200/  200000 | consumed samples:      5030400 | elapsed time per iteration (ms): 262.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.243780E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157300/  200000 | consumed samples:      5033600 | elapsed time per iteration (ms): 262.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.246085E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157400/  200000 | consumed samples:      5036800 | elapsed time per iteration (ms): 344.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230619E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157500/  200000 | consumed samples:      5040000 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.237502E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157600/  200000 | consumed samples:      5043200 | elapsed time per iteration (ms): 276.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.239241E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157700/  200000 | consumed samples:      5046400 | elapsed time per iteration (ms): 267.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250908E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157800/  200000 | consumed samples:      5049600 | elapsed time per iteration (ms): 269.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.245378E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   157900/  200000 | consumed samples:      5052800 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.247906E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158000/  200000 | consumed samples:      5056000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.256022E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158100/  200000 | consumed samples:      5059200 | elapsed time per iteration (ms): 270.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.248990E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158200/  200000 | consumed samples:      5062400 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.271527E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158300/  200000 | consumed samples:      5065600 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260759E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158400/  200000 | consumed samples:      5068800 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.259821E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158500/  200000 | consumed samples:      5072000 | elapsed time per iteration (ms): 271.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272749E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158600/  200000 | consumed samples:      5075200 | elapsed time per iteration (ms): 275.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272971E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158700/  200000 | consumed samples:      5078400 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268994E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158800/  200000 | consumed samples:      5081600 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.268603E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158900/  200000 | consumed samples:      5084800 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.277544E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159000/  200000 | consumed samples:      5088000 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272606E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159100/  200000 | consumed samples:      5091200 | elapsed time per iteration (ms): 270.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269322E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159200/  200000 | consumed samples:      5094400 | elapsed time per iteration (ms): 269.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.293704E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159300/  200000 | consumed samples:      5097600 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267501E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159400/  200000 | consumed samples:      5100800 | elapsed time per iteration (ms): 265.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270092E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159500/  200000 | consumed samples:      5104000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.217395E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159600/  200000 | consumed samples:      5107200 | elapsed time per iteration (ms): 270.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.205521E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159700/  200000 | consumed samples:      5110400 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.217775E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159800/  200000 | consumed samples:      5113600 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.206438E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   159900/  200000 | consumed samples:      5116800 | elapsed time per iteration (ms): 267.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.222833E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160000/  200000 | consumed samples:      5120000 | elapsed time per iteration (ms): 266.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.225426E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160100/  200000 | consumed samples:      5123200 | elapsed time per iteration (ms): 500.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230386E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160200/  200000 | consumed samples:      5126400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.233156E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160300/  200000 | consumed samples:      5129600 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.240759E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160400/  200000 | consumed samples:      5132800 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.223496E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160500/  200000 | consumed samples:      5136000 | elapsed time per iteration (ms): 264.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.244941E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160600/  200000 | consumed samples:      5139200 | elapsed time per iteration (ms): 275.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.230397E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160700/  200000 | consumed samples:      5142400 | elapsed time per iteration (ms): 273.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.250929E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160800/  200000 | consumed samples:      5145600 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.233353E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   160900/  200000 | consumed samples:      5148800 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.242297E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161000/  200000 | consumed samples:      5152000 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255392E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161100/  200000 | consumed samples:      5155200 | elapsed time per iteration (ms): 273.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263076E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161200/  200000 | consumed samples:      5158400 | elapsed time per iteration (ms): 262.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257017E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161300/  200000 | consumed samples:      5161600 | elapsed time per iteration (ms): 264.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.257862E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161400/  200000 | consumed samples:      5164800 | elapsed time per iteration (ms): 275.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260684E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161500/  200000 | consumed samples:      5168000 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.241700E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   161600/  200000 | consumed samples:      5171200 | elapsed time per iteration (ms): 274.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.255969E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   161700/  200000 | consumed samples:      5174400 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.263357E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161800/  200000 | consumed samples:      5177600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.267116E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161900/  200000 | consumed samples:      5180800 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.260545E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162000/  200000 | consumed samples:      5184000 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.270196E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162100/  200000 | consumed samples:      5187200 | elapsed time per iteration (ms): 279.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.272460E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162200/  200000 | consumed samples:      5190400 | elapsed time per iteration (ms): 268.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.262572E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162300/  200000 | consumed samples:      5193600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.264824E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162400/  200000 | consumed samples:      5196800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.280967E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162500/  200000 | consumed samples:      5200000 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.269312E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162600/  200000 | consumed samples:      5203200 | elapsed time per iteration (ms): 282.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.200124E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162700/  200000 | consumed samples:      5206400 | elapsed time per iteration (ms): 264.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.183944E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162800/  200000 | consumed samples:      5209600 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.194130E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162900/  200000 | consumed samples:      5212800 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.188399E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163000/  200000 | consumed samples:      5216000 | elapsed time per iteration (ms): 264.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.174165E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163100/  200000 | consumed samples:      5219200 | elapsed time per iteration (ms): 277.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.205831E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163200/  200000 | consumed samples:      5222400 | elapsed time per iteration (ms): 263.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.223372E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163300/  200000 | consumed samples:      5225600 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.220923E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163400/  200000 | consumed samples:      5228800 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.201921E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163500/  200000 | consumed samples:      5232000 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.193133E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163600/  200000 | consumed samples:      5235200 | elapsed time per iteration (ms): 285.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.198814E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163700/  200000 | consumed samples:      5238400 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.188917E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163800/  200000 | consumed samples:      5241600 | elapsed time per iteration (ms): 261.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.208644E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163900/  200000 | consumed samples:      5244800 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.201002E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164000/  200000 | consumed samples:      5248000 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.213497E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164100/  200000 | consumed samples:      5251200 | elapsed time per iteration (ms): 271.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.197492E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164200/  200000 | consumed samples:      5254400 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.200137E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164300/  200000 | consumed samples:      5257600 | elapsed time per iteration (ms): 270.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.195833E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164400/  200000 | consumed samples:      5260800 | elapsed time per iteration (ms): 263.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.198243E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164500/  200000 | consumed samples:      5264000 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.198264E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164600/  200000 | consumed samples:      5267200 | elapsed time per iteration (ms): 276.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.190588E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   164700/  200000 | consumed samples:      5270400 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.211427E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164800/  200000 | consumed samples:      5273600 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.194932E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164900/  200000 | consumed samples:      5276800 | elapsed time per iteration (ms): 263.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.203455E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165000/  200000 | consumed samples:      5280000 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.202429E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165100/  200000 | consumed samples:      5283200 | elapsed time per iteration (ms): 285.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.221389E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165200/  200000 | consumed samples:      5286400 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.213672E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165300/  200000 | consumed samples:      5289600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.201435E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165400/  200000 | consumed samples:      5292800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.199574E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165500/  200000 | consumed samples:      5296000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.206182E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165600/  200000 | consumed samples:      5299200 | elapsed time per iteration (ms): 272.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.228100E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   165700/  200000 | consumed samples:      5302400 | elapsed time per iteration (ms): 268.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.169757E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165800/  200000 | consumed samples:      5305600 | elapsed time per iteration (ms): 360.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.150124E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165900/  200000 | consumed samples:      5308800 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.146524E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166000/  200000 | consumed samples:      5312000 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.154282E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166100/  200000 | consumed samples:      5315200 | elapsed time per iteration (ms): 278.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.138475E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166200/  200000 | consumed samples:      5318400 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.154160E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166300/  200000 | consumed samples:      5321600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.156959E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166400/  200000 | consumed samples:      5324800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.137528E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166500/  200000 | consumed samples:      5328000 | elapsed time per iteration (ms): 268.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.154230E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166600/  200000 | consumed samples:      5331200 | elapsed time per iteration (ms): 272.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.152955E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   166700/  200000 | consumed samples:      5334400 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.140411E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166800/  200000 | consumed samples:      5337600 | elapsed time per iteration (ms): 258.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.142313E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166900/  200000 | consumed samples:      5340800 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.142419E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167000/  200000 | consumed samples:      5344000 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.139507E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167100/  200000 | consumed samples:      5347200 | elapsed time per iteration (ms): 269.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.155076E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167200/  200000 | consumed samples:      5350400 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.159779E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167300/  200000 | consumed samples:      5353600 | elapsed time per iteration (ms): 271.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.143094E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167400/  200000 | consumed samples:      5356800 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.143954E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167500/  200000 | consumed samples:      5360000 | elapsed time per iteration (ms): 258.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.145209E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167600/  200000 | consumed samples:      5363200 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.142645E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   167700/  200000 | consumed samples:      5366400 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.146130E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167800/  200000 | consumed samples:      5369600 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.146053E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167900/  200000 | consumed samples:      5372800 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.152947E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   168000/  200000 | consumed samples:      5376000 | elapsed time per iteration (ms): 270.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.149859E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168100/  200000 | consumed samples:      5379200 | elapsed time per iteration (ms): 267.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.156217E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168200/  200000 | consumed samples:      5382400 | elapsed time per iteration (ms): 256.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.150264E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168300/  200000 | consumed samples:      5385600 | elapsed time per iteration (ms): 257.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.168785E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168400/  200000 | consumed samples:      5388800 | elapsed time per iteration (ms): 257.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.167680E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168500/  200000 | consumed samples:      5392000 | elapsed time per iteration (ms): 256.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.154192E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168600/  200000 | consumed samples:      5395200 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.149339E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168700/  200000 | consumed samples:      5398400 | elapsed time per iteration (ms): 267.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.147033E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168800/  200000 | consumed samples:      5401600 | elapsed time per iteration (ms): 267.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.136708E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168900/  200000 | consumed samples:      5404800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.115787E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169000/  200000 | consumed samples:      5408000 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.109129E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169100/  200000 | consumed samples:      5411200 | elapsed time per iteration (ms): 277.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.102906E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169200/  200000 | consumed samples:      5414400 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120349E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169300/  200000 | consumed samples:      5417600 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.124788E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169400/  200000 | consumed samples:      5420800 | elapsed time per iteration (ms): 264.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106895E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169500/  200000 | consumed samples:      5424000 | elapsed time per iteration (ms): 269.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.113213E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169600/  200000 | consumed samples:      5427200 | elapsed time per iteration (ms): 274.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.104585E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169700/  200000 | consumed samples:      5430400 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.118935E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169800/  200000 | consumed samples:      5433600 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.127154E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169900/  200000 | consumed samples:      5436800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.116936E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   170000/  200000 | consumed samples:      5440000 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.122816E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170100/  200000 | consumed samples:      5443200 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120557E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170200/  200000 | consumed samples:      5446400 | elapsed time per iteration (ms): 272.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.122624E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170300/  200000 | consumed samples:      5449600 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.132311E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170400/  200000 | consumed samples:      5452800 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.115992E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170500/  200000 | consumed samples:      5456000 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.116390E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   170600/  200000 | consumed samples:      5459200 | elapsed time per iteration (ms): 269.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.132204E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170700/  200000 | consumed samples:      5462400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126542E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170800/  200000 | consumed samples:      5465600 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126570E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170900/  200000 | consumed samples:      5468800 | elapsed time per iteration (ms): 269.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120199E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171000/  200000 | consumed samples:      5472000 | elapsed time per iteration (ms): 266.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.117489E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171100/  200000 | consumed samples:      5475200 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.121830E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171200/  200000 | consumed samples:      5478400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126299E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171300/  200000 | consumed samples:      5481600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.123249E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171400/  200000 | consumed samples:      5484800 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.116336E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171500/  200000 | consumed samples:      5488000 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.123721E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171600/  200000 | consumed samples:      5491200 | elapsed time per iteration (ms): 274.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.123049E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171700/  200000 | consumed samples:      5494400 | elapsed time per iteration (ms): 271.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126931E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171800/  200000 | consumed samples:      5497600 | elapsed time per iteration (ms): 257.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.140336E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171900/  200000 | consumed samples:      5500800 | elapsed time per iteration (ms): 265.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.107727E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172000/  200000 | consumed samples:      5504000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.101625E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172100/  200000 | consumed samples:      5507200 | elapsed time per iteration (ms): 274.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.101327E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172200/  200000 | consumed samples:      5510400 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.096947E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172300/  200000 | consumed samples:      5513600 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.101330E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172400/  200000 | consumed samples:      5516800 | elapsed time per iteration (ms): 275.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.101972E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172500/  200000 | consumed samples:      5520000 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.112982E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172600/  200000 | consumed samples:      5523200 | elapsed time per iteration (ms): 276.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.110229E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   172700/  200000 | consumed samples:      5526400 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.100163E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172800/  200000 | consumed samples:      5529600 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106587E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172900/  200000 | consumed samples:      5532800 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.096238E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173000/  200000 | consumed samples:      5536000 | elapsed time per iteration (ms): 261.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.098087E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173100/  200000 | consumed samples:      5539200 | elapsed time per iteration (ms): 282.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.100422E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173200/  200000 | consumed samples:      5542400 | elapsed time per iteration (ms): 264.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.097255E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173300/  200000 | consumed samples:      5545600 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.099247E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173400/  200000 | consumed samples:      5548800 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.101497E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173500/  200000 | consumed samples:      5552000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.113429E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173600/  200000 | consumed samples:      5555200 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106395E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   173700/  200000 | consumed samples:      5558400 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.105275E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173800/  200000 | consumed samples:      5561600 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.105932E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration   173900/  200000 | consumed samples:      5564800 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.104985E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174000/  200000 | consumed samples:      5568000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.110082E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174100/  200000 | consumed samples:      5571200 | elapsed time per iteration (ms): 286.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.119526E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174200/  200000 | consumed samples:      5574400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.115006E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174300/  200000 | consumed samples:      5577600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106532E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174400/  200000 | consumed samples:      5580800 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106603E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174500/  200000 | consumed samples:      5584000 | elapsed time per iteration (ms): 262.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.113052E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174600/  200000 | consumed samples:      5587200 | elapsed time per iteration (ms): 376.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.119233E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174700/  200000 | consumed samples:      5590400 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.097145E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174800/  200000 | consumed samples:      5593600 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.105479E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174900/  200000 | consumed samples:      5596800 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.098902E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175000/  200000 | consumed samples:      5600000 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.094129E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175100/  200000 | consumed samples:      5603200 | elapsed time per iteration (ms): 278.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.088611E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175200/  200000 | consumed samples:      5606400 | elapsed time per iteration (ms): 262.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.085587E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175300/  200000 | consumed samples:      5609600 | elapsed time per iteration (ms): 268.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.087277E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175400/  200000 | consumed samples:      5612800 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.088968E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175500/  200000 | consumed samples:      5616000 | elapsed time per iteration (ms): 257.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.094894E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175600/  200000 | consumed samples:      5619200 | elapsed time per iteration (ms): 275.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086808E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175700/  200000 | consumed samples:      5622400 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.076476E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175800/  200000 | consumed samples:      5625600 | elapsed time per iteration (ms): 257.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.099069E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175900/  200000 | consumed samples:      5628800 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.097855E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176000/  200000 | consumed samples:      5632000 | elapsed time per iteration (ms): 263.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.091785E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176100/  200000 | consumed samples:      5635200 | elapsed time per iteration (ms): 276.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.085098E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176200/  200000 | consumed samples:      5638400 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.092567E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176300/  200000 | consumed samples:      5641600 | elapsed time per iteration (ms): 258.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.090799E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176400/  200000 | consumed samples:      5644800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.078686E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176500/  200000 | consumed samples:      5648000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083217E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176600/  200000 | consumed samples:      5651200 | elapsed time per iteration (ms): 270.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.089440E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176700/  200000 | consumed samples:      5654400 | elapsed time per iteration (ms): 262.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.091283E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176800/  200000 | consumed samples:      5657600 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.092441E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176900/  200000 | consumed samples:      5660800 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.094401E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177000/  200000 | consumed samples:      5664000 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.079465E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177100/  200000 | consumed samples:      5667200 | elapsed time per iteration (ms): 276.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.080363E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177200/  200000 | consumed samples:      5670400 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.090878E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177300/  200000 | consumed samples:      5673600 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086819E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177400/  200000 | consumed samples:      5676800 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.089930E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177500/  200000 | consumed samples:      5680000 | elapsed time per iteration (ms): 268.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.095410E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177600/  200000 | consumed samples:      5683200 | elapsed time per iteration (ms): 271.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.095411E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177700/  200000 | consumed samples:      5686400 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.080012E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   177800/  200000 | consumed samples:      5689600 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.092497E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177900/  200000 | consumed samples:      5692800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.100547E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178000/  200000 | consumed samples:      5696000 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.105654E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178100/  200000 | consumed samples:      5699200 | elapsed time per iteration (ms): 272.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.093815E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178200/  200000 | consumed samples:      5702400 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.081823E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178300/  200000 | consumed samples:      5705600 | elapsed time per iteration (ms): 270.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086848E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178400/  200000 | consumed samples:      5708800 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.085423E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178500/  200000 | consumed samples:      5712000 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.072881E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178600/  200000 | consumed samples:      5715200 | elapsed time per iteration (ms): 275.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083525E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178700/  200000 | consumed samples:      5718400 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068518E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   178800/  200000 | consumed samples:      5721600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073026E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178900/  200000 | consumed samples:      5724800 | elapsed time per iteration (ms): 262.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074952E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179000/  200000 | consumed samples:      5728000 | elapsed time per iteration (ms): 273.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086556E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179100/  200000 | consumed samples:      5731200 | elapsed time per iteration (ms): 272.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.084452E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179200/  200000 | consumed samples:      5734400 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074372E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179300/  200000 | consumed samples:      5737600 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083526E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179400/  200000 | consumed samples:      5740800 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.084358E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179500/  200000 | consumed samples:      5744000 | elapsed time per iteration (ms): 263.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.082450E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179600/  200000 | consumed samples:      5747200 | elapsed time per iteration (ms): 277.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083133E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179700/  200000 | consumed samples:      5750400 | elapsed time per iteration (ms): 271.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.079765E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   179800/  200000 | consumed samples:      5753600 | elapsed time per iteration (ms): 264.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.070757E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   179900/  200000 | consumed samples:      5756800 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.076275E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180000/  200000 | consumed samples:      5760000 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.081343E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180100/  200000 | consumed samples:      5763200 | elapsed time per iteration (ms): 522.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086613E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180200/  200000 | consumed samples:      5766400 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.080432E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180300/  200000 | consumed samples:      5769600 | elapsed time per iteration (ms): 262.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073811E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180400/  200000 | consumed samples:      5772800 | elapsed time per iteration (ms): 264.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.075109E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180500/  200000 | consumed samples:      5776000 | elapsed time per iteration (ms): 271.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.088142E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180600/  200000 | consumed samples:      5779200 | elapsed time per iteration (ms): 271.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.080937E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   180700/  200000 | consumed samples:      5782400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.096082E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180800/  200000 | consumed samples:      5785600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.091142E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180900/  200000 | consumed samples:      5788800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083862E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181000/  200000 | consumed samples:      5792000 | elapsed time per iteration (ms): 260.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.084035E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181100/  200000 | consumed samples:      5795200 | elapsed time per iteration (ms): 282.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.082774E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181200/  200000 | consumed samples:      5798400 | elapsed time per iteration (ms): 273.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071295E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181300/  200000 | consumed samples:      5801600 | elapsed time per iteration (ms): 266.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.076894E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181400/  200000 | consumed samples:      5804800 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.067901E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181500/  200000 | consumed samples:      5808000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074643E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181600/  200000 | consumed samples:      5811200 | elapsed time per iteration (ms): 277.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068492E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181700/  200000 | consumed samples:      5814400 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.079343E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181800/  200000 | consumed samples:      5817600 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074212E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181900/  200000 | consumed samples:      5820800 | elapsed time per iteration (ms): 272.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074725E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182000/  200000 | consumed samples:      5824000 | elapsed time per iteration (ms): 268.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.070697E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182100/  200000 | consumed samples:      5827200 | elapsed time per iteration (ms): 282.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.069264E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182200/  200000 | consumed samples:      5830400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068549E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182300/  200000 | consumed samples:      5833600 | elapsed time per iteration (ms): 257.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065985E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   182400/  200000 | consumed samples:      5836800 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071703E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182500/  200000 | consumed samples:      5840000 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.081193E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182600/  200000 | consumed samples:      5843200 | elapsed time per iteration (ms): 280.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.077068E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182700/  200000 | consumed samples:      5846400 | elapsed time per iteration (ms): 270.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.072343E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182800/  200000 | consumed samples:      5849600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071044E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182900/  200000 | consumed samples:      5852800 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066450E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183000/  200000 | consumed samples:      5856000 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066483E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183100/  200000 | consumed samples:      5859200 | elapsed time per iteration (ms): 276.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.072278E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183200/  200000 | consumed samples:      5862400 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.069766E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183300/  200000 | consumed samples:      5865600 | elapsed time per iteration (ms): 256.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068078E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183400/  200000 | consumed samples:      5868800 | elapsed time per iteration (ms): 271.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.070702E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183500/  200000 | consumed samples:      5872000 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.075099E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   183600/  200000 | consumed samples:      5875200 | elapsed time per iteration (ms): 269.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.085013E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183700/  200000 | consumed samples:      5878400 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068785E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183800/  200000 | consumed samples:      5881600 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.062045E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183900/  200000 | consumed samples:      5884800 | elapsed time per iteration (ms): 358.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068805E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184000/  200000 | consumed samples:      5888000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073772E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184100/  200000 | consumed samples:      5891200 | elapsed time per iteration (ms): 281.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083381E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184200/  200000 | consumed samples:      5894400 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071946E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184300/  200000 | consumed samples:      5897600 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.061211E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184400/  200000 | consumed samples:      5900800 | elapsed time per iteration (ms): 265.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074769E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184500/  200000 | consumed samples:      5904000 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060253E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184600/  200000 | consumed samples:      5907200 | elapsed time per iteration (ms): 275.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.077384E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184700/  200000 | consumed samples:      5910400 | elapsed time per iteration (ms): 261.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.052858E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184800/  200000 | consumed samples:      5913600 | elapsed time per iteration (ms): 265.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.086069E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184900/  200000 | consumed samples:      5916800 | elapsed time per iteration (ms): 265.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.062117E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185000/  200000 | consumed samples:      5920000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.058440E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185100/  200000 | consumed samples:      5923200 | elapsed time per iteration (ms): 271.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.058521E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185200/  200000 | consumed samples:      5926400 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.067998E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185300/  200000 | consumed samples:      5929600 | elapsed time per iteration (ms): 259.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065311E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185400/  200000 | consumed samples:      5932800 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.055257E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185500/  200000 | consumed samples:      5936000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.053355E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185600/  200000 | consumed samples:      5939200 | elapsed time per iteration (ms): 281.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.056709E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185700/  200000 | consumed samples:      5942400 | elapsed time per iteration (ms): 257.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.058475E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185800/  200000 | consumed samples:      5945600 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.052745E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185900/  200000 | consumed samples:      5948800 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.072867E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186000/  200000 | consumed samples:      5952000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.070124E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186100/  200000 | consumed samples:      5955200 | elapsed time per iteration (ms): 271.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066494E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186200/  200000 | consumed samples:      5958400 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066510E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186300/  200000 | consumed samples:      5961600 | elapsed time per iteration (ms): 270.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.061750E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186400/  200000 | consumed samples:      5964800 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.055488E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186500/  200000 | consumed samples:      5968000 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068889E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   186600/  200000 | consumed samples:      5971200 | elapsed time per iteration (ms): 275.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066633E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186700/  200000 | consumed samples:      5974400 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.067252E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186800/  200000 | consumed samples:      5977600 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068749E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186900/  200000 | consumed samples:      5980800 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059654E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187000/  200000 | consumed samples:      5984000 | elapsed time per iteration (ms): 263.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.055153E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187100/  200000 | consumed samples:      5987200 | elapsed time per iteration (ms): 279.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065859E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187200/  200000 | consumed samples:      5990400 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065315E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187300/  200000 | consumed samples:      5993600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.057157E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187400/  200000 | consumed samples:      5996800 | elapsed time per iteration (ms): 257.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065723E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187500/  200000 | consumed samples:      6000000 | elapsed time per iteration (ms): 257.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.078610E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   187600/  200000 | consumed samples:      6003200 | elapsed time per iteration (ms): 279.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.039907E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187700/  200000 | consumed samples:      6006400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.077934E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187800/  200000 | consumed samples:      6009600 | elapsed time per iteration (ms): 271.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.069839E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187900/  200000 | consumed samples:      6012800 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.054250E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188000/  200000 | consumed samples:      6016000 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.054959E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188100/  200000 | consumed samples:      6019200 | elapsed time per iteration (ms): 279.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.051376E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188200/  200000 | consumed samples:      6022400 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.050897E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188300/  200000 | consumed samples:      6025600 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.053377E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188400/  200000 | consumed samples:      6028800 | elapsed time per iteration (ms): 259.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059241E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188500/  200000 | consumed samples:      6032000 | elapsed time per iteration (ms): 270.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.052619E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   188600/  200000 | consumed samples:      6035200 | elapsed time per iteration (ms): 273.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065623E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188700/  200000 | consumed samples:      6038400 | elapsed time per iteration (ms): 258.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059663E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   188800/  200000 | consumed samples:      6041600 | elapsed time per iteration (ms): 264.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060753E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188900/  200000 | consumed samples:      6044800 | elapsed time per iteration (ms): 257.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.055550E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189000/  200000 | consumed samples:      6048000 | elapsed time per iteration (ms): 259.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060761E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189100/  200000 | consumed samples:      6051200 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071333E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189200/  200000 | consumed samples:      6054400 | elapsed time per iteration (ms): 266.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059049E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189300/  200000 | consumed samples:      6057600 | elapsed time per iteration (ms): 268.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.050897E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189400/  200000 | consumed samples:      6060800 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.045807E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189500/  200000 | consumed samples:      6064000 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.063733E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189600/  200000 | consumed samples:      6067200 | elapsed time per iteration (ms): 280.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059211E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189700/  200000 | consumed samples:      6070400 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060878E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189800/  200000 | consumed samples:      6073600 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.067352E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189900/  200000 | consumed samples:      6076800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066724E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190000/  200000 | consumed samples:      6080000 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074373E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190100/  200000 | consumed samples:      6083200 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.080996E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190200/  200000 | consumed samples:      6086400 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064425E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190300/  200000 | consumed samples:      6089600 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064381E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190400/  200000 | consumed samples:      6092800 | elapsed time per iteration (ms): 257.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.068555E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190500/  200000 | consumed samples:      6096000 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060953E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190600/  200000 | consumed samples:      6099200 | elapsed time per iteration (ms): 274.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.057030E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190700/  200000 | consumed samples:      6102400 | elapsed time per iteration (ms): 277.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074546E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190800/  200000 | consumed samples:      6105600 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.054657E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190900/  200000 | consumed samples:      6108800 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.052057E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191000/  200000 | consumed samples:      6112000 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.050854E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191100/  200000 | consumed samples:      6115200 | elapsed time per iteration (ms): 281.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.069816E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191200/  200000 | consumed samples:      6118400 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064359E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191300/  200000 | consumed samples:      6121600 | elapsed time per iteration (ms): 263.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060788E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191400/  200000 | consumed samples:      6124800 | elapsed time per iteration (ms): 267.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074601E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191500/  200000 | consumed samples:      6128000 | elapsed time per iteration (ms): 269.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073551E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191600/  200000 | consumed samples:      6131200 | elapsed time per iteration (ms): 274.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.060859E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   191700/  200000 | consumed samples:      6134400 | elapsed time per iteration (ms): 262.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059956E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191800/  200000 | consumed samples:      6137600 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.055339E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191900/  200000 | consumed samples:      6140800 | elapsed time per iteration (ms): 262.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066042E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192000/  200000 | consumed samples:      6144000 | elapsed time per iteration (ms): 266.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.065390E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192100/  200000 | consumed samples:      6147200 | elapsed time per iteration (ms): 276.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.057146E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192200/  200000 | consumed samples:      6150400 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.061220E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192300/  200000 | consumed samples:      6153600 | elapsed time per iteration (ms): 263.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.059694E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192400/  200000 | consumed samples:      6156800 | elapsed time per iteration (ms): 261.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064545E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192500/  200000 | consumed samples:      6160000 | elapsed time per iteration (ms): 261.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066202E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192600/  200000 | consumed samples:      6163200 | elapsed time per iteration (ms): 277.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073767E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   192700/  200000 | consumed samples:      6166400 | elapsed time per iteration (ms): 264.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.075907E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192800/  200000 | consumed samples:      6169600 | elapsed time per iteration (ms): 258.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.069244E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192900/  200000 | consumed samples:      6172800 | elapsed time per iteration (ms): 276.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066824E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   193000/  200000 | consumed samples:      6176000 | elapsed time per iteration (ms): 264.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066125E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193100/  200000 | consumed samples:      6179200 | elapsed time per iteration (ms): 275.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.085331E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193200/  200000 | consumed samples:      6182400 | elapsed time per iteration (ms): 260.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064040E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193300/  200000 | consumed samples:      6185600 | elapsed time per iteration (ms): 258.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.064624E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193400/  200000 | consumed samples:      6188800 | elapsed time per iteration (ms): 260.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.063372E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193500/  200000 | consumed samples:      6192000 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.074514E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193600/  200000 | consumed samples:      6195200 | elapsed time per iteration (ms): 276.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.077507E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193700/  200000 | consumed samples:      6198400 | elapsed time per iteration (ms): 370.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.076173E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193800/  200000 | consumed samples:      6201600 | elapsed time per iteration (ms): 265.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.072342E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193900/  200000 | consumed samples:      6204800 | elapsed time per iteration (ms): 260.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.058725E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   194000/  200000 | consumed samples:      6208000 | elapsed time per iteration (ms): 261.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.061878E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194100/  200000 | consumed samples:      6211200 | elapsed time per iteration (ms): 278.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.088166E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194200/  200000 | consumed samples:      6214400 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.071853E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194300/  200000 | consumed samples:      6217600 | elapsed time per iteration (ms): 260.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.083038E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194400/  200000 | consumed samples:      6220800 | elapsed time per iteration (ms): 270.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.077301E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194500/  200000 | consumed samples:      6224000 | elapsed time per iteration (ms): 257.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066459E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194600/  200000 | consumed samples:      6227200 | elapsed time per iteration (ms): 271.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.092149E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194700/  200000 | consumed samples:      6230400 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.073001E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194800/  200000 | consumed samples:      6233600 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.091671E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194900/  200000 | consumed samples:      6236800 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.066152E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   195000/  200000 | consumed samples:      6240000 | elapsed time per iteration (ms): 264.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.096007E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195100/  200000 | consumed samples:      6243200 | elapsed time per iteration (ms): 284.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.099280E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195200/  200000 | consumed samples:      6246400 | elapsed time per iteration (ms): 258.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.107294E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195300/  200000 | consumed samples:      6249600 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.146382E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195400/  200000 | consumed samples:      6252800 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.116841E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195500/  200000 | consumed samples:      6256000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.104158E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195600/  200000 | consumed samples:      6259200 | elapsed time per iteration (ms): 274.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120915E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195700/  200000 | consumed samples:      6262400 | elapsed time per iteration (ms): 263.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.112662E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195800/  200000 | consumed samples:      6265600 | elapsed time per iteration (ms): 266.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.114666E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195900/  200000 | consumed samples:      6268800 | elapsed time per iteration (ms): 265.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.115173E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196000/  200000 | consumed samples:      6272000 | elapsed time per iteration (ms): 258.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.102067E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196100/  200000 | consumed samples:      6275200 | elapsed time per iteration (ms): 270.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.108669E-05 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196200/  200000 | consumed samples:      6278400 | elapsed time per iteration (ms): 255.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.118064E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration   196300/  200000 | consumed samples:      6281600 | elapsed time per iteration (ms): 260.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.106856E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196400/  200000 | consumed samples:      6284800 | elapsed time per iteration (ms): 262.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.122904E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196500/  200000 | consumed samples:      6288000 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.138755E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196600/  200000 | consumed samples:      6291200 | elapsed time per iteration (ms): 284.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.132904E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196700/  200000 | consumed samples:      6294400 | elapsed time per iteration (ms): 260.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126571E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196800/  200000 | consumed samples:      6297600 | elapsed time per iteration (ms): 259.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.135384E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196900/  200000 | consumed samples:      6300800 | elapsed time per iteration (ms): 264.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.122628E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197000/  200000 | consumed samples:      6304000 | elapsed time per iteration (ms): 260.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.093673E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197100/  200000 | consumed samples:      6307200 | elapsed time per iteration (ms): 279.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.099152E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197200/  200000 | consumed samples:      6310400 | elapsed time per iteration (ms): 259.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.110427E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197300/  200000 | consumed samples:      6313600 | elapsed time per iteration (ms): 273.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.110932E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197400/  200000 | consumed samples:      6316800 | elapsed time per iteration (ms): 261.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.108469E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197500/  200000 | consumed samples:      6320000 | elapsed time per iteration (ms): 261.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.098453E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197600/  200000 | consumed samples:      6323200 | elapsed time per iteration (ms): 272.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.103719E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197700/  200000 | consumed samples:      6326400 | elapsed time per iteration (ms): 261.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.112857E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197800/  200000 | consumed samples:      6329600 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.125136E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197900/  200000 | consumed samples:      6332800 | elapsed time per iteration (ms): 264.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120184E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198000/  200000 | consumed samples:      6336000 | elapsed time per iteration (ms): 267.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.109672E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198100/  200000 | consumed samples:      6339200 | elapsed time per iteration (ms): 277.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.127102E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198200/  200000 | consumed samples:      6342400 | elapsed time per iteration (ms): 259.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.128623E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198300/  200000 | consumed samples:      6345600 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.114149E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   198400/  200000 | consumed samples:      6348800 | elapsed time per iteration (ms): 258.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.124620E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198500/  200000 | consumed samples:      6352000 | elapsed time per iteration (ms): 259.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.120695E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198600/  200000 | consumed samples:      6355200 | elapsed time per iteration (ms): 281.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.121334E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198700/  200000 | consumed samples:      6358400 | elapsed time per iteration (ms): 259.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.118880E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198800/  200000 | consumed samples:      6361600 | elapsed time per iteration (ms): 272.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.112002E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198900/  200000 | consumed samples:      6364800 | elapsed time per iteration (ms): 262.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.116865E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199000/  200000 | consumed samples:      6368000 | elapsed time per iteration (ms): 259.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126639E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199100/  200000 | consumed samples:      6371200 | elapsed time per iteration (ms): 274.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.130989E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199200/  200000 | consumed samples:      6374400 | elapsed time per iteration (ms): 261.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.117202E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199300/  200000 | consumed samples:      6377600 | elapsed time per iteration (ms): 262.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.137324E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   199400/  200000 | consumed samples:      6380800 | elapsed time per iteration (ms): 256.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.119210E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199500/  200000 | consumed samples:      6384000 | elapsed time per iteration (ms): 275.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.133383E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199600/  200000 | consumed samples:      6387200 | elapsed time per iteration (ms): 273.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.122442E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199700/  200000 | consumed samples:      6390400 | elapsed time per iteration (ms): 262.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.117481E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199800/  200000 | consumed samples:      6393600 | elapsed time per iteration (ms): 260.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.136209E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199900/  200000 | consumed samples:      6396800 | elapsed time per iteration (ms): 259.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.131991E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   200000/  200000 | consumed samples:      6400000 | elapsed time per iteration (ms): 258.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 1.126943E-05 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
