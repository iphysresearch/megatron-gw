 iteration      100/  200000 | consumed samples:         3200 | elapsed time per iteration (ms): 471.2 | learning rate: 4.495E-05 | global batch size:    32 | lm loss: 1.785777E-02 | loss scale: 4194304.0 | grad norm: 0.008 | number of skipped iterations:  11 | number of nan iterations:   0 |
 iteration      200/  200000 | consumed samples:         6400 | elapsed time per iteration (ms): 369.0 | learning rate: 9.545E-05 | global batch size:    32 | lm loss: 4.986697E-04 | loss scale: 4194304.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/  200000 | consumed samples:         9600 | elapsed time per iteration (ms): 408.2 | learning rate: 9.992E-05 | global batch size:    32 | lm loss: 3.318047E-04 | loss scale: 4194304.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/  200000 | consumed samples:        12800 | elapsed time per iteration (ms): 359.4 | learning rate: 9.983E-05 | global batch size:    32 | lm loss: 2.470932E-04 | loss scale: 4194304.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/  200000 | consumed samples:        16000 | elapsed time per iteration (ms): 413.0 | learning rate: 9.973E-05 | global batch size:    32 | lm loss: 2.209480E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/  200000 | consumed samples:        19200 | elapsed time per iteration (ms): 381.9 | learning rate: 9.964E-05 | global batch size:    32 | lm loss: 1.506734E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/  200000 | consumed samples:        22400 | elapsed time per iteration (ms): 361.6 | learning rate: 9.955E-05 | global batch size:    32 | lm loss: 1.534848E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/  200000 | consumed samples:        25600 | elapsed time per iteration (ms): 372.3 | learning rate: 9.946E-05 | global batch size:    32 | lm loss: 1.571744E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/  200000 | consumed samples:        28800 | elapsed time per iteration (ms): 356.2 | learning rate: 9.937E-05 | global batch size:    32 | lm loss: 1.580432E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/  200000 | consumed samples:        32000 | elapsed time per iteration (ms): 371.8 | learning rate: 9.928E-05 | global batch size:    32 | lm loss: 1.477497E-04 | loss scale: 4194304.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1100/  200000 | consumed samples:        35200 | elapsed time per iteration (ms): 359.3 | learning rate: 9.919E-05 | global batch size:    32 | lm loss: 1.497969E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1200/  200000 | consumed samples:        38400 | elapsed time per iteration (ms): 348.6 | learning rate: 9.910E-05 | global batch size:    32 | lm loss: 1.489092E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1300/  200000 | consumed samples:        41600 | elapsed time per iteration (ms): 346.5 | learning rate: 9.901E-05 | global batch size:    32 | lm loss: 1.397486E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1400/  200000 | consumed samples:        44800 | elapsed time per iteration (ms): 350.4 | learning rate: 9.892E-05 | global batch size:    32 | lm loss: 1.433333E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1500/  200000 | consumed samples:        48000 | elapsed time per iteration (ms): 350.2 | learning rate: 9.882E-05 | global batch size:    32 | lm loss: 1.435907E-04 | loss scale: 8388608.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1600/  200000 | consumed samples:        51200 | elapsed time per iteration (ms): 369.1 | learning rate: 9.873E-05 | global batch size:    32 | lm loss: 1.467992E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1700/  200000 | consumed samples:        54400 | elapsed time per iteration (ms): 359.5 | learning rate: 9.864E-05 | global batch size:    32 | lm loss: 1.527669E-04 | loss scale: 8388608.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1800/  200000 | consumed samples:        57600 | elapsed time per iteration (ms): 354.7 | learning rate: 9.855E-05 | global batch size:    32 | lm loss: 1.421634E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1900/  200000 | consumed samples:        60800 | elapsed time per iteration (ms): 394.3 | learning rate: 9.846E-05 | global batch size:    32 | lm loss: 1.430189E-04 | loss scale: 8388608.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2000/  200000 | consumed samples:        64000 | elapsed time per iteration (ms): 364.3 | learning rate: 9.837E-05 | global batch size:    32 | lm loss: 1.551724E-04 | loss scale: 8388608.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2100/  200000 | consumed samples:        67200 | elapsed time per iteration (ms): 357.3 | learning rate: 9.828E-05 | global batch size:    32 | lm loss: 1.783969E-04 | loss scale: 16777216.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2200/  200000 | consumed samples:        70400 | elapsed time per iteration (ms): 351.9 | learning rate: 9.819E-05 | global batch size:    32 | lm loss: 1.501196E-04 | loss scale: 16777216.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2300/  200000 | consumed samples:        73600 | elapsed time per iteration (ms): 367.0 | learning rate: 9.810E-05 | global batch size:    32 | lm loss: 1.484642E-04 | loss scale: 16777216.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2400/  200000 | consumed samples:        76800 | elapsed time per iteration (ms): 359.6 | learning rate: 9.800E-05 | global batch size:    32 | lm loss: 1.582061E-04 | loss scale: 16777216.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2500/  200000 | consumed samples:        80000 | elapsed time per iteration (ms): 360.0 | learning rate: 9.791E-05 | global batch size:    32 | lm loss: 1.426181E-04 | loss scale: 16777216.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2600/  200000 | consumed samples:        83200 | elapsed time per iteration (ms): 337.9 | learning rate: 9.782E-05 | global batch size:    32 | lm loss: 1.473197E-04 | loss scale: 16777216.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2700/  200000 | consumed samples:        86400 | elapsed time per iteration (ms): 361.1 | learning rate: 9.773E-05 | global batch size:    32 | lm loss: 1.694522E-04 | loss scale: 16777216.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2800/  200000 | consumed samples:        89600 | elapsed time per iteration (ms): 363.3 | learning rate: 9.764E-05 | global batch size:    32 | lm loss: 1.390667E-04 | loss scale: 16777216.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     2900/  200000 | consumed samples:        92800 | elapsed time per iteration (ms): 372.3 | learning rate: 9.755E-05 | global batch size:    32 | lm loss: 1.456508E-04 | loss scale: 16777216.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3000/  200000 | consumed samples:        96000 | elapsed time per iteration (ms): 349.1 | learning rate: 9.746E-05 | global batch size:    32 | lm loss: 1.494469E-04 | loss scale: 16777216.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3100/  200000 | consumed samples:        99200 | elapsed time per iteration (ms): 370.5 | learning rate: 9.737E-05 | global batch size:    32 | lm loss: 1.471059E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3200/  200000 | consumed samples:       102400 | elapsed time per iteration (ms): 362.5 | learning rate: 9.728E-05 | global batch size:    32 | lm loss: 1.578767E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3300/  200000 | consumed samples:       105600 | elapsed time per iteration (ms): 347.9 | learning rate: 9.718E-05 | global batch size:    32 | lm loss: 1.517658E-04 | loss scale: 33554432.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3400/  200000 | consumed samples:       108800 | elapsed time per iteration (ms): 365.7 | learning rate: 9.709E-05 | global batch size:    32 | lm loss: 1.474658E-04 | loss scale: 33554432.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3500/  200000 | consumed samples:       112000 | elapsed time per iteration (ms): 350.9 | learning rate: 9.700E-05 | global batch size:    32 | lm loss: 2.651518E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3600/  200000 | consumed samples:       115200 | elapsed time per iteration (ms): 355.5 | learning rate: 9.691E-05 | global batch size:    32 | lm loss: 1.385148E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3700/  200000 | consumed samples:       118400 | elapsed time per iteration (ms): 366.3 | learning rate: 9.682E-05 | global batch size:    32 | lm loss: 1.450157E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3800/  200000 | consumed samples:       121600 | elapsed time per iteration (ms): 334.0 | learning rate: 9.673E-05 | global batch size:    32 | lm loss: 1.410868E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     3900/  200000 | consumed samples:       124800 | elapsed time per iteration (ms): 323.3 | learning rate: 9.664E-05 | global batch size:    32 | lm loss: 1.482366E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4000/  200000 | consumed samples:       128000 | elapsed time per iteration (ms): 378.8 | learning rate: 9.655E-05 | global batch size:    32 | lm loss: 1.458315E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4100/  200000 | consumed samples:       131200 | elapsed time per iteration (ms): 361.9 | learning rate: 9.646E-05 | global batch size:    32 | lm loss: 1.466726E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4200/  200000 | consumed samples:       134400 | elapsed time per iteration (ms): 337.0 | learning rate: 9.636E-05 | global batch size:    32 | lm loss: 1.518127E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4300/  200000 | consumed samples:       137600 | elapsed time per iteration (ms): 318.1 | learning rate: 9.627E-05 | global batch size:    32 | lm loss: 1.590502E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4400/  200000 | consumed samples:       140800 | elapsed time per iteration (ms): 348.2 | learning rate: 9.618E-05 | global batch size:    32 | lm loss: 1.446270E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4500/  200000 | consumed samples:       144000 | elapsed time per iteration (ms): 382.4 | learning rate: 9.609E-05 | global batch size:    32 | lm loss: 1.437636E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4600/  200000 | consumed samples:       147200 | elapsed time per iteration (ms): 340.8 | learning rate: 9.600E-05 | global batch size:    32 | lm loss: 1.517650E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4700/  200000 | consumed samples:       150400 | elapsed time per iteration (ms): 328.5 | learning rate: 9.591E-05 | global batch size:    32 | lm loss: 1.499808E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4800/  200000 | consumed samples:       153600 | elapsed time per iteration (ms): 316.5 | learning rate: 9.582E-05 | global batch size:    32 | lm loss: 1.489916E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     4900/  200000 | consumed samples:       156800 | elapsed time per iteration (ms): 364.2 | learning rate: 9.573E-05 | global batch size:    32 | lm loss: 1.569792E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5000/  200000 | consumed samples:       160000 | elapsed time per iteration (ms): 352.7 | learning rate: 9.564E-05 | global batch size:    32 | lm loss: 1.414610E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5100/  200000 | consumed samples:       163200 | elapsed time per iteration (ms): 484.5 | learning rate: 9.554E-05 | global batch size:    32 | lm loss: 1.606898E-04 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5200/  200000 | consumed samples:       166400 | elapsed time per iteration (ms): 427.0 | learning rate: 9.545E-05 | global batch size:    32 | lm loss: 1.790081E-04 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5300/  200000 | consumed samples:       169600 | elapsed time per iteration (ms): 345.1 | learning rate: 9.536E-05 | global batch size:    32 | lm loss: 1.422717E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5400/  200000 | consumed samples:       172800 | elapsed time per iteration (ms): 378.4 | learning rate: 9.527E-05 | global batch size:    32 | lm loss: 1.392293E-04 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5500/  200000 | consumed samples:       176000 | elapsed time per iteration (ms): 332.1 | learning rate: 9.518E-05 | global batch size:    32 | lm loss: 1.607780E-04 | loss scale: 134217728.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5600/  200000 | consumed samples:       179200 | elapsed time per iteration (ms): 388.9 | learning rate: 9.509E-05 | global batch size:    32 | lm loss: 1.811069E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     5700/  200000 | consumed samples:       182400 | elapsed time per iteration (ms): 345.3 | learning rate: 9.500E-05 | global batch size:    32 | lm loss: 2.423832E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration     5800/  200000 | consumed samples:       185600 | elapsed time per iteration (ms): 369.4 | learning rate: 9.491E-05 | global batch size:    32 | lm loss: 1.403700E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     5900/  200000 | consumed samples:       188800 | elapsed time per iteration (ms): 353.2 | learning rate: 9.482E-05 | global batch size:    32 | lm loss: 1.391089E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6000/  200000 | consumed samples:       192000 | elapsed time per iteration (ms): 350.2 | learning rate: 9.473E-05 | global batch size:    32 | lm loss: 1.380361E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6100/  200000 | consumed samples:       195200 | elapsed time per iteration (ms): 372.5 | learning rate: 9.464E-05 | global batch size:    32 | lm loss: 1.463094E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6200/  200000 | consumed samples:       198400 | elapsed time per iteration (ms): 405.8 | learning rate: 9.454E-05 | global batch size:    32 | lm loss: 1.407300E-04 | loss scale: 67108864.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6300/  200000 | consumed samples:       201600 | elapsed time per iteration (ms): 374.9 | learning rate: 9.445E-05 | global batch size:    32 | lm loss: 1.380310E-04 | loss scale: 67108864.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6400/  200000 | consumed samples:       204800 | elapsed time per iteration (ms): 374.9 | learning rate: 9.436E-05 | global batch size:    32 | lm loss: 1.367994E-04 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6500/  200000 | consumed samples:       208000 | elapsed time per iteration (ms): 348.4 | learning rate: 9.427E-05 | global batch size:    32 | lm loss: 1.119710E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6600/  200000 | consumed samples:       211200 | elapsed time per iteration (ms): 358.7 | learning rate: 9.418E-05 | global batch size:    32 | lm loss: 1.115227E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6700/  200000 | consumed samples:       214400 | elapsed time per iteration (ms): 372.5 | learning rate: 9.409E-05 | global batch size:    32 | lm loss: 1.017765E-04 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6800/  200000 | consumed samples:       217600 | elapsed time per iteration (ms): 366.2 | learning rate: 9.400E-05 | global batch size:    32 | lm loss: 7.605180E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     6900/  200000 | consumed samples:       220800 | elapsed time per iteration (ms): 337.9 | learning rate: 9.391E-05 | global batch size:    32 | lm loss: 7.229105E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7000/  200000 | consumed samples:       224000 | elapsed time per iteration (ms): 368.1 | learning rate: 9.382E-05 | global batch size:    32 | lm loss: 6.322125E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7100/  200000 | consumed samples:       227200 | elapsed time per iteration (ms): 369.0 | learning rate: 9.372E-05 | global batch size:    32 | lm loss: 6.847236E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7200/  200000 | consumed samples:       230400 | elapsed time per iteration (ms): 409.6 | learning rate: 9.363E-05 | global batch size:    32 | lm loss: 5.247702E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7300/  200000 | consumed samples:       233600 | elapsed time per iteration (ms): 359.7 | learning rate: 9.354E-05 | global batch size:    32 | lm loss: 4.936167E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7400/  200000 | consumed samples:       236800 | elapsed time per iteration (ms): 366.1 | learning rate: 9.345E-05 | global batch size:    32 | lm loss: 5.066157E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7500/  200000 | consumed samples:       240000 | elapsed time per iteration (ms): 344.2 | learning rate: 9.336E-05 | global batch size:    32 | lm loss: 4.187353E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7600/  200000 | consumed samples:       243200 | elapsed time per iteration (ms): 389.9 | learning rate: 9.327E-05 | global batch size:    32 | lm loss: 4.442580E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7700/  200000 | consumed samples:       246400 | elapsed time per iteration (ms): 342.5 | learning rate: 9.318E-05 | global batch size:    32 | lm loss: 1.883012E-04 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration     7800/  200000 | consumed samples:       249600 | elapsed time per iteration (ms): 374.6 | learning rate: 9.309E-05 | global batch size:    32 | lm loss: 1.558632E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     7900/  200000 | consumed samples:       252800 | elapsed time per iteration (ms): 347.0 | learning rate: 9.300E-05 | global batch size:    32 | lm loss: 1.549112E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8000/  200000 | consumed samples:       256000 | elapsed time per iteration (ms): 411.7 | learning rate: 9.291E-05 | global batch size:    32 | lm loss: 1.522842E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8100/  200000 | consumed samples:       259200 | elapsed time per iteration (ms): 360.5 | learning rate: 9.282E-05 | global batch size:    32 | lm loss: 1.523363E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8200/  200000 | consumed samples:       262400 | elapsed time per iteration (ms): 479.0 | learning rate: 9.273E-05 | global batch size:    32 | lm loss: 1.504215E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8300/  200000 | consumed samples:       265600 | elapsed time per iteration (ms): 341.5 | learning rate: 9.264E-05 | global batch size:    32 | lm loss: 1.558436E-04 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8400/  200000 | consumed samples:       268800 | elapsed time per iteration (ms): 375.7 | learning rate: 9.254E-05 | global batch size:    32 | lm loss: 1.510089E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8500/  200000 | consumed samples:       272000 | elapsed time per iteration (ms): 360.0 | learning rate: 9.245E-05 | global batch size:    32 | lm loss: 1.499004E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8600/  200000 | consumed samples:       275200 | elapsed time per iteration (ms): 387.3 | learning rate: 9.236E-05 | global batch size:    32 | lm loss: 1.520099E-04 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8700/  200000 | consumed samples:       278400 | elapsed time per iteration (ms): 336.9 | learning rate: 9.227E-05 | global batch size:    32 | lm loss: 1.465916E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8800/  200000 | consumed samples:       281600 | elapsed time per iteration (ms): 368.1 | learning rate: 9.218E-05 | global batch size:    32 | lm loss: 1.464727E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     8900/  200000 | consumed samples:       284800 | elapsed time per iteration (ms): 319.2 | learning rate: 9.209E-05 | global batch size:    32 | lm loss: 1.533123E-04 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9000/  200000 | consumed samples:       288000 | elapsed time per iteration (ms): 323.2 | learning rate: 9.200E-05 | global batch size:    32 | lm loss: 1.460841E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9100/  200000 | consumed samples:       291200 | elapsed time per iteration (ms): 360.2 | learning rate: 9.191E-05 | global batch size:    32 | lm loss: 1.519922E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9200/  200000 | consumed samples:       294400 | elapsed time per iteration (ms): 351.6 | learning rate: 9.182E-05 | global batch size:    32 | lm loss: 1.455082E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9300/  200000 | consumed samples:       297600 | elapsed time per iteration (ms): 379.7 | learning rate: 9.172E-05 | global batch size:    32 | lm loss: 1.428193E-04 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9400/  200000 | consumed samples:       300800 | elapsed time per iteration (ms): 367.7 | learning rate: 9.163E-05 | global batch size:    32 | lm loss: 1.545772E-04 | loss scale: 67108864.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9500/  200000 | consumed samples:       304000 | elapsed time per iteration (ms): 381.7 | learning rate: 9.154E-05 | global batch size:    32 | lm loss: 1.528613E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9600/  200000 | consumed samples:       307200 | elapsed time per iteration (ms): 360.6 | learning rate: 9.145E-05 | global batch size:    32 | lm loss: 1.506445E-04 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9700/  200000 | consumed samples:       310400 | elapsed time per iteration (ms): 358.7 | learning rate: 9.136E-05 | global batch size:    32 | lm loss: 1.554951E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9800/  200000 | consumed samples:       313600 | elapsed time per iteration (ms): 347.3 | learning rate: 9.127E-05 | global batch size:    32 | lm loss: 1.436494E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     9900/  200000 | consumed samples:       316800 | elapsed time per iteration (ms): 364.7 | learning rate: 9.118E-05 | global batch size:    32 | lm loss: 1.476407E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10000/  200000 | consumed samples:       320000 | elapsed time per iteration (ms): 351.0 | learning rate: 9.109E-05 | global batch size:    32 | lm loss: 1.546068E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10100/  200000 | consumed samples:       323200 | elapsed time per iteration (ms): 364.2 | learning rate: 9.100E-05 | global batch size:    32 | lm loss: 1.488581E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10200/  200000 | consumed samples:       326400 | elapsed time per iteration (ms): 328.0 | learning rate: 9.090E-05 | global batch size:    32 | lm loss: 1.511565E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10300/  200000 | consumed samples:       329600 | elapsed time per iteration (ms): 347.6 | learning rate: 9.081E-05 | global batch size:    32 | lm loss: 1.441038E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10400/  200000 | consumed samples:       332800 | elapsed time per iteration (ms): 337.1 | learning rate: 9.072E-05 | global batch size:    32 | lm loss: 1.553200E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10500/  200000 | consumed samples:       336000 | elapsed time per iteration (ms): 321.9 | learning rate: 9.063E-05 | global batch size:    32 | lm loss: 1.447419E-04 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10600/  200000 | consumed samples:       339200 | elapsed time per iteration (ms): 376.6 | learning rate: 9.054E-05 | global batch size:    32 | lm loss: 1.469164E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10700/  200000 | consumed samples:       342400 | elapsed time per iteration (ms): 328.3 | learning rate: 9.045E-05 | global batch size:    32 | lm loss: 1.509763E-04 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    10800/  200000 | consumed samples:       345600 | elapsed time per iteration (ms): 298.1 | learning rate: 9.036E-05 | global batch size:    32 | lm loss: 1.508135E-04 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    10900/  200000 | consumed samples:       348800 | elapsed time per iteration (ms): 322.0 | learning rate: 9.027E-05 | global batch size:    32 | lm loss: 1.478408E-04 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11000/  200000 | consumed samples:       352000 | elapsed time per iteration (ms): 349.2 | learning rate: 9.018E-05 | global batch size:    32 | lm loss: 1.485355E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11100/  200000 | consumed samples:       355200 | elapsed time per iteration (ms): 374.8 | learning rate: 9.009E-05 | global batch size:    32 | lm loss: 1.451441E-04 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11200/  200000 | consumed samples:       358400 | elapsed time per iteration (ms): 338.2 | learning rate: 9.000E-05 | global batch size:    32 | lm loss: 1.596872E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    11300/  200000 | consumed samples:       361600 | elapsed time per iteration (ms): 333.4 | learning rate: 8.991E-05 | global batch size:    32 | lm loss: 1.506316E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11400/  200000 | consumed samples:       364800 | elapsed time per iteration (ms): 298.3 | learning rate: 8.982E-05 | global batch size:    32 | lm loss: 1.523869E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11500/  200000 | consumed samples:       368000 | elapsed time per iteration (ms): 348.8 | learning rate: 8.972E-05 | global batch size:    32 | lm loss: 1.390413E-04 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11600/  200000 | consumed samples:       371200 | elapsed time per iteration (ms): 319.1 | learning rate: 8.963E-05 | global batch size:    32 | lm loss: 1.120600E-04 | loss scale: 33554432.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11700/  200000 | consumed samples:       374400 | elapsed time per iteration (ms): 322.3 | learning rate: 8.954E-05 | global batch size:    32 | lm loss: 1.037858E-04 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11800/  200000 | consumed samples:       377600 | elapsed time per iteration (ms): 311.6 | learning rate: 8.945E-05 | global batch size:    32 | lm loss: 5.667754E-05 | loss scale: 33554432.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    11900/  200000 | consumed samples:       380800 | elapsed time per iteration (ms): 327.8 | learning rate: 8.936E-05 | global batch size:    32 | lm loss: 4.904431E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12000/  200000 | consumed samples:       384000 | elapsed time per iteration (ms): 327.7 | learning rate: 8.927E-05 | global batch size:    32 | lm loss: 5.432752E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12100/  200000 | consumed samples:       387200 | elapsed time per iteration (ms): 332.8 | learning rate: 8.918E-05 | global batch size:    32 | lm loss: 4.287210E-05 | loss scale: 33554432.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12200/  200000 | consumed samples:       390400 | elapsed time per iteration (ms): 293.7 | learning rate: 8.909E-05 | global batch size:    32 | lm loss: 3.575186E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12300/  200000 | consumed samples:       393600 | elapsed time per iteration (ms): 320.5 | learning rate: 8.900E-05 | global batch size:    32 | lm loss: 3.551249E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12400/  200000 | consumed samples:       396800 | elapsed time per iteration (ms): 307.9 | learning rate: 8.890E-05 | global batch size:    32 | lm loss: 3.596747E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12500/  200000 | consumed samples:       400000 | elapsed time per iteration (ms): 327.0 | learning rate: 8.881E-05 | global batch size:    32 | lm loss: 3.356057E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12600/  200000 | consumed samples:       403200 | elapsed time per iteration (ms): 309.1 | learning rate: 8.872E-05 | global batch size:    32 | lm loss: 3.119295E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12700/  200000 | consumed samples:       406400 | elapsed time per iteration (ms): 284.2 | learning rate: 8.863E-05 | global batch size:    32 | lm loss: 3.002872E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12800/  200000 | consumed samples:       409600 | elapsed time per iteration (ms): 284.1 | learning rate: 8.854E-05 | global batch size:    32 | lm loss: 3.022101E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    12900/  200000 | consumed samples:       412800 | elapsed time per iteration (ms): 282.8 | learning rate: 8.845E-05 | global batch size:    32 | lm loss: 2.978411E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13000/  200000 | consumed samples:       416000 | elapsed time per iteration (ms): 327.3 | learning rate: 8.836E-05 | global batch size:    32 | lm loss: 4.009528E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13100/  200000 | consumed samples:       419200 | elapsed time per iteration (ms): 402.4 | learning rate: 8.827E-05 | global batch size:    32 | lm loss: 2.636703E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13200/  200000 | consumed samples:       422400 | elapsed time per iteration (ms): 480.5 | learning rate: 8.818E-05 | global batch size:    32 | lm loss: 2.995229E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13300/  200000 | consumed samples:       425600 | elapsed time per iteration (ms): 389.9 | learning rate: 8.808E-05 | global batch size:    32 | lm loss: 2.541373E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13400/  200000 | consumed samples:       428800 | elapsed time per iteration (ms): 347.8 | learning rate: 8.799E-05 | global batch size:    32 | lm loss: 3.648011E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13500/  200000 | consumed samples:       432000 | elapsed time per iteration (ms): 388.4 | learning rate: 8.790E-05 | global batch size:    32 | lm loss: 4.168097E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13600/  200000 | consumed samples:       435200 | elapsed time per iteration (ms): 337.9 | learning rate: 8.781E-05 | global batch size:    32 | lm loss: 2.364675E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13700/  200000 | consumed samples:       438400 | elapsed time per iteration (ms): 367.3 | learning rate: 8.772E-05 | global batch size:    32 | lm loss: 2.968058E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13800/  200000 | consumed samples:       441600 | elapsed time per iteration (ms): 406.4 | learning rate: 8.763E-05 | global batch size:    32 | lm loss: 4.251082E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    13900/  200000 | consumed samples:       444800 | elapsed time per iteration (ms): 365.0 | learning rate: 8.754E-05 | global batch size:    32 | lm loss: 2.701898E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14000/  200000 | consumed samples:       448000 | elapsed time per iteration (ms): 393.8 | learning rate: 8.745E-05 | global batch size:    32 | lm loss: 2.197734E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14100/  200000 | consumed samples:       451200 | elapsed time per iteration (ms): 342.9 | learning rate: 8.736E-05 | global batch size:    32 | lm loss: 1.977656E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14200/  200000 | consumed samples:       454400 | elapsed time per iteration (ms): 360.2 | learning rate: 8.726E-05 | global batch size:    32 | lm loss: 1.899820E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14300/  200000 | consumed samples:       457600 | elapsed time per iteration (ms): 362.7 | learning rate: 8.717E-05 | global batch size:    32 | lm loss: 2.114345E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14400/  200000 | consumed samples:       460800 | elapsed time per iteration (ms): 378.7 | learning rate: 8.708E-05 | global batch size:    32 | lm loss: 2.382256E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    14500/  200000 | consumed samples:       464000 | elapsed time per iteration (ms): 353.1 | learning rate: 8.699E-05 | global batch size:    32 | lm loss: 1.844139E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14600/  200000 | consumed samples:       467200 | elapsed time per iteration (ms): 380.3 | learning rate: 8.690E-05 | global batch size:    32 | lm loss: 1.854777E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14700/  200000 | consumed samples:       470400 | elapsed time per iteration (ms): 362.7 | learning rate: 8.681E-05 | global batch size:    32 | lm loss: 1.827849E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14800/  200000 | consumed samples:       473600 | elapsed time per iteration (ms): 408.6 | learning rate: 8.672E-05 | global batch size:    32 | lm loss: 2.155690E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    14900/  200000 | consumed samples:       476800 | elapsed time per iteration (ms): 344.4 | learning rate: 8.663E-05 | global batch size:    32 | lm loss: 2.471328E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15000/  200000 | consumed samples:       480000 | elapsed time per iteration (ms): 399.5 | learning rate: 8.654E-05 | global batch size:    32 | lm loss: 1.786290E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15100/  200000 | consumed samples:       483200 | elapsed time per iteration (ms): 354.3 | learning rate: 8.645E-05 | global batch size:    32 | lm loss: 1.819461E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15200/  200000 | consumed samples:       486400 | elapsed time per iteration (ms): 356.7 | learning rate: 8.635E-05 | global batch size:    32 | lm loss: 1.691287E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15300/  200000 | consumed samples:       489600 | elapsed time per iteration (ms): 353.4 | learning rate: 8.626E-05 | global batch size:    32 | lm loss: 1.882343E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15400/  200000 | consumed samples:       492800 | elapsed time per iteration (ms): 379.9 | learning rate: 8.618E-05 | global batch size:    32 | lm loss: 2.154968E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    15500/  200000 | consumed samples:       496000 | elapsed time per iteration (ms): 352.7 | learning rate: 8.608E-05 | global batch size:    32 | lm loss: 3.019599E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15600/  200000 | consumed samples:       499200 | elapsed time per iteration (ms): 376.6 | learning rate: 8.599E-05 | global batch size:    32 | lm loss: 2.017264E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15700/  200000 | consumed samples:       502400 | elapsed time per iteration (ms): 342.0 | learning rate: 8.590E-05 | global batch size:    32 | lm loss: 1.702903E-05 | loss scale: 134217728.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15800/  200000 | consumed samples:       505600 | elapsed time per iteration (ms): 397.4 | learning rate: 8.581E-05 | global batch size:    32 | lm loss: 1.642282E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    15900/  200000 | consumed samples:       508800 | elapsed time per iteration (ms): 375.5 | learning rate: 8.572E-05 | global batch size:    32 | lm loss: 3.096000E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16000/  200000 | consumed samples:       512000 | elapsed time per iteration (ms): 359.4 | learning rate: 8.563E-05 | global batch size:    32 | lm loss: 2.142690E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16100/  200000 | consumed samples:       515200 | elapsed time per iteration (ms): 346.2 | learning rate: 8.554E-05 | global batch size:    32 | lm loss: 1.564059E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16200/  200000 | consumed samples:       518400 | elapsed time per iteration (ms): 369.8 | learning rate: 8.545E-05 | global batch size:    32 | lm loss: 1.683099E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16300/  200000 | consumed samples:       521600 | elapsed time per iteration (ms): 374.2 | learning rate: 8.536E-05 | global batch size:    32 | lm loss: 1.841267E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16400/  200000 | consumed samples:       524800 | elapsed time per iteration (ms): 353.4 | learning rate: 8.526E-05 | global batch size:    32 | lm loss: 1.697228E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16500/  200000 | consumed samples:       528000 | elapsed time per iteration (ms): 345.0 | learning rate: 8.517E-05 | global batch size:    32 | lm loss: 2.056767E-05 | loss scale: 268435456.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16600/  200000 | consumed samples:       531200 | elapsed time per iteration (ms): 401.4 | learning rate: 8.508E-05 | global batch size:    32 | lm loss: 1.946826E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    16700/  200000 | consumed samples:       534400 | elapsed time per iteration (ms): 334.8 | learning rate: 8.499E-05 | global batch size:    32 | lm loss: 1.555973E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    16800/  200000 | consumed samples:       537600 | elapsed time per iteration (ms): 443.3 | learning rate: 8.490E-05 | global batch size:    32 | lm loss: 1.587832E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    16900/  200000 | consumed samples:       540800 | elapsed time per iteration (ms): 345.6 | learning rate: 8.481E-05 | global batch size:    32 | lm loss: 1.526423E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17000/  200000 | consumed samples:       544000 | elapsed time per iteration (ms): 378.4 | learning rate: 8.472E-05 | global batch size:    32 | lm loss: 1.647918E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17100/  200000 | consumed samples:       547200 | elapsed time per iteration (ms): 337.1 | learning rate: 8.463E-05 | global batch size:    32 | lm loss: 1.619249E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17200/  200000 | consumed samples:       550400 | elapsed time per iteration (ms): 349.4 | learning rate: 8.454E-05 | global batch size:    32 | lm loss: 2.565573E-05 | loss scale: 134217728.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17300/  200000 | consumed samples:       553600 | elapsed time per iteration (ms): 347.5 | learning rate: 8.445E-05 | global batch size:    32 | lm loss: 1.725682E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17400/  200000 | consumed samples:       556800 | elapsed time per iteration (ms): 355.5 | learning rate: 8.436E-05 | global batch size:    32 | lm loss: 1.560149E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17500/  200000 | consumed samples:       560000 | elapsed time per iteration (ms): 354.1 | learning rate: 8.426E-05 | global batch size:    32 | lm loss: 1.458320E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17600/  200000 | consumed samples:       563200 | elapsed time per iteration (ms): 353.9 | learning rate: 8.417E-05 | global batch size:    32 | lm loss: 1.574167E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17700/  200000 | consumed samples:       566400 | elapsed time per iteration (ms): 349.6 | learning rate: 8.408E-05 | global batch size:    32 | lm loss: 1.933318E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17800/  200000 | consumed samples:       569600 | elapsed time per iteration (ms): 405.5 | learning rate: 8.399E-05 | global batch size:    32 | lm loss: 1.760371E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    17900/  200000 | consumed samples:       572800 | elapsed time per iteration (ms): 361.1 | learning rate: 8.390E-05 | global batch size:    32 | lm loss: 1.844425E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    18000/  200000 | consumed samples:       576000 | elapsed time per iteration (ms): 369.6 | learning rate: 8.381E-05 | global batch size:    32 | lm loss: 1.521679E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18100/  200000 | consumed samples:       579200 | elapsed time per iteration (ms): 349.8 | learning rate: 8.372E-05 | global batch size:    32 | lm loss: 1.492306E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18200/  200000 | consumed samples:       582400 | elapsed time per iteration (ms): 373.2 | learning rate: 8.363E-05 | global batch size:    32 | lm loss: 1.533196E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18300/  200000 | consumed samples:       585600 | elapsed time per iteration (ms): 345.3 | learning rate: 8.354E-05 | global batch size:    32 | lm loss: 1.577783E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18400/  200000 | consumed samples:       588800 | elapsed time per iteration (ms): 364.9 | learning rate: 8.345E-05 | global batch size:    32 | lm loss: 1.669727E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18500/  200000 | consumed samples:       592000 | elapsed time per iteration (ms): 348.0 | learning rate: 8.335E-05 | global batch size:    32 | lm loss: 1.531109E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18600/  200000 | consumed samples:       595200 | elapsed time per iteration (ms): 386.8 | learning rate: 8.326E-05 | global batch size:    32 | lm loss: 1.590648E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18700/  200000 | consumed samples:       598400 | elapsed time per iteration (ms): 356.9 | learning rate: 8.317E-05 | global batch size:    32 | lm loss: 1.520681E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18800/  200000 | consumed samples:       601600 | elapsed time per iteration (ms): 411.7 | learning rate: 8.308E-05 | global batch size:    32 | lm loss: 1.518763E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    18900/  200000 | consumed samples:       604800 | elapsed time per iteration (ms): 323.9 | learning rate: 8.299E-05 | global batch size:    32 | lm loss: 1.473129E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    19000/  200000 | consumed samples:       608000 | elapsed time per iteration (ms): 339.6 | learning rate: 8.290E-05 | global batch size:    32 | lm loss: 1.430678E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19100/  200000 | consumed samples:       611200 | elapsed time per iteration (ms): 330.9 | learning rate: 8.281E-05 | global batch size:    32 | lm loss: 1.460125E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19200/  200000 | consumed samples:       614400 | elapsed time per iteration (ms): 333.2 | learning rate: 8.272E-05 | global batch size:    32 | lm loss: 1.377832E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19300/  200000 | consumed samples:       617600 | elapsed time per iteration (ms): 369.1 | learning rate: 8.263E-05 | global batch size:    32 | lm loss: 1.457340E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19400/  200000 | consumed samples:       620800 | elapsed time per iteration (ms): 358.1 | learning rate: 8.254E-05 | global batch size:    32 | lm loss: 2.835336E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19500/  200000 | consumed samples:       624000 | elapsed time per iteration (ms): 403.5 | learning rate: 8.245E-05 | global batch size:    32 | lm loss: 1.449858E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19600/  200000 | consumed samples:       627200 | elapsed time per iteration (ms): 330.3 | learning rate: 8.235E-05 | global batch size:    32 | lm loss: 1.408641E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19700/  200000 | consumed samples:       630400 | elapsed time per iteration (ms): 327.6 | learning rate: 8.226E-05 | global batch size:    32 | lm loss: 1.348092E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19800/  200000 | consumed samples:       633600 | elapsed time per iteration (ms): 299.8 | learning rate: 8.217E-05 | global batch size:    32 | lm loss: 1.384683E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    19900/  200000 | consumed samples:       636800 | elapsed time per iteration (ms): 296.9 | learning rate: 8.208E-05 | global batch size:    32 | lm loss: 1.442997E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    20000/  200000 | consumed samples:       640000 | elapsed time per iteration (ms): 297.4 | learning rate: 8.199E-05 | global batch size:    32 | lm loss: 1.437980E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20100/  200000 | consumed samples:       643200 | elapsed time per iteration (ms): 737.3 | learning rate: 8.190E-05 | global batch size:    32 | lm loss: 1.482624E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20200/  200000 | consumed samples:       646400 | elapsed time per iteration (ms): 414.8 | learning rate: 8.181E-05 | global batch size:    32 | lm loss: 1.456206E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20300/  200000 | consumed samples:       649600 | elapsed time per iteration (ms): 345.1 | learning rate: 8.172E-05 | global batch size:    32 | lm loss: 1.366548E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20400/  200000 | consumed samples:       652800 | elapsed time per iteration (ms): 406.0 | learning rate: 8.163E-05 | global batch size:    32 | lm loss: 1.507099E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20500/  200000 | consumed samples:       656000 | elapsed time per iteration (ms): 321.6 | learning rate: 8.154E-05 | global batch size:    32 | lm loss: 1.541199E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20600/  200000 | consumed samples:       659200 | elapsed time per iteration (ms): 339.3 | learning rate: 8.145E-05 | global batch size:    32 | lm loss: 1.342722E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20700/  200000 | consumed samples:       662400 | elapsed time per iteration (ms): 342.9 | learning rate: 8.135E-05 | global batch size:    32 | lm loss: 1.235121E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20800/  200000 | consumed samples:       665600 | elapsed time per iteration (ms): 287.3 | learning rate: 8.126E-05 | global batch size:    32 | lm loss: 1.383094E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20900/  200000 | consumed samples:       668800 | elapsed time per iteration (ms): 287.5 | learning rate: 8.117E-05 | global batch size:    32 | lm loss: 2.307124E-05 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21000/  200000 | consumed samples:       672000 | elapsed time per iteration (ms): 333.6 | learning rate: 8.108E-05 | global batch size:    32 | lm loss: 1.779156E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    21100/  200000 | consumed samples:       675200 | elapsed time per iteration (ms): 369.9 | learning rate: 8.099E-05 | global batch size:    32 | lm loss: 1.299422E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21200/  200000 | consumed samples:       678400 | elapsed time per iteration (ms): 341.1 | learning rate: 8.090E-05 | global batch size:    32 | lm loss: 1.198840E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21300/  200000 | consumed samples:       681600 | elapsed time per iteration (ms): 458.3 | learning rate: 8.081E-05 | global batch size:    32 | lm loss: 1.256016E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21400/  200000 | consumed samples:       684800 | elapsed time per iteration (ms): 418.3 | learning rate: 8.072E-05 | global batch size:    32 | lm loss: 1.247385E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21500/  200000 | consumed samples:       688000 | elapsed time per iteration (ms): 376.1 | learning rate: 8.063E-05 | global batch size:    32 | lm loss: 1.133220E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21600/  200000 | consumed samples:       691200 | elapsed time per iteration (ms): 359.2 | learning rate: 8.054E-05 | global batch size:    32 | lm loss: 1.171429E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21700/  200000 | consumed samples:       694400 | elapsed time per iteration (ms): 344.1 | learning rate: 8.045E-05 | global batch size:    32 | lm loss: 1.356024E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21800/  200000 | consumed samples:       697600 | elapsed time per iteration (ms): 371.9 | learning rate: 8.036E-05 | global batch size:    32 | lm loss: 1.366288E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    21900/  200000 | consumed samples:       700800 | elapsed time per iteration (ms): 377.7 | learning rate: 8.026E-05 | global batch size:    32 | lm loss: 1.401013E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22000/  200000 | consumed samples:       704000 | elapsed time per iteration (ms): 366.8 | learning rate: 8.017E-05 | global batch size:    32 | lm loss: 1.192020E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22100/  200000 | consumed samples:       707200 | elapsed time per iteration (ms): 358.0 | learning rate: 8.008E-05 | global batch size:    32 | lm loss: 1.350470E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22200/  200000 | consumed samples:       710400 | elapsed time per iteration (ms): 348.5 | learning rate: 7.999E-05 | global batch size:    32 | lm loss: 1.179601E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22300/  200000 | consumed samples:       713600 | elapsed time per iteration (ms): 367.4 | learning rate: 7.990E-05 | global batch size:    32 | lm loss: 1.094838E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22400/  200000 | consumed samples:       716800 | elapsed time per iteration (ms): 402.5 | learning rate: 7.981E-05 | global batch size:    32 | lm loss: 1.162409E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22500/  200000 | consumed samples:       720000 | elapsed time per iteration (ms): 371.5 | learning rate: 7.972E-05 | global batch size:    32 | lm loss: 1.178881E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22600/  200000 | consumed samples:       723200 | elapsed time per iteration (ms): 378.8 | learning rate: 7.963E-05 | global batch size:    32 | lm loss: 1.430683E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    22700/  200000 | consumed samples:       726400 | elapsed time per iteration (ms): 398.1 | learning rate: 7.954E-05 | global batch size:    32 | lm loss: 1.130115E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22800/  200000 | consumed samples:       729600 | elapsed time per iteration (ms): 365.4 | learning rate: 7.945E-05 | global batch size:    32 | lm loss: 1.152143E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    22900/  200000 | consumed samples:       732800 | elapsed time per iteration (ms): 356.6 | learning rate: 7.936E-05 | global batch size:    32 | lm loss: 1.131303E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23000/  200000 | consumed samples:       736000 | elapsed time per iteration (ms): 360.2 | learning rate: 7.926E-05 | global batch size:    32 | lm loss: 1.282253E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23100/  200000 | consumed samples:       739200 | elapsed time per iteration (ms): 393.8 | learning rate: 7.917E-05 | global batch size:    32 | lm loss: 1.715814E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23200/  200000 | consumed samples:       742400 | elapsed time per iteration (ms): 365.8 | learning rate: 7.908E-05 | global batch size:    32 | lm loss: 1.286069E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23300/  200000 | consumed samples:       745600 | elapsed time per iteration (ms): 371.6 | learning rate: 7.899E-05 | global batch size:    32 | lm loss: 1.187721E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23400/  200000 | consumed samples:       748800 | elapsed time per iteration (ms): 397.9 | learning rate: 7.890E-05 | global batch size:    32 | lm loss: 1.247227E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23500/  200000 | consumed samples:       752000 | elapsed time per iteration (ms): 365.4 | learning rate: 7.881E-05 | global batch size:    32 | lm loss: 1.202683E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23600/  200000 | consumed samples:       755200 | elapsed time per iteration (ms): 364.2 | learning rate: 7.872E-05 | global batch size:    32 | lm loss: 1.140166E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23700/  200000 | consumed samples:       758400 | elapsed time per iteration (ms): 341.5 | learning rate: 7.863E-05 | global batch size:    32 | lm loss: 1.120898E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23800/  200000 | consumed samples:       761600 | elapsed time per iteration (ms): 402.8 | learning rate: 7.854E-05 | global batch size:    32 | lm loss: 1.129712E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    23900/  200000 | consumed samples:       764800 | elapsed time per iteration (ms): 333.8 | learning rate: 7.844E-05 | global batch size:    32 | lm loss: 1.124732E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24000/  200000 | consumed samples:       768000 | elapsed time per iteration (ms): 398.8 | learning rate: 7.835E-05 | global batch size:    32 | lm loss: 1.657836E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24100/  200000 | consumed samples:       771200 | elapsed time per iteration (ms): 345.1 | learning rate: 7.826E-05 | global batch size:    32 | lm loss: 1.655276E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24200/  200000 | consumed samples:       774400 | elapsed time per iteration (ms): 365.3 | learning rate: 7.817E-05 | global batch size:    32 | lm loss: 1.119162E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24300/  200000 | consumed samples:       777600 | elapsed time per iteration (ms): 368.5 | learning rate: 7.808E-05 | global batch size:    32 | lm loss: 1.191647E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24400/  200000 | consumed samples:       780800 | elapsed time per iteration (ms): 394.5 | learning rate: 7.799E-05 | global batch size:    32 | lm loss: 1.059441E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24500/  200000 | consumed samples:       784000 | elapsed time per iteration (ms): 333.5 | learning rate: 7.790E-05 | global batch size:    32 | lm loss: 1.476893E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24600/  200000 | consumed samples:       787200 | elapsed time per iteration (ms): 422.5 | learning rate: 7.781E-05 | global batch size:    32 | lm loss: 1.105038E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24700/  200000 | consumed samples:       790400 | elapsed time per iteration (ms): 358.0 | learning rate: 7.772E-05 | global batch size:    32 | lm loss: 1.097013E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    24800/  200000 | consumed samples:       793600 | elapsed time per iteration (ms): 407.4 | learning rate: 7.763E-05 | global batch size:    32 | lm loss: 1.090126E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    24900/  200000 | consumed samples:       796800 | elapsed time per iteration (ms): 361.3 | learning rate: 7.754E-05 | global batch size:    32 | lm loss: 1.073299E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25000/  200000 | consumed samples:       800000 | elapsed time per iteration (ms): 372.5 | learning rate: 7.744E-05 | global batch size:    32 | lm loss: 1.167544E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25100/  200000 | consumed samples:       803200 | elapsed time per iteration (ms): 344.7 | learning rate: 7.735E-05 | global batch size:    32 | lm loss: 1.190126E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25200/  200000 | consumed samples:       806400 | elapsed time per iteration (ms): 356.5 | learning rate: 7.726E-05 | global batch size:    32 | lm loss: 9.974549E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25300/  200000 | consumed samples:       809600 | elapsed time per iteration (ms): 298.9 | learning rate: 7.717E-05 | global batch size:    32 | lm loss: 1.036780E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25400/  200000 | consumed samples:       812800 | elapsed time per iteration (ms): 401.7 | learning rate: 7.708E-05 | global batch size:    32 | lm loss: 1.013928E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25500/  200000 | consumed samples:       816000 | elapsed time per iteration (ms): 335.2 | learning rate: 7.699E-05 | global batch size:    32 | lm loss: 1.081891E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25600/  200000 | consumed samples:       819200 | elapsed time per iteration (ms): 378.4 | learning rate: 7.690E-05 | global batch size:    32 | lm loss: 9.287831E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25700/  200000 | consumed samples:       822400 | elapsed time per iteration (ms): 347.2 | learning rate: 7.681E-05 | global batch size:    32 | lm loss: 1.205157E-05 | loss scale: 67108864.0 | grad norm: 0.003 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    25800/  200000 | consumed samples:       825600 | elapsed time per iteration (ms): 406.3 | learning rate: 7.672E-05 | global batch size:    32 | lm loss: 2.017314E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25900/  200000 | consumed samples:       828800 | elapsed time per iteration (ms): 336.4 | learning rate: 7.663E-05 | global batch size:    32 | lm loss: 1.011664E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26000/  200000 | consumed samples:       832000 | elapsed time per iteration (ms): 362.9 | learning rate: 7.653E-05 | global batch size:    32 | lm loss: 1.064606E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26100/  200000 | consumed samples:       835200 | elapsed time per iteration (ms): 342.4 | learning rate: 7.644E-05 | global batch size:    32 | lm loss: 1.008703E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26200/  200000 | consumed samples:       838400 | elapsed time per iteration (ms): 361.6 | learning rate: 7.635E-05 | global batch size:    32 | lm loss: 9.660117E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26300/  200000 | consumed samples:       841600 | elapsed time per iteration (ms): 328.1 | learning rate: 7.626E-05 | global batch size:    32 | lm loss: 1.120518E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26400/  200000 | consumed samples:       844800 | elapsed time per iteration (ms): 305.1 | learning rate: 7.617E-05 | global batch size:    32 | lm loss: 9.981267E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26500/  200000 | consumed samples:       848000 | elapsed time per iteration (ms): 387.0 | learning rate: 7.608E-05 | global batch size:    32 | lm loss: 1.028926E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26600/  200000 | consumed samples:       851200 | elapsed time per iteration (ms): 384.9 | learning rate: 7.599E-05 | global batch size:    32 | lm loss: 1.046938E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26700/  200000 | consumed samples:       854400 | elapsed time per iteration (ms): 356.1 | learning rate: 7.590E-05 | global batch size:    32 | lm loss: 9.899621E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26800/  200000 | consumed samples:       857600 | elapsed time per iteration (ms): 365.4 | learning rate: 7.581E-05 | global batch size:    32 | lm loss: 9.768729E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26900/  200000 | consumed samples:       860800 | elapsed time per iteration (ms): 387.4 | learning rate: 7.571E-05 | global batch size:    32 | lm loss: 9.675026E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27000/  200000 | consumed samples:       864000 | elapsed time per iteration (ms): 347.9 | learning rate: 7.562E-05 | global batch size:    32 | lm loss: 1.015278E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27100/  200000 | consumed samples:       867200 | elapsed time per iteration (ms): 314.4 | learning rate: 7.553E-05 | global batch size:    32 | lm loss: 1.046662E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27200/  200000 | consumed samples:       870400 | elapsed time per iteration (ms): 338.0 | learning rate: 7.544E-05 | global batch size:    32 | lm loss: 1.380387E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27300/  200000 | consumed samples:       873600 | elapsed time per iteration (ms): 365.3 | learning rate: 7.535E-05 | global batch size:    32 | lm loss: 1.178520E-05 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27400/  200000 | consumed samples:       876800 | elapsed time per iteration (ms): 337.7 | learning rate: 7.526E-05 | global batch size:    32 | lm loss: 1.013900E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27500/  200000 | consumed samples:       880000 | elapsed time per iteration (ms): 358.1 | learning rate: 7.517E-05 | global batch size:    32 | lm loss: 1.001453E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27600/  200000 | consumed samples:       883200 | elapsed time per iteration (ms): 353.2 | learning rate: 7.508E-05 | global batch size:    32 | lm loss: 1.089077E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27700/  200000 | consumed samples:       886400 | elapsed time per iteration (ms): 302.7 | learning rate: 7.499E-05 | global batch size:    32 | lm loss: 1.057882E-05 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27800/  200000 | consumed samples:       889600 | elapsed time per iteration (ms): 324.6 | learning rate: 7.489E-05 | global batch size:    32 | lm loss: 1.086404E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27900/  200000 | consumed samples:       892800 | elapsed time per iteration (ms): 333.3 | learning rate: 7.480E-05 | global batch size:    32 | lm loss: 9.920893E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28000/  200000 | consumed samples:       896000 | elapsed time per iteration (ms): 411.1 | learning rate: 7.471E-05 | global batch size:    32 | lm loss: 1.022340E-05 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28100/  200000 | consumed samples:       899200 | elapsed time per iteration (ms): 377.7 | learning rate: 7.462E-05 | global batch size:    32 | lm loss: 1.078997E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    28200/  200000 | consumed samples:       902400 | elapsed time per iteration (ms): 308.8 | learning rate: 7.453E-05 | global batch size:    32 | lm loss: 1.053164E-05 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    28300/  200000 | consumed samples:       905600 | elapsed time per iteration (ms): 347.7 | learning rate: 7.444E-05 | global batch size:    32 | lm loss: 1.028001E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28400/  200000 | consumed samples:       908800 | elapsed time per iteration (ms): 315.5 | learning rate: 7.435E-05 | global batch size:    32 | lm loss: 9.229248E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28500/  200000 | consumed samples:       912000 | elapsed time per iteration (ms): 309.4 | learning rate: 7.426E-05 | global batch size:    32 | lm loss: 8.993208E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28600/  200000 | consumed samples:       915200 | elapsed time per iteration (ms): 362.1 | learning rate: 7.417E-05 | global batch size:    32 | lm loss: 1.250395E-05 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    28700/  200000 | consumed samples:       918400 | elapsed time per iteration (ms): 323.0 | learning rate: 7.408E-05 | global batch size:    32 | lm loss: 9.778481E-06 | loss scale: 33554432.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28800/  200000 | consumed samples:       921600 | elapsed time per iteration (ms): 318.8 | learning rate: 7.399E-05 | global batch size:    32 | lm loss: 9.063975E-06 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28900/  200000 | consumed samples:       924800 | elapsed time per iteration (ms): 292.4 | learning rate: 7.390E-05 | global batch size:    32 | lm loss: 9.165284E-06 | loss scale: 33554432.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29000/  200000 | consumed samples:       928000 | elapsed time per iteration (ms): 363.6 | learning rate: 7.380E-05 | global batch size:    32 | lm loss: 9.325590E-06 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29100/  200000 | consumed samples:       931200 | elapsed time per iteration (ms): 291.3 | learning rate: 7.371E-05 | global batch size:    32 | lm loss: 1.026303E-05 | loss scale: 33554432.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29200/  200000 | consumed samples:       934400 | elapsed time per iteration (ms): 310.2 | learning rate: 7.362E-05 | global batch size:    32 | lm loss: 8.892101E-06 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29300/  200000 | consumed samples:       937600 | elapsed time per iteration (ms): 348.9 | learning rate: 7.353E-05 | global batch size:    32 | lm loss: 1.015739E-05 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29400/  200000 | consumed samples:       940800 | elapsed time per iteration (ms): 372.4 | learning rate: 7.344E-05 | global batch size:    32 | lm loss: 9.361456E-06 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29500/  200000 | consumed samples:       944000 | elapsed time per iteration (ms): 454.6 | learning rate: 7.335E-05 | global batch size:    32 | lm loss: 9.687396E-06 | loss scale: 33554432.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29600/  200000 | consumed samples:       947200 | elapsed time per iteration (ms): 437.9 | learning rate: 7.326E-05 | global batch size:    32 | lm loss: 1.241692E-05 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29700/  200000 | consumed samples:       950400 | elapsed time per iteration (ms): 366.2 | learning rate: 7.317E-05 | global batch size:    32 | lm loss: 2.439979E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29800/  200000 | consumed samples:       953600 | elapsed time per iteration (ms): 366.4 | learning rate: 7.308E-05 | global batch size:    32 | lm loss: 9.661756E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29900/  200000 | consumed samples:       956800 | elapsed time per iteration (ms): 352.1 | learning rate: 7.299E-05 | global batch size:    32 | lm loss: 9.232492E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30000/  200000 | consumed samples:       960000 | elapsed time per iteration (ms): 378.7 | learning rate: 7.289E-05 | global batch size:    32 | lm loss: 9.750077E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30100/  200000 | consumed samples:       963200 | elapsed time per iteration (ms): 353.0 | learning rate: 7.280E-05 | global batch size:    32 | lm loss: 9.330926E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30200/  200000 | consumed samples:       966400 | elapsed time per iteration (ms): 381.2 | learning rate: 7.271E-05 | global batch size:    32 | lm loss: 1.025606E-05 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30300/  200000 | consumed samples:       969600 | elapsed time per iteration (ms): 363.2 | learning rate: 7.262E-05 | global batch size:    32 | lm loss: 9.100807E-06 | loss scale: 67108864.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30400/  200000 | consumed samples:       972800 | elapsed time per iteration (ms): 381.8 | learning rate: 7.253E-05 | global batch size:    32 | lm loss: 9.639934E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30500/  200000 | consumed samples:       976000 | elapsed time per iteration (ms): 351.0 | learning rate: 7.244E-05 | global batch size:    32 | lm loss: 8.964735E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30600/  200000 | consumed samples:       979200 | elapsed time per iteration (ms): 425.4 | learning rate: 7.235E-05 | global batch size:    32 | lm loss: 8.932386E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30700/  200000 | consumed samples:       982400 | elapsed time per iteration (ms): 387.3 | learning rate: 7.226E-05 | global batch size:    32 | lm loss: 8.855515E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30800/  200000 | consumed samples:       985600 | elapsed time per iteration (ms): 370.0 | learning rate: 7.217E-05 | global batch size:    32 | lm loss: 9.482122E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    30900/  200000 | consumed samples:       988800 | elapsed time per iteration (ms): 368.4 | learning rate: 7.207E-05 | global batch size:    32 | lm loss: 8.902621E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31000/  200000 | consumed samples:       992000 | elapsed time per iteration (ms): 373.8 | learning rate: 7.198E-05 | global batch size:    32 | lm loss: 9.003608E-06 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31100/  200000 | consumed samples:       995200 | elapsed time per iteration (ms): 376.4 | learning rate: 7.189E-05 | global batch size:    32 | lm loss: 1.053417E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31200/  200000 | consumed samples:       998400 | elapsed time per iteration (ms): 383.7 | learning rate: 7.180E-05 | global batch size:    32 | lm loss: 9.207090E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31300/  200000 | consumed samples:      1001600 | elapsed time per iteration (ms): 363.4 | learning rate: 7.171E-05 | global batch size:    32 | lm loss: 9.709912E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31400/  200000 | consumed samples:      1004800 | elapsed time per iteration (ms): 358.5 | learning rate: 7.162E-05 | global batch size:    32 | lm loss: 8.819788E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31500/  200000 | consumed samples:      1008000 | elapsed time per iteration (ms): 362.1 | learning rate: 7.153E-05 | global batch size:    32 | lm loss: 8.816090E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31600/  200000 | consumed samples:      1011200 | elapsed time per iteration (ms): 352.9 | learning rate: 7.144E-05 | global batch size:    32 | lm loss: 8.798545E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31700/  200000 | consumed samples:      1014400 | elapsed time per iteration (ms): 403.1 | learning rate: 7.135E-05 | global batch size:    32 | lm loss: 8.850913E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    31800/  200000 | consumed samples:      1017600 | elapsed time per iteration (ms): 349.0 | learning rate: 7.126E-05 | global batch size:    32 | lm loss: 9.410341E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    31900/  200000 | consumed samples:      1020800 | elapsed time per iteration (ms): 405.6 | learning rate: 7.117E-05 | global batch size:    32 | lm loss: 9.321183E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32000/  200000 | consumed samples:      1024000 | elapsed time per iteration (ms): 374.1 | learning rate: 7.107E-05 | global batch size:    32 | lm loss: 1.009501E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32100/  200000 | consumed samples:      1027200 | elapsed time per iteration (ms): 364.7 | learning rate: 7.098E-05 | global batch size:    32 | lm loss: 9.015145E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32200/  200000 | consumed samples:      1030400 | elapsed time per iteration (ms): 355.9 | learning rate: 7.089E-05 | global batch size:    32 | lm loss: 8.552375E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32300/  200000 | consumed samples:      1033600 | elapsed time per iteration (ms): 375.9 | learning rate: 7.080E-05 | global batch size:    32 | lm loss: 1.211722E-05 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32400/  200000 | consumed samples:      1036800 | elapsed time per iteration (ms): 358.0 | learning rate: 7.071E-05 | global batch size:    32 | lm loss: 9.599638E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32500/  200000 | consumed samples:      1040000 | elapsed time per iteration (ms): 381.7 | learning rate: 7.062E-05 | global batch size:    32 | lm loss: 8.915165E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32600/  200000 | consumed samples:      1043200 | elapsed time per iteration (ms): 453.9 | learning rate: 7.053E-05 | global batch size:    32 | lm loss: 8.645438E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32700/  200000 | consumed samples:      1046400 | elapsed time per iteration (ms): 353.2 | learning rate: 7.044E-05 | global batch size:    32 | lm loss: 8.648276E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32800/  200000 | consumed samples:      1049600 | elapsed time per iteration (ms): 379.6 | learning rate: 7.035E-05 | global batch size:    32 | lm loss: 8.729923E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    32900/  200000 | consumed samples:      1052800 | elapsed time per iteration (ms): 382.9 | learning rate: 7.025E-05 | global batch size:    32 | lm loss: 9.096587E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33000/  200000 | consumed samples:      1056000 | elapsed time per iteration (ms): 355.5 | learning rate: 7.016E-05 | global batch size:    32 | lm loss: 8.887199E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33100/  200000 | consumed samples:      1059200 | elapsed time per iteration (ms): 401.1 | learning rate: 7.007E-05 | global batch size:    32 | lm loss: 8.974255E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33200/  200000 | consumed samples:      1062400 | elapsed time per iteration (ms): 350.1 | learning rate: 6.998E-05 | global batch size:    32 | lm loss: 8.698492E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33300/  200000 | consumed samples:      1065600 | elapsed time per iteration (ms): 373.6 | learning rate: 6.989E-05 | global batch size:    32 | lm loss: 8.679515E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33400/  200000 | consumed samples:      1068800 | elapsed time per iteration (ms): 358.8 | learning rate: 6.980E-05 | global batch size:    32 | lm loss: 9.664618E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    33500/  200000 | consumed samples:      1072000 | elapsed time per iteration (ms): 355.4 | learning rate: 6.971E-05 | global batch size:    32 | lm loss: 9.437385E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33600/  200000 | consumed samples:      1075200 | elapsed time per iteration (ms): 378.1 | learning rate: 6.962E-05 | global batch size:    32 | lm loss: 9.262152E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33700/  200000 | consumed samples:      1078400 | elapsed time per iteration (ms): 349.5 | learning rate: 6.953E-05 | global batch size:    32 | lm loss: 8.786069E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33800/  200000 | consumed samples:      1081600 | elapsed time per iteration (ms): 331.6 | learning rate: 6.944E-05 | global batch size:    32 | lm loss: 8.448579E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    33900/  200000 | consumed samples:      1084800 | elapsed time per iteration (ms): 343.0 | learning rate: 6.935E-05 | global batch size:    32 | lm loss: 8.566448E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34000/  200000 | consumed samples:      1088000 | elapsed time per iteration (ms): 367.7 | learning rate: 6.925E-05 | global batch size:    32 | lm loss: 8.593127E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34100/  200000 | consumed samples:      1091200 | elapsed time per iteration (ms): 520.2 | learning rate: 6.916E-05 | global batch size:    32 | lm loss: 8.750345E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34200/  200000 | consumed samples:      1094400 | elapsed time per iteration (ms): 327.1 | learning rate: 6.907E-05 | global batch size:    32 | lm loss: 8.950245E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34300/  200000 | consumed samples:      1097600 | elapsed time per iteration (ms): 379.5 | learning rate: 6.898E-05 | global batch size:    32 | lm loss: 8.607974E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34400/  200000 | consumed samples:      1100800 | elapsed time per iteration (ms): 356.3 | learning rate: 6.889E-05 | global batch size:    32 | lm loss: 8.192210E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34500/  200000 | consumed samples:      1104000 | elapsed time per iteration (ms): 348.0 | learning rate: 6.880E-05 | global batch size:    32 | lm loss: 8.011687E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34600/  200000 | consumed samples:      1107200 | elapsed time per iteration (ms): 381.5 | learning rate: 6.871E-05 | global batch size:    32 | lm loss: 9.390826E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34700/  200000 | consumed samples:      1110400 | elapsed time per iteration (ms): 380.8 | learning rate: 6.862E-05 | global batch size:    32 | lm loss: 8.586735E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34800/  200000 | consumed samples:      1113600 | elapsed time per iteration (ms): 381.5 | learning rate: 6.853E-05 | global batch size:    32 | lm loss: 9.292038E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34900/  200000 | consumed samples:      1116800 | elapsed time per iteration (ms): 360.2 | learning rate: 6.843E-05 | global batch size:    32 | lm loss: 9.883286E-06 | loss scale: 268435456.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35000/  200000 | consumed samples:      1120000 | elapsed time per iteration (ms): 364.3 | learning rate: 6.834E-05 | global batch size:    32 | lm loss: 1.036338E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35100/  200000 | consumed samples:      1123200 | elapsed time per iteration (ms): 356.9 | learning rate: 6.825E-05 | global batch size:    32 | lm loss: 8.773561E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    35200/  200000 | consumed samples:      1126400 | elapsed time per iteration (ms): 420.2 | learning rate: 6.816E-05 | global batch size:    32 | lm loss: 8.836563E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35300/  200000 | consumed samples:      1129600 | elapsed time per iteration (ms): 339.7 | learning rate: 6.807E-05 | global batch size:    32 | lm loss: 8.537305E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35400/  200000 | consumed samples:      1132800 | elapsed time per iteration (ms): 361.3 | learning rate: 6.798E-05 | global batch size:    32 | lm loss: 8.457889E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35500/  200000 | consumed samples:      1136000 | elapsed time per iteration (ms): 447.6 | learning rate: 6.789E-05 | global batch size:    32 | lm loss: 8.927466E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35600/  200000 | consumed samples:      1139200 | elapsed time per iteration (ms): 348.6 | learning rate: 6.780E-05 | global batch size:    32 | lm loss: 8.225574E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35700/  200000 | consumed samples:      1142400 | elapsed time per iteration (ms): 325.2 | learning rate: 6.771E-05 | global batch size:    32 | lm loss: 8.245310E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    35800/  200000 | consumed samples:      1145600 | elapsed time per iteration (ms): 402.5 | learning rate: 6.762E-05 | global batch size:    32 | lm loss: 1.085875E-05 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35900/  200000 | consumed samples:      1148800 | elapsed time per iteration (ms): 343.9 | learning rate: 6.753E-05 | global batch size:    32 | lm loss: 8.582887E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36000/  200000 | consumed samples:      1152000 | elapsed time per iteration (ms): 334.1 | learning rate: 6.743E-05 | global batch size:    32 | lm loss: 8.735312E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36100/  200000 | consumed samples:      1155200 | elapsed time per iteration (ms): 304.9 | learning rate: 6.734E-05 | global batch size:    32 | lm loss: 8.476831E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36200/  200000 | consumed samples:      1158400 | elapsed time per iteration (ms): 454.4 | learning rate: 6.725E-05 | global batch size:    32 | lm loss: 8.517418E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36300/  200000 | consumed samples:      1161600 | elapsed time per iteration (ms): 348.9 | learning rate: 6.716E-05 | global batch size:    32 | lm loss: 8.411415E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36400/  200000 | consumed samples:      1164800 | elapsed time per iteration (ms): 285.5 | learning rate: 6.707E-05 | global batch size:    32 | lm loss: 7.778351E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36500/  200000 | consumed samples:      1168000 | elapsed time per iteration (ms): 334.3 | learning rate: 6.698E-05 | global batch size:    32 | lm loss: 8.295292E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36600/  200000 | consumed samples:      1171200 | elapsed time per iteration (ms): 333.6 | learning rate: 6.689E-05 | global batch size:    32 | lm loss: 9.785605E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36700/  200000 | consumed samples:      1174400 | elapsed time per iteration (ms): 324.1 | learning rate: 6.680E-05 | global batch size:    32 | lm loss: 8.489978E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36800/  200000 | consumed samples:      1177600 | elapsed time per iteration (ms): 280.8 | learning rate: 6.671E-05 | global batch size:    32 | lm loss: 8.166044E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36900/  200000 | consumed samples:      1180800 | elapsed time per iteration (ms): 336.5 | learning rate: 6.662E-05 | global batch size:    32 | lm loss: 8.021768E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37000/  200000 | consumed samples:      1184000 | elapsed time per iteration (ms): 344.6 | learning rate: 6.652E-05 | global batch size:    32 | lm loss: 8.054373E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37100/  200000 | consumed samples:      1187200 | elapsed time per iteration (ms): 367.3 | learning rate: 6.643E-05 | global batch size:    32 | lm loss: 7.929313E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37200/  200000 | consumed samples:      1190400 | elapsed time per iteration (ms): 362.2 | learning rate: 6.634E-05 | global batch size:    32 | lm loss: 7.839777E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37300/  200000 | consumed samples:      1193600 | elapsed time per iteration (ms): 356.9 | learning rate: 6.625E-05 | global batch size:    32 | lm loss: 7.893621E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37400/  200000 | consumed samples:      1196800 | elapsed time per iteration (ms): 362.4 | learning rate: 6.616E-05 | global batch size:    32 | lm loss: 9.526412E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37500/  200000 | consumed samples:      1200000 | elapsed time per iteration (ms): 488.1 | learning rate: 6.607E-05 | global batch size:    32 | lm loss: 8.089269E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37600/  200000 | consumed samples:      1203200 | elapsed time per iteration (ms): 412.1 | learning rate: 6.598E-05 | global batch size:    32 | lm loss: 7.732348E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37700/  200000 | consumed samples:      1206400 | elapsed time per iteration (ms): 379.7 | learning rate: 6.589E-05 | global batch size:    32 | lm loss: 1.218657E-05 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37800/  200000 | consumed samples:      1209600 | elapsed time per iteration (ms): 359.0 | learning rate: 6.580E-05 | global batch size:    32 | lm loss: 8.113472E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37900/  200000 | consumed samples:      1212800 | elapsed time per iteration (ms): 415.9 | learning rate: 6.570E-05 | global batch size:    32 | lm loss: 7.603461E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38000/  200000 | consumed samples:      1216000 | elapsed time per iteration (ms): 387.2 | learning rate: 6.561E-05 | global batch size:    32 | lm loss: 7.805888E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38100/  200000 | consumed samples:      1219200 | elapsed time per iteration (ms): 364.6 | learning rate: 6.552E-05 | global batch size:    32 | lm loss: 8.083400E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38200/  200000 | consumed samples:      1222400 | elapsed time per iteration (ms): 396.1 | learning rate: 6.543E-05 | global batch size:    32 | lm loss: 7.510359E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38300/  200000 | consumed samples:      1225600 | elapsed time per iteration (ms): 346.4 | learning rate: 6.534E-05 | global batch size:    32 | lm loss: 7.582905E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38400/  200000 | consumed samples:      1228800 | elapsed time per iteration (ms): 384.4 | learning rate: 6.525E-05 | global batch size:    32 | lm loss: 7.651139E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38500/  200000 | consumed samples:      1232000 | elapsed time per iteration (ms): 340.4 | learning rate: 6.516E-05 | global batch size:    32 | lm loss: 8.212538E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38600/  200000 | consumed samples:      1235200 | elapsed time per iteration (ms): 438.5 | learning rate: 6.507E-05 | global batch size:    32 | lm loss: 7.762377E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38700/  200000 | consumed samples:      1238400 | elapsed time per iteration (ms): 335.1 | learning rate: 6.498E-05 | global batch size:    32 | lm loss: 7.860302E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38800/  200000 | consumed samples:      1241600 | elapsed time per iteration (ms): 412.6 | learning rate: 6.489E-05 | global batch size:    32 | lm loss: 8.129542E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    38900/  200000 | consumed samples:      1244800 | elapsed time per iteration (ms): 327.1 | learning rate: 6.480E-05 | global batch size:    32 | lm loss: 8.867266E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    39000/  200000 | consumed samples:      1248000 | elapsed time per iteration (ms): 370.4 | learning rate: 6.470E-05 | global batch size:    32 | lm loss: 9.448306E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39100/  200000 | consumed samples:      1251200 | elapsed time per iteration (ms): 366.3 | learning rate: 6.461E-05 | global batch size:    32 | lm loss: 8.603148E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39200/  200000 | consumed samples:      1254400 | elapsed time per iteration (ms): 376.3 | learning rate: 6.452E-05 | global batch size:    32 | lm loss: 7.899006E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39300/  200000 | consumed samples:      1257600 | elapsed time per iteration (ms): 360.2 | learning rate: 6.443E-05 | global batch size:    32 | lm loss: 8.058704E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39400/  200000 | consumed samples:      1260800 | elapsed time per iteration (ms): 363.8 | learning rate: 6.434E-05 | global batch size:    32 | lm loss: 9.099767E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39500/  200000 | consumed samples:      1264000 | elapsed time per iteration (ms): 344.7 | learning rate: 6.425E-05 | global batch size:    32 | lm loss: 8.122110E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39600/  200000 | consumed samples:      1267200 | elapsed time per iteration (ms): 388.4 | learning rate: 6.416E-05 | global batch size:    32 | lm loss: 7.956246E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39700/  200000 | consumed samples:      1270400 | elapsed time per iteration (ms): 384.3 | learning rate: 6.407E-05 | global batch size:    32 | lm loss: 7.797703E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39800/  200000 | consumed samples:      1273600 | elapsed time per iteration (ms): 376.8 | learning rate: 6.398E-05 | global batch size:    32 | lm loss: 7.889281E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    39900/  200000 | consumed samples:      1276800 | elapsed time per iteration (ms): 367.4 | learning rate: 6.389E-05 | global batch size:    32 | lm loss: 8.932739E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    40000/  200000 | consumed samples:      1280000 | elapsed time per iteration (ms): 343.7 | learning rate: 6.379E-05 | global batch size:    32 | lm loss: 8.273638E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40100/  200000 | consumed samples:      1283200 | elapsed time per iteration (ms): 849.2 | learning rate: 6.370E-05 | global batch size:    32 | lm loss: 7.697009E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40200/  200000 | consumed samples:      1286400 | elapsed time per iteration (ms): 335.2 | learning rate: 6.361E-05 | global batch size:    32 | lm loss: 7.934585E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40300/  200000 | consumed samples:      1289600 | elapsed time per iteration (ms): 373.2 | learning rate: 6.352E-05 | global batch size:    32 | lm loss: 8.194525E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40400/  200000 | consumed samples:      1292800 | elapsed time per iteration (ms): 340.9 | learning rate: 6.343E-05 | global batch size:    32 | lm loss: 8.082567E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40500/  200000 | consumed samples:      1296000 | elapsed time per iteration (ms): 436.4 | learning rate: 6.334E-05 | global batch size:    32 | lm loss: 7.432341E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40600/  200000 | consumed samples:      1299200 | elapsed time per iteration (ms): 412.9 | learning rate: 6.325E-05 | global batch size:    32 | lm loss: 7.685478E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40700/  200000 | consumed samples:      1302400 | elapsed time per iteration (ms): 375.6 | learning rate: 6.316E-05 | global batch size:    32 | lm loss: 7.402310E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40800/  200000 | consumed samples:      1305600 | elapsed time per iteration (ms): 359.6 | learning rate: 6.307E-05 | global batch size:    32 | lm loss: 7.280411E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    40900/  200000 | consumed samples:      1308800 | elapsed time per iteration (ms): 364.5 | learning rate: 6.298E-05 | global batch size:    32 | lm loss: 7.240415E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41000/  200000 | consumed samples:      1312000 | elapsed time per iteration (ms): 396.8 | learning rate: 6.288E-05 | global batch size:    32 | lm loss: 7.428216E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41100/  200000 | consumed samples:      1315200 | elapsed time per iteration (ms): 360.3 | learning rate: 6.279E-05 | global batch size:    32 | lm loss: 7.722307E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41200/  200000 | consumed samples:      1318400 | elapsed time per iteration (ms): 351.2 | learning rate: 6.270E-05 | global batch size:    32 | lm loss: 7.581277E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41300/  200000 | consumed samples:      1321600 | elapsed time per iteration (ms): 363.4 | learning rate: 6.261E-05 | global batch size:    32 | lm loss: 7.107871E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41400/  200000 | consumed samples:      1324800 | elapsed time per iteration (ms): 348.6 | learning rate: 6.252E-05 | global batch size:    32 | lm loss: 7.262329E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41500/  200000 | consumed samples:      1328000 | elapsed time per iteration (ms): 423.3 | learning rate: 6.243E-05 | global batch size:    32 | lm loss: 7.147969E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41600/  200000 | consumed samples:      1331200 | elapsed time per iteration (ms): 353.8 | learning rate: 6.234E-05 | global batch size:    32 | lm loss: 7.697093E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41700/  200000 | consumed samples:      1334400 | elapsed time per iteration (ms): 371.4 | learning rate: 6.225E-05 | global batch size:    32 | lm loss: 7.518724E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41800/  200000 | consumed samples:      1337600 | elapsed time per iteration (ms): 336.1 | learning rate: 6.216E-05 | global batch size:    32 | lm loss: 7.754587E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    41900/  200000 | consumed samples:      1340800 | elapsed time per iteration (ms): 359.7 | learning rate: 6.206E-05 | global batch size:    32 | lm loss: 7.504846E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42000/  200000 | consumed samples:      1344000 | elapsed time per iteration (ms): 418.1 | learning rate: 6.197E-05 | global batch size:    32 | lm loss: 7.735334E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42100/  200000 | consumed samples:      1347200 | elapsed time per iteration (ms): 344.0 | learning rate: 6.188E-05 | global batch size:    32 | lm loss: 7.869402E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42200/  200000 | consumed samples:      1350400 | elapsed time per iteration (ms): 372.0 | learning rate: 6.179E-05 | global batch size:    32 | lm loss: 7.950376E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42300/  200000 | consumed samples:      1353600 | elapsed time per iteration (ms): 363.6 | learning rate: 6.170E-05 | global batch size:    32 | lm loss: 8.426643E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42400/  200000 | consumed samples:      1356800 | elapsed time per iteration (ms): 344.6 | learning rate: 6.161E-05 | global batch size:    32 | lm loss: 7.689788E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42500/  200000 | consumed samples:      1360000 | elapsed time per iteration (ms): 356.7 | learning rate: 6.152E-05 | global batch size:    32 | lm loss: 7.910136E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    42600/  200000 | consumed samples:      1363200 | elapsed time per iteration (ms): 392.8 | learning rate: 6.143E-05 | global batch size:    32 | lm loss: 7.558080E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    42700/  200000 | consumed samples:      1366400 | elapsed time per iteration (ms): 356.9 | learning rate: 6.134E-05 | global batch size:    32 | lm loss: 7.982610E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42800/  200000 | consumed samples:      1369600 | elapsed time per iteration (ms): 341.3 | learning rate: 6.125E-05 | global batch size:    32 | lm loss: 7.659320E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    42900/  200000 | consumed samples:      1372800 | elapsed time per iteration (ms): 350.2 | learning rate: 6.116E-05 | global batch size:    32 | lm loss: 7.233054E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43000/  200000 | consumed samples:      1376000 | elapsed time per iteration (ms): 425.6 | learning rate: 6.106E-05 | global batch size:    32 | lm loss: 8.578757E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43100/  200000 | consumed samples:      1379200 | elapsed time per iteration (ms): 353.4 | learning rate: 6.097E-05 | global batch size:    32 | lm loss: 8.513852E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43200/  200000 | consumed samples:      1382400 | elapsed time per iteration (ms): 341.0 | learning rate: 6.088E-05 | global batch size:    32 | lm loss: 7.887324E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43300/  200000 | consumed samples:      1385600 | elapsed time per iteration (ms): 375.9 | learning rate: 6.079E-05 | global batch size:    32 | lm loss: 7.461784E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43400/  200000 | consumed samples:      1388800 | elapsed time per iteration (ms): 362.7 | learning rate: 6.070E-05 | global batch size:    32 | lm loss: 7.750312E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43500/  200000 | consumed samples:      1392000 | elapsed time per iteration (ms): 361.7 | learning rate: 6.061E-05 | global batch size:    32 | lm loss: 7.463570E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43600/  200000 | consumed samples:      1395200 | elapsed time per iteration (ms): 351.0 | learning rate: 6.052E-05 | global batch size:    32 | lm loss: 7.812607E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43700/  200000 | consumed samples:      1398400 | elapsed time per iteration (ms): 404.7 | learning rate: 6.043E-05 | global batch size:    32 | lm loss: 7.306704E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43800/  200000 | consumed samples:      1401600 | elapsed time per iteration (ms): 332.3 | learning rate: 6.034E-05 | global batch size:    32 | lm loss: 7.284806E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    43900/  200000 | consumed samples:      1404800 | elapsed time per iteration (ms): 306.2 | learning rate: 6.025E-05 | global batch size:    32 | lm loss: 7.877645E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    44000/  200000 | consumed samples:      1408000 | elapsed time per iteration (ms): 306.6 | learning rate: 6.015E-05 | global batch size:    32 | lm loss: 7.416091E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44100/  200000 | consumed samples:      1411200 | elapsed time per iteration (ms): 348.7 | learning rate: 6.006E-05 | global batch size:    32 | lm loss: 7.238601E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44200/  200000 | consumed samples:      1414400 | elapsed time per iteration (ms): 337.9 | learning rate: 5.997E-05 | global batch size:    32 | lm loss: 7.680085E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44300/  200000 | consumed samples:      1417600 | elapsed time per iteration (ms): 297.7 | learning rate: 5.988E-05 | global batch size:    32 | lm loss: 7.821468E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44400/  200000 | consumed samples:      1420800 | elapsed time per iteration (ms): 337.6 | learning rate: 5.979E-05 | global batch size:    32 | lm loss: 7.582873E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44500/  200000 | consumed samples:      1424000 | elapsed time per iteration (ms): 324.5 | learning rate: 5.970E-05 | global batch size:    32 | lm loss: 9.055897E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44600/  200000 | consumed samples:      1427200 | elapsed time per iteration (ms): 420.6 | learning rate: 5.961E-05 | global batch size:    32 | lm loss: 7.474786E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44700/  200000 | consumed samples:      1430400 | elapsed time per iteration (ms): 287.9 | learning rate: 5.952E-05 | global batch size:    32 | lm loss: 7.439366E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44800/  200000 | consumed samples:      1433600 | elapsed time per iteration (ms): 320.0 | learning rate: 5.943E-05 | global batch size:    32 | lm loss: 7.756242E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    44900/  200000 | consumed samples:      1436800 | elapsed time per iteration (ms): 359.4 | learning rate: 5.934E-05 | global batch size:    32 | lm loss: 7.243803E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45000/  200000 | consumed samples:      1440000 | elapsed time per iteration (ms): 319.6 | learning rate: 5.924E-05 | global batch size:    32 | lm loss: 7.318815E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45100/  200000 | consumed samples:      1443200 | elapsed time per iteration (ms): 293.2 | learning rate: 5.915E-05 | global batch size:    32 | lm loss: 7.561059E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45200/  200000 | consumed samples:      1446400 | elapsed time per iteration (ms): 363.6 | learning rate: 5.906E-05 | global batch size:    32 | lm loss: 8.427497E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45300/  200000 | consumed samples:      1449600 | elapsed time per iteration (ms): 399.4 | learning rate: 5.897E-05 | global batch size:    32 | lm loss: 8.440370E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45400/  200000 | consumed samples:      1452800 | elapsed time per iteration (ms): 453.4 | learning rate: 5.888E-05 | global batch size:    32 | lm loss: 7.688953E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45500/  200000 | consumed samples:      1456000 | elapsed time per iteration (ms): 381.2 | learning rate: 5.879E-05 | global batch size:    32 | lm loss: 7.244771E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45600/  200000 | consumed samples:      1459200 | elapsed time per iteration (ms): 407.4 | learning rate: 5.870E-05 | global batch size:    32 | lm loss: 7.154931E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    45700/  200000 | consumed samples:      1462400 | elapsed time per iteration (ms): 392.1 | learning rate: 5.861E-05 | global batch size:    32 | lm loss: 7.310634E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45800/  200000 | consumed samples:      1465600 | elapsed time per iteration (ms): 380.9 | learning rate: 5.852E-05 | global batch size:    32 | lm loss: 7.282327E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    45900/  200000 | consumed samples:      1468800 | elapsed time per iteration (ms): 351.8 | learning rate: 5.843E-05 | global batch size:    32 | lm loss: 7.040605E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46000/  200000 | consumed samples:      1472000 | elapsed time per iteration (ms): 355.1 | learning rate: 5.833E-05 | global batch size:    32 | lm loss: 7.312163E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    46100/  200000 | consumed samples:      1475200 | elapsed time per iteration (ms): 416.8 | learning rate: 5.824E-05 | global batch size:    32 | lm loss: 7.500869E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46200/  200000 | consumed samples:      1478400 | elapsed time per iteration (ms): 362.8 | learning rate: 5.815E-05 | global batch size:    32 | lm loss: 7.192480E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46300/  200000 | consumed samples:      1481600 | elapsed time per iteration (ms): 362.5 | learning rate: 5.806E-05 | global batch size:    32 | lm loss: 8.251956E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46400/  200000 | consumed samples:      1484800 | elapsed time per iteration (ms): 353.6 | learning rate: 5.797E-05 | global batch size:    32 | lm loss: 7.061108E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46500/  200000 | consumed samples:      1488000 | elapsed time per iteration (ms): 347.7 | learning rate: 5.788E-05 | global batch size:    32 | lm loss: 7.349477E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46600/  200000 | consumed samples:      1491200 | elapsed time per iteration (ms): 393.9 | learning rate: 5.779E-05 | global batch size:    32 | lm loss: 7.300870E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46700/  200000 | consumed samples:      1494400 | elapsed time per iteration (ms): 360.0 | learning rate: 5.770E-05 | global batch size:    32 | lm loss: 7.213046E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46800/  200000 | consumed samples:      1497600 | elapsed time per iteration (ms): 461.5 | learning rate: 5.761E-05 | global batch size:    32 | lm loss: 7.339905E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    46900/  200000 | consumed samples:      1500800 | elapsed time per iteration (ms): 331.2 | learning rate: 5.752E-05 | global batch size:    32 | lm loss: 6.711737E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47000/  200000 | consumed samples:      1504000 | elapsed time per iteration (ms): 427.8 | learning rate: 5.742E-05 | global batch size:    32 | lm loss: 7.032785E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47100/  200000 | consumed samples:      1507200 | elapsed time per iteration (ms): 367.1 | learning rate: 5.733E-05 | global batch size:    32 | lm loss: 7.292708E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47200/  200000 | consumed samples:      1510400 | elapsed time per iteration (ms): 368.8 | learning rate: 5.724E-05 | global batch size:    32 | lm loss: 7.207902E-06 | loss scale: 134217728.0 | grad norm: 0.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    47300/  200000 | consumed samples:      1513600 | elapsed time per iteration (ms): 337.9 | learning rate: 5.715E-05 | global batch size:    32 | lm loss: 6.926933E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47400/  200000 | consumed samples:      1516800 | elapsed time per iteration (ms): 381.2 | learning rate: 5.706E-05 | global batch size:    32 | lm loss: 7.157853E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47500/  200000 | consumed samples:      1520000 | elapsed time per iteration (ms): 341.7 | learning rate: 5.697E-05 | global batch size:    32 | lm loss: 6.826506E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47600/  200000 | consumed samples:      1523200 | elapsed time per iteration (ms): 375.1 | learning rate: 5.688E-05 | global batch size:    32 | lm loss: 7.801197E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47700/  200000 | consumed samples:      1526400 | elapsed time per iteration (ms): 363.8 | learning rate: 5.679E-05 | global batch size:    32 | lm loss: 7.552466E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47800/  200000 | consumed samples:      1529600 | elapsed time per iteration (ms): 420.7 | learning rate: 5.670E-05 | global batch size:    32 | lm loss: 7.331033E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    47900/  200000 | consumed samples:      1532800 | elapsed time per iteration (ms): 357.7 | learning rate: 5.661E-05 | global batch size:    32 | lm loss: 7.029321E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48000/  200000 | consumed samples:      1536000 | elapsed time per iteration (ms): 391.2 | learning rate: 5.651E-05 | global batch size:    32 | lm loss: 7.034066E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48100/  200000 | consumed samples:      1539200 | elapsed time per iteration (ms): 362.6 | learning rate: 5.642E-05 | global batch size:    32 | lm loss: 6.497990E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48200/  200000 | consumed samples:      1542400 | elapsed time per iteration (ms): 361.8 | learning rate: 5.633E-05 | global batch size:    32 | lm loss: 7.001518E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48300/  200000 | consumed samples:      1545600 | elapsed time per iteration (ms): 340.2 | learning rate: 5.624E-05 | global batch size:    32 | lm loss: 7.204957E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48400/  200000 | consumed samples:      1548800 | elapsed time per iteration (ms): 377.6 | learning rate: 5.615E-05 | global batch size:    32 | lm loss: 7.100040E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48500/  200000 | consumed samples:      1552000 | elapsed time per iteration (ms): 363.0 | learning rate: 5.606E-05 | global batch size:    32 | lm loss: 7.097581E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48600/  200000 | consumed samples:      1555200 | elapsed time per iteration (ms): 459.3 | learning rate: 5.597E-05 | global batch size:    32 | lm loss: 7.170030E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48700/  200000 | consumed samples:      1558400 | elapsed time per iteration (ms): 368.0 | learning rate: 5.588E-05 | global batch size:    32 | lm loss: 7.267983E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48800/  200000 | consumed samples:      1561600 | elapsed time per iteration (ms): 421.8 | learning rate: 5.579E-05 | global batch size:    32 | lm loss: 6.919411E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    48900/  200000 | consumed samples:      1564800 | elapsed time per iteration (ms): 358.2 | learning rate: 5.570E-05 | global batch size:    32 | lm loss: 6.787218E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49000/  200000 | consumed samples:      1568000 | elapsed time per iteration (ms): 375.3 | learning rate: 5.560E-05 | global batch size:    32 | lm loss: 6.757607E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49100/  200000 | consumed samples:      1571200 | elapsed time per iteration (ms): 352.8 | learning rate: 5.551E-05 | global batch size:    32 | lm loss: 6.855142E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49200/  200000 | consumed samples:      1574400 | elapsed time per iteration (ms): 379.9 | learning rate: 5.542E-05 | global batch size:    32 | lm loss: 7.232351E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49300/  200000 | consumed samples:      1577600 | elapsed time per iteration (ms): 341.2 | learning rate: 5.533E-05 | global batch size:    32 | lm loss: 6.976839E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    49400/  200000 | consumed samples:      1580800 | elapsed time per iteration (ms): 383.1 | learning rate: 5.524E-05 | global batch size:    32 | lm loss: 7.189668E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49500/  200000 | consumed samples:      1584000 | elapsed time per iteration (ms): 348.2 | learning rate: 5.515E-05 | global batch size:    32 | lm loss: 6.731233E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49600/  200000 | consumed samples:      1587200 | elapsed time per iteration (ms): 366.4 | learning rate: 5.506E-05 | global batch size:    32 | lm loss: 7.072450E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49700/  200000 | consumed samples:      1590400 | elapsed time per iteration (ms): 318.7 | learning rate: 5.497E-05 | global batch size:    32 | lm loss: 7.435471E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49800/  200000 | consumed samples:      1593600 | elapsed time per iteration (ms): 404.0 | learning rate: 5.488E-05 | global batch size:    32 | lm loss: 6.730357E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    49900/  200000 | consumed samples:      1596800 | elapsed time per iteration (ms): 475.8 | learning rate: 5.479E-05 | global batch size:    32 | lm loss: 6.908959E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50000/  200000 | consumed samples:      1600000 | elapsed time per iteration (ms): 398.5 | learning rate: 5.469E-05 | global batch size:    32 | lm loss: 7.666808E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50100/  200000 | consumed samples:      1603200 | elapsed time per iteration (ms): 361.3 | learning rate: 5.460E-05 | global batch size:    32 | lm loss: 6.586444E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50200/  200000 | consumed samples:      1606400 | elapsed time per iteration (ms): 375.8 | learning rate: 5.451E-05 | global batch size:    32 | lm loss: 6.332552E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50300/  200000 | consumed samples:      1609600 | elapsed time per iteration (ms): 355.9 | learning rate: 5.442E-05 | global batch size:    32 | lm loss: 6.578040E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50400/  200000 | consumed samples:      1612800 | elapsed time per iteration (ms): 382.1 | learning rate: 5.433E-05 | global batch size:    32 | lm loss: 6.701348E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    50500/  200000 | consumed samples:      1616000 | elapsed time per iteration (ms): 358.4 | learning rate: 5.424E-05 | global batch size:    32 | lm loss: 6.733040E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50600/  200000 | consumed samples:      1619200 | elapsed time per iteration (ms): 404.9 | learning rate: 5.415E-05 | global batch size:    32 | lm loss: 7.159603E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50700/  200000 | consumed samples:      1622400 | elapsed time per iteration (ms): 290.7 | learning rate: 5.406E-05 | global batch size:    32 | lm loss: 6.792913E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50800/  200000 | consumed samples:      1625600 | elapsed time per iteration (ms): 410.9 | learning rate: 5.397E-05 | global batch size:    32 | lm loss: 7.391816E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    50900/  200000 | consumed samples:      1628800 | elapsed time per iteration (ms): 318.4 | learning rate: 5.388E-05 | global batch size:    32 | lm loss: 7.075180E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51000/  200000 | consumed samples:      1632000 | elapsed time per iteration (ms): 355.6 | learning rate: 5.379E-05 | global batch size:    32 | lm loss: 7.024854E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51100/  200000 | consumed samples:      1635200 | elapsed time per iteration (ms): 347.1 | learning rate: 5.370E-05 | global batch size:    32 | lm loss: 7.085972E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51200/  200000 | consumed samples:      1638400 | elapsed time per iteration (ms): 325.9 | learning rate: 5.360E-05 | global batch size:    32 | lm loss: 7.497495E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51300/  200000 | consumed samples:      1641600 | elapsed time per iteration (ms): 343.7 | learning rate: 5.351E-05 | global batch size:    32 | lm loss: 7.372470E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51400/  200000 | consumed samples:      1644800 | elapsed time per iteration (ms): 307.8 | learning rate: 5.342E-05 | global batch size:    32 | lm loss: 7.377805E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51500/  200000 | consumed samples:      1648000 | elapsed time per iteration (ms): 344.4 | learning rate: 5.333E-05 | global batch size:    32 | lm loss: 6.787812E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51600/  200000 | consumed samples:      1651200 | elapsed time per iteration (ms): 359.5 | learning rate: 5.324E-05 | global batch size:    32 | lm loss: 6.700584E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51700/  200000 | consumed samples:      1654400 | elapsed time per iteration (ms): 349.3 | learning rate: 5.315E-05 | global batch size:    32 | lm loss: 6.965212E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51800/  200000 | consumed samples:      1657600 | elapsed time per iteration (ms): 357.8 | learning rate: 5.306E-05 | global batch size:    32 | lm loss: 7.124601E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    51900/  200000 | consumed samples:      1660800 | elapsed time per iteration (ms): 317.8 | learning rate: 5.297E-05 | global batch size:    32 | lm loss: 6.461055E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52000/  200000 | consumed samples:      1664000 | elapsed time per iteration (ms): 323.1 | learning rate: 5.288E-05 | global batch size:    32 | lm loss: 7.629217E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    52100/  200000 | consumed samples:      1667200 | elapsed time per iteration (ms): 338.0 | learning rate: 5.279E-05 | global batch size:    32 | lm loss: 6.843286E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52200/  200000 | consumed samples:      1670400 | elapsed time per iteration (ms): 371.3 | learning rate: 5.270E-05 | global batch size:    32 | lm loss: 6.542074E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52300/  200000 | consumed samples:      1673600 | elapsed time per iteration (ms): 325.8 | learning rate: 5.261E-05 | global batch size:    32 | lm loss: 7.596877E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52400/  200000 | consumed samples:      1676800 | elapsed time per iteration (ms): 349.1 | learning rate: 5.251E-05 | global batch size:    32 | lm loss: 6.438940E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52500/  200000 | consumed samples:      1680000 | elapsed time per iteration (ms): 359.8 | learning rate: 5.242E-05 | global batch size:    32 | lm loss: 6.606337E-06 | loss scale: 67108864.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52600/  200000 | consumed samples:      1683200 | elapsed time per iteration (ms): 394.8 | learning rate: 5.233E-05 | global batch size:    32 | lm loss: 7.099101E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52700/  200000 | consumed samples:      1686400 | elapsed time per iteration (ms): 285.4 | learning rate: 5.224E-05 | global batch size:    32 | lm loss: 6.661630E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52800/  200000 | consumed samples:      1689600 | elapsed time per iteration (ms): 472.7 | learning rate: 5.215E-05 | global batch size:    32 | lm loss: 6.738458E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    52900/  200000 | consumed samples:      1692800 | elapsed time per iteration (ms): 366.9 | learning rate: 5.206E-05 | global batch size:    32 | lm loss: 6.291950E-06 | loss scale: 67108864.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53000/  200000 | consumed samples:      1696000 | elapsed time per iteration (ms): 366.9 | learning rate: 5.197E-05 | global batch size:    32 | lm loss: 6.748368E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53100/  200000 | consumed samples:      1699200 | elapsed time per iteration (ms): 379.8 | learning rate: 5.188E-05 | global batch size:    32 | lm loss: 6.086416E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53200/  200000 | consumed samples:      1702400 | elapsed time per iteration (ms): 342.2 | learning rate: 5.179E-05 | global batch size:    32 | lm loss: 6.960752E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53300/  200000 | consumed samples:      1705600 | elapsed time per iteration (ms): 350.8 | learning rate: 5.169E-05 | global batch size:    32 | lm loss: 6.275313E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53400/  200000 | consumed samples:      1708800 | elapsed time per iteration (ms): 372.3 | learning rate: 5.160E-05 | global batch size:    32 | lm loss: 6.821460E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53500/  200000 | consumed samples:      1712000 | elapsed time per iteration (ms): 505.3 | learning rate: 5.151E-05 | global batch size:    32 | lm loss: 6.403960E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53600/  200000 | consumed samples:      1715200 | elapsed time per iteration (ms): 391.3 | learning rate: 5.142E-05 | global batch size:    32 | lm loss: 6.648480E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53700/  200000 | consumed samples:      1718400 | elapsed time per iteration (ms): 379.2 | learning rate: 5.133E-05 | global batch size:    32 | lm loss: 6.549475E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53800/  200000 | consumed samples:      1721600 | elapsed time per iteration (ms): 383.8 | learning rate: 5.124E-05 | global batch size:    32 | lm loss: 6.324821E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    53900/  200000 | consumed samples:      1724800 | elapsed time per iteration (ms): 358.3 | learning rate: 5.115E-05 | global batch size:    32 | lm loss: 6.589235E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54000/  200000 | consumed samples:      1728000 | elapsed time per iteration (ms): 369.7 | learning rate: 5.106E-05 | global batch size:    32 | lm loss: 6.154861E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54100/  200000 | consumed samples:      1731200 | elapsed time per iteration (ms): 373.6 | learning rate: 5.097E-05 | global batch size:    32 | lm loss: 6.120954E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54200/  200000 | consumed samples:      1734400 | elapsed time per iteration (ms): 386.7 | learning rate: 5.087E-05 | global batch size:    32 | lm loss: 8.527042E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54300/  200000 | consumed samples:      1737600 | elapsed time per iteration (ms): 339.9 | learning rate: 5.078E-05 | global batch size:    32 | lm loss: 7.952593E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54400/  200000 | consumed samples:      1740800 | elapsed time per iteration (ms): 405.0 | learning rate: 5.069E-05 | global batch size:    32 | lm loss: 6.686482E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54500/  200000 | consumed samples:      1744000 | elapsed time per iteration (ms): 334.6 | learning rate: 5.060E-05 | global batch size:    32 | lm loss: 6.452063E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54600/  200000 | consumed samples:      1747200 | elapsed time per iteration (ms): 416.8 | learning rate: 5.051E-05 | global batch size:    32 | lm loss: 6.563478E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54700/  200000 | consumed samples:      1750400 | elapsed time per iteration (ms): 358.5 | learning rate: 5.042E-05 | global batch size:    32 | lm loss: 6.667679E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54800/  200000 | consumed samples:      1753600 | elapsed time per iteration (ms): 373.3 | learning rate: 5.033E-05 | global batch size:    32 | lm loss: 6.928944E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    54900/  200000 | consumed samples:      1756800 | elapsed time per iteration (ms): 363.6 | learning rate: 5.024E-05 | global batch size:    32 | lm loss: 6.336276E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55000/  200000 | consumed samples:      1760000 | elapsed time per iteration (ms): 391.2 | learning rate: 5.015E-05 | global batch size:    32 | lm loss: 6.661338E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55100/  200000 | consumed samples:      1763200 | elapsed time per iteration (ms): 344.9 | learning rate: 5.005E-05 | global batch size:    32 | lm loss: 6.737617E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55200/  200000 | consumed samples:      1766400 | elapsed time per iteration (ms): 386.3 | learning rate: 4.996E-05 | global batch size:    32 | lm loss: 6.749414E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55300/  200000 | consumed samples:      1769600 | elapsed time per iteration (ms): 349.1 | learning rate: 4.987E-05 | global batch size:    32 | lm loss: 6.641196E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55400/  200000 | consumed samples:      1772800 | elapsed time per iteration (ms): 371.0 | learning rate: 4.978E-05 | global batch size:    32 | lm loss: 6.561285E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55500/  200000 | consumed samples:      1776000 | elapsed time per iteration (ms): 342.6 | learning rate: 4.969E-05 | global batch size:    32 | lm loss: 6.509243E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55600/  200000 | consumed samples:      1779200 | elapsed time per iteration (ms): 379.9 | learning rate: 4.960E-05 | global batch size:    32 | lm loss: 6.337255E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55700/  200000 | consumed samples:      1782400 | elapsed time per iteration (ms): 391.8 | learning rate: 4.951E-05 | global batch size:    32 | lm loss: 6.341547E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55800/  200000 | consumed samples:      1785600 | elapsed time per iteration (ms): 355.5 | learning rate: 4.942E-05 | global batch size:    32 | lm loss: 6.522242E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    55900/  200000 | consumed samples:      1788800 | elapsed time per iteration (ms): 360.3 | learning rate: 4.933E-05 | global batch size:    32 | lm loss: 6.932351E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    56000/  200000 | consumed samples:      1792000 | elapsed time per iteration (ms): 333.5 | learning rate: 4.924E-05 | global batch size:    32 | lm loss: 6.518131E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56100/  200000 | consumed samples:      1795200 | elapsed time per iteration (ms): 367.9 | learning rate: 4.915E-05 | global batch size:    32 | lm loss: 6.752736E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56200/  200000 | consumed samples:      1798400 | elapsed time per iteration (ms): 424.9 | learning rate: 4.906E-05 | global batch size:    32 | lm loss: 6.291536E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56300/  200000 | consumed samples:      1801600 | elapsed time per iteration (ms): 373.9 | learning rate: 4.896E-05 | global batch size:    32 | lm loss: 6.267499E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56400/  200000 | consumed samples:      1804800 | elapsed time per iteration (ms): 382.2 | learning rate: 4.887E-05 | global batch size:    32 | lm loss: 6.941673E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56500/  200000 | consumed samples:      1808000 | elapsed time per iteration (ms): 350.7 | learning rate: 4.878E-05 | global batch size:    32 | lm loss: 7.328659E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56600/  200000 | consumed samples:      1811200 | elapsed time per iteration (ms): 454.8 | learning rate: 4.869E-05 | global batch size:    32 | lm loss: 6.439671E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56700/  200000 | consumed samples:      1814400 | elapsed time per iteration (ms): 357.8 | learning rate: 4.860E-05 | global batch size:    32 | lm loss: 6.171695E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56800/  200000 | consumed samples:      1817600 | elapsed time per iteration (ms): 378.6 | learning rate: 4.851E-05 | global batch size:    32 | lm loss: 6.301311E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    56900/  200000 | consumed samples:      1820800 | elapsed time per iteration (ms): 353.1 | learning rate: 4.842E-05 | global batch size:    32 | lm loss: 6.152120E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57000/  200000 | consumed samples:      1824000 | elapsed time per iteration (ms): 370.8 | learning rate: 4.833E-05 | global batch size:    32 | lm loss: 6.231234E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57100/  200000 | consumed samples:      1827200 | elapsed time per iteration (ms): 385.5 | learning rate: 4.824E-05 | global batch size:    32 | lm loss: 6.477254E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57200/  200000 | consumed samples:      1830400 | elapsed time per iteration (ms): 379.2 | learning rate: 4.814E-05 | global batch size:    32 | lm loss: 6.412425E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57300/  200000 | consumed samples:      1833600 | elapsed time per iteration (ms): 359.6 | learning rate: 4.805E-05 | global batch size:    32 | lm loss: 6.524761E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57400/  200000 | consumed samples:      1836800 | elapsed time per iteration (ms): 366.4 | learning rate: 4.796E-05 | global batch size:    32 | lm loss: 6.312350E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57500/  200000 | consumed samples:      1840000 | elapsed time per iteration (ms): 348.6 | learning rate: 4.787E-05 | global batch size:    32 | lm loss: 6.404353E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57600/  200000 | consumed samples:      1843200 | elapsed time per iteration (ms): 418.8 | learning rate: 4.778E-05 | global batch size:    32 | lm loss: 6.517494E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57700/  200000 | consumed samples:      1846400 | elapsed time per iteration (ms): 336.4 | learning rate: 4.769E-05 | global batch size:    32 | lm loss: 6.383492E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57800/  200000 | consumed samples:      1849600 | elapsed time per iteration (ms): 355.4 | learning rate: 4.760E-05 | global batch size:    32 | lm loss: 7.088304E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    57900/  200000 | consumed samples:      1852800 | elapsed time per iteration (ms): 339.1 | learning rate: 4.751E-05 | global batch size:    32 | lm loss: 6.488219E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58000/  200000 | consumed samples:      1856000 | elapsed time per iteration (ms): 331.3 | learning rate: 4.742E-05 | global batch size:    32 | lm loss: 6.646639E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58100/  200000 | consumed samples:      1859200 | elapsed time per iteration (ms): 345.6 | learning rate: 4.732E-05 | global batch size:    32 | lm loss: 6.503295E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58200/  200000 | consumed samples:      1862400 | elapsed time per iteration (ms): 338.3 | learning rate: 4.723E-05 | global batch size:    32 | lm loss: 6.904094E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    58300/  200000 | consumed samples:      1865600 | elapsed time per iteration (ms): 371.2 | learning rate: 4.714E-05 | global batch size:    32 | lm loss: 6.347097E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58400/  200000 | consumed samples:      1868800 | elapsed time per iteration (ms): 372.0 | learning rate: 4.705E-05 | global batch size:    32 | lm loss: 6.405179E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58500/  200000 | consumed samples:      1872000 | elapsed time per iteration (ms): 358.9 | learning rate: 4.696E-05 | global batch size:    32 | lm loss: 6.850648E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58600/  200000 | consumed samples:      1875200 | elapsed time per iteration (ms): 425.9 | learning rate: 4.687E-05 | global batch size:    32 | lm loss: 6.426011E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58700/  200000 | consumed samples:      1878400 | elapsed time per iteration (ms): 361.2 | learning rate: 4.678E-05 | global batch size:    32 | lm loss: 6.618054E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58800/  200000 | consumed samples:      1881600 | elapsed time per iteration (ms): 343.3 | learning rate: 4.669E-05 | global batch size:    32 | lm loss: 6.543593E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    58900/  200000 | consumed samples:      1884800 | elapsed time per iteration (ms): 328.2 | learning rate: 4.660E-05 | global batch size:    32 | lm loss: 6.244444E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59000/  200000 | consumed samples:      1888000 | elapsed time per iteration (ms): 337.5 | learning rate: 4.651E-05 | global batch size:    32 | lm loss: 6.625629E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    59100/  200000 | consumed samples:      1891200 | elapsed time per iteration (ms): 339.9 | learning rate: 4.642E-05 | global batch size:    32 | lm loss: 6.739566E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59200/  200000 | consumed samples:      1894400 | elapsed time per iteration (ms): 346.4 | learning rate: 4.632E-05 | global batch size:    32 | lm loss: 6.495256E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59300/  200000 | consumed samples:      1897600 | elapsed time per iteration (ms): 569.0 | learning rate: 4.623E-05 | global batch size:    32 | lm loss: 6.495506E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    59400/  200000 | consumed samples:      1900800 | elapsed time per iteration (ms): 340.1 | learning rate: 4.614E-05 | global batch size:    32 | lm loss: 6.053807E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59500/  200000 | consumed samples:      1904000 | elapsed time per iteration (ms): 311.6 | learning rate: 4.605E-05 | global batch size:    32 | lm loss: 6.083779E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59600/  200000 | consumed samples:      1907200 | elapsed time per iteration (ms): 318.1 | learning rate: 4.596E-05 | global batch size:    32 | lm loss: 6.116157E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59700/  200000 | consumed samples:      1910400 | elapsed time per iteration (ms): 286.6 | learning rate: 4.587E-05 | global batch size:    32 | lm loss: 6.287027E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59800/  200000 | consumed samples:      1913600 | elapsed time per iteration (ms): 291.4 | learning rate: 4.578E-05 | global batch size:    32 | lm loss: 6.098516E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    59900/  200000 | consumed samples:      1916800 | elapsed time per iteration (ms): 336.7 | learning rate: 4.569E-05 | global batch size:    32 | lm loss: 6.173838E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60000/  200000 | consumed samples:      1920000 | elapsed time per iteration (ms): 455.5 | learning rate: 4.560E-05 | global batch size:    32 | lm loss: 6.241398E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60100/  200000 | consumed samples:      1923200 | elapsed time per iteration (ms): 711.6 | learning rate: 4.551E-05 | global batch size:    32 | lm loss: 6.044355E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60200/  200000 | consumed samples:      1926400 | elapsed time per iteration (ms): 308.0 | learning rate: 4.541E-05 | global batch size:    32 | lm loss: 6.240620E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60300/  200000 | consumed samples:      1929600 | elapsed time per iteration (ms): 354.2 | learning rate: 4.532E-05 | global batch size:    32 | lm loss: 5.994836E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60400/  200000 | consumed samples:      1932800 | elapsed time per iteration (ms): 359.2 | learning rate: 4.523E-05 | global batch size:    32 | lm loss: 7.524098E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60500/  200000 | consumed samples:      1936000 | elapsed time per iteration (ms): 347.8 | learning rate: 4.514E-05 | global batch size:    32 | lm loss: 6.360174E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60600/  200000 | consumed samples:      1939200 | elapsed time per iteration (ms): 391.8 | learning rate: 4.505E-05 | global batch size:    32 | lm loss: 6.192470E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60700/  200000 | consumed samples:      1942400 | elapsed time per iteration (ms): 373.4 | learning rate: 4.496E-05 | global batch size:    32 | lm loss: 6.219171E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60800/  200000 | consumed samples:      1945600 | elapsed time per iteration (ms): 355.2 | learning rate: 4.487E-05 | global batch size:    32 | lm loss: 6.335998E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    60900/  200000 | consumed samples:      1948800 | elapsed time per iteration (ms): 355.5 | learning rate: 4.478E-05 | global batch size:    32 | lm loss: 6.402713E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61000/  200000 | consumed samples:      1952000 | elapsed time per iteration (ms): 326.0 | learning rate: 4.469E-05 | global batch size:    32 | lm loss: 6.479099E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61100/  200000 | consumed samples:      1955200 | elapsed time per iteration (ms): 370.3 | learning rate: 4.459E-05 | global batch size:    32 | lm loss: 6.041679E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61200/  200000 | consumed samples:      1958400 | elapsed time per iteration (ms): 281.2 | learning rate: 4.450E-05 | global batch size:    32 | lm loss: 6.943754E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61300/  200000 | consumed samples:      1961600 | elapsed time per iteration (ms): 355.7 | learning rate: 4.441E-05 | global batch size:    32 | lm loss: 6.144622E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61400/  200000 | consumed samples:      1964800 | elapsed time per iteration (ms): 538.8 | learning rate: 4.432E-05 | global batch size:    32 | lm loss: 6.502100E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    61500/  200000 | consumed samples:      1968000 | elapsed time per iteration (ms): 498.3 | learning rate: 4.423E-05 | global batch size:    32 | lm loss: 6.404360E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61600/  200000 | consumed samples:      1971200 | elapsed time per iteration (ms): 365.0 | learning rate: 4.414E-05 | global batch size:    32 | lm loss: 6.399482E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61700/  200000 | consumed samples:      1974400 | elapsed time per iteration (ms): 351.8 | learning rate: 4.405E-05 | global batch size:    32 | lm loss: 6.259754E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61800/  200000 | consumed samples:      1977600 | elapsed time per iteration (ms): 361.7 | learning rate: 4.396E-05 | global batch size:    32 | lm loss: 6.070351E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    61900/  200000 | consumed samples:      1980800 | elapsed time per iteration (ms): 358.7 | learning rate: 4.387E-05 | global batch size:    32 | lm loss: 6.342795E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62000/  200000 | consumed samples:      1984000 | elapsed time per iteration (ms): 345.0 | learning rate: 4.378E-05 | global batch size:    32 | lm loss: 6.544460E-06 | loss scale: 134217728.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62100/  200000 | consumed samples:      1987200 | elapsed time per iteration (ms): 362.8 | learning rate: 4.369E-05 | global batch size:    32 | lm loss: 6.210094E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62200/  200000 | consumed samples:      1990400 | elapsed time per iteration (ms): 354.0 | learning rate: 4.360E-05 | global batch size:    32 | lm loss: 6.055644E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62300/  200000 | consumed samples:      1993600 | elapsed time per iteration (ms): 396.9 | learning rate: 4.350E-05 | global batch size:    32 | lm loss: 6.304146E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62400/  200000 | consumed samples:      1996800 | elapsed time per iteration (ms): 443.1 | learning rate: 4.341E-05 | global batch size:    32 | lm loss: 6.233039E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62500/  200000 | consumed samples:      2000000 | elapsed time per iteration (ms): 349.8 | learning rate: 4.332E-05 | global batch size:    32 | lm loss: 5.636498E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62600/  200000 | consumed samples:      2003200 | elapsed time per iteration (ms): 386.3 | learning rate: 4.323E-05 | global batch size:    32 | lm loss: 6.008276E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62700/  200000 | consumed samples:      2006400 | elapsed time per iteration (ms): 398.8 | learning rate: 4.314E-05 | global batch size:    32 | lm loss: 5.819790E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62800/  200000 | consumed samples:      2009600 | elapsed time per iteration (ms): 341.9 | learning rate: 4.305E-05 | global batch size:    32 | lm loss: 6.188775E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    62900/  200000 | consumed samples:      2012800 | elapsed time per iteration (ms): 378.4 | learning rate: 4.296E-05 | global batch size:    32 | lm loss: 5.955588E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63000/  200000 | consumed samples:      2016000 | elapsed time per iteration (ms): 349.6 | learning rate: 4.287E-05 | global batch size:    32 | lm loss: 6.109173E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63100/  200000 | consumed samples:      2019200 | elapsed time per iteration (ms): 378.8 | learning rate: 4.278E-05 | global batch size:    32 | lm loss: 5.746750E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63200/  200000 | consumed samples:      2022400 | elapsed time per iteration (ms): 346.9 | learning rate: 4.268E-05 | global batch size:    32 | lm loss: 5.970389E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63300/  200000 | consumed samples:      2025600 | elapsed time per iteration (ms): 388.7 | learning rate: 4.259E-05 | global batch size:    32 | lm loss: 6.244378E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63400/  200000 | consumed samples:      2028800 | elapsed time per iteration (ms): 363.3 | learning rate: 4.250E-05 | global batch size:    32 | lm loss: 6.259627E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63500/  200000 | consumed samples:      2032000 | elapsed time per iteration (ms): 370.8 | learning rate: 4.241E-05 | global batch size:    32 | lm loss: 6.102381E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63600/  200000 | consumed samples:      2035200 | elapsed time per iteration (ms): 397.1 | learning rate: 4.232E-05 | global batch size:    32 | lm loss: 6.018991E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63700/  200000 | consumed samples:      2038400 | elapsed time per iteration (ms): 406.1 | learning rate: 4.223E-05 | global batch size:    32 | lm loss: 6.257485E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63800/  200000 | consumed samples:      2041600 | elapsed time per iteration (ms): 327.2 | learning rate: 4.214E-05 | global batch size:    32 | lm loss: 5.979030E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    63900/  200000 | consumed samples:      2044800 | elapsed time per iteration (ms): 373.2 | learning rate: 4.205E-05 | global batch size:    32 | lm loss: 6.282004E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    64000/  200000 | consumed samples:      2048000 | elapsed time per iteration (ms): 335.8 | learning rate: 4.196E-05 | global batch size:    32 | lm loss: 6.487282E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64100/  200000 | consumed samples:      2051200 | elapsed time per iteration (ms): 369.6 | learning rate: 4.187E-05 | global batch size:    32 | lm loss: 6.204823E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64200/  200000 | consumed samples:      2054400 | elapsed time per iteration (ms): 366.7 | learning rate: 4.178E-05 | global batch size:    32 | lm loss: 6.230831E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64300/  200000 | consumed samples:      2057600 | elapsed time per iteration (ms): 366.0 | learning rate: 4.168E-05 | global batch size:    32 | lm loss: 6.387281E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64400/  200000 | consumed samples:      2060800 | elapsed time per iteration (ms): 374.3 | learning rate: 4.159E-05 | global batch size:    32 | lm loss: 6.370616E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64500/  200000 | consumed samples:      2064000 | elapsed time per iteration (ms): 344.1 | learning rate: 4.150E-05 | global batch size:    32 | lm loss: 6.467049E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64600/  200000 | consumed samples:      2067200 | elapsed time per iteration (ms): 512.7 | learning rate: 4.141E-05 | global batch size:    32 | lm loss: 6.436506E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    64700/  200000 | consumed samples:      2070400 | elapsed time per iteration (ms): 334.6 | learning rate: 4.132E-05 | global batch size:    32 | lm loss: 6.079830E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64800/  200000 | consumed samples:      2073600 | elapsed time per iteration (ms): 365.4 | learning rate: 4.123E-05 | global batch size:    32 | lm loss: 6.056298E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    64900/  200000 | consumed samples:      2076800 | elapsed time per iteration (ms): 338.0 | learning rate: 4.114E-05 | global batch size:    32 | lm loss: 6.553309E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65000/  200000 | consumed samples:      2080000 | elapsed time per iteration (ms): 377.0 | learning rate: 4.105E-05 | global batch size:    32 | lm loss: 6.206771E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65100/  200000 | consumed samples:      2083200 | elapsed time per iteration (ms): 336.1 | learning rate: 4.096E-05 | global batch size:    32 | lm loss: 6.070826E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65200/  200000 | consumed samples:      2086400 | elapsed time per iteration (ms): 401.4 | learning rate: 4.087E-05 | global batch size:    32 | lm loss: 6.057105E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65300/  200000 | consumed samples:      2089600 | elapsed time per iteration (ms): 342.9 | learning rate: 4.077E-05 | global batch size:    32 | lm loss: 6.157259E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65400/  200000 | consumed samples:      2092800 | elapsed time per iteration (ms): 384.8 | learning rate: 4.068E-05 | global batch size:    32 | lm loss: 6.430206E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65500/  200000 | consumed samples:      2096000 | elapsed time per iteration (ms): 371.2 | learning rate: 4.059E-05 | global batch size:    32 | lm loss: 6.170530E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65600/  200000 | consumed samples:      2099200 | elapsed time per iteration (ms): 427.1 | learning rate: 4.050E-05 | global batch size:    32 | lm loss: 5.745293E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65700/  200000 | consumed samples:      2102400 | elapsed time per iteration (ms): 374.6 | learning rate: 4.041E-05 | global batch size:    32 | lm loss: 5.609096E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65800/  200000 | consumed samples:      2105600 | elapsed time per iteration (ms): 409.3 | learning rate: 4.032E-05 | global batch size:    32 | lm loss: 5.765277E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    65900/  200000 | consumed samples:      2108800 | elapsed time per iteration (ms): 348.5 | learning rate: 4.023E-05 | global batch size:    32 | lm loss: 5.936869E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66000/  200000 | consumed samples:      2112000 | elapsed time per iteration (ms): 369.7 | learning rate: 4.014E-05 | global batch size:    32 | lm loss: 6.240656E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66100/  200000 | consumed samples:      2115200 | elapsed time per iteration (ms): 337.5 | learning rate: 4.005E-05 | global batch size:    32 | lm loss: 6.063323E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66200/  200000 | consumed samples:      2118400 | elapsed time per iteration (ms): 373.1 | learning rate: 3.995E-05 | global batch size:    32 | lm loss: 6.424113E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66300/  200000 | consumed samples:      2121600 | elapsed time per iteration (ms): 359.7 | learning rate: 3.986E-05 | global batch size:    32 | lm loss: 6.174995E-06 | loss scale: 268435456.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66400/  200000 | consumed samples:      2124800 | elapsed time per iteration (ms): 371.5 | learning rate: 3.977E-05 | global batch size:    32 | lm loss: 6.207081E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66500/  200000 | consumed samples:      2128000 | elapsed time per iteration (ms): 421.4 | learning rate: 3.968E-05 | global batch size:    32 | lm loss: 5.948558E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66600/  200000 | consumed samples:      2131200 | elapsed time per iteration (ms): 454.2 | learning rate: 3.959E-05 | global batch size:    32 | lm loss: 6.364674E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    66700/  200000 | consumed samples:      2134400 | elapsed time per iteration (ms): 341.0 | learning rate: 3.950E-05 | global batch size:    32 | lm loss: 5.728638E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66800/  200000 | consumed samples:      2137600 | elapsed time per iteration (ms): 340.1 | learning rate: 3.941E-05 | global batch size:    32 | lm loss: 5.940344E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    66900/  200000 | consumed samples:      2140800 | elapsed time per iteration (ms): 368.6 | learning rate: 3.932E-05 | global batch size:    32 | lm loss: 5.963230E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67000/  200000 | consumed samples:      2144000 | elapsed time per iteration (ms): 342.1 | learning rate: 3.923E-05 | global batch size:    32 | lm loss: 5.969604E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67100/  200000 | consumed samples:      2147200 | elapsed time per iteration (ms): 389.1 | learning rate: 3.914E-05 | global batch size:    32 | lm loss: 5.908537E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67200/  200000 | consumed samples:      2150400 | elapsed time per iteration (ms): 376.5 | learning rate: 3.905E-05 | global batch size:    32 | lm loss: 6.019237E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67300/  200000 | consumed samples:      2153600 | elapsed time per iteration (ms): 318.1 | learning rate: 3.895E-05 | global batch size:    32 | lm loss: 6.140096E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67400/  200000 | consumed samples:      2156800 | elapsed time per iteration (ms): 322.6 | learning rate: 3.886E-05 | global batch size:    32 | lm loss: 6.032783E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67500/  200000 | consumed samples:      2160000 | elapsed time per iteration (ms): 324.0 | learning rate: 3.877E-05 | global batch size:    32 | lm loss: 5.849851E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67600/  200000 | consumed samples:      2163200 | elapsed time per iteration (ms): 331.1 | learning rate: 3.868E-05 | global batch size:    32 | lm loss: 5.907933E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67700/  200000 | consumed samples:      2166400 | elapsed time per iteration (ms): 341.6 | learning rate: 3.859E-05 | global batch size:    32 | lm loss: 5.908677E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    67800/  200000 | consumed samples:      2169600 | elapsed time per iteration (ms): 401.1 | learning rate: 3.850E-05 | global batch size:    32 | lm loss: 6.024628E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    67900/  200000 | consumed samples:      2172800 | elapsed time per iteration (ms): 425.6 | learning rate: 3.841E-05 | global batch size:    32 | lm loss: 5.996780E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68000/  200000 | consumed samples:      2176000 | elapsed time per iteration (ms): 326.8 | learning rate: 3.832E-05 | global batch size:    32 | lm loss: 6.057735E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68100/  200000 | consumed samples:      2179200 | elapsed time per iteration (ms): 324.1 | learning rate: 3.823E-05 | global batch size:    32 | lm loss: 5.835482E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68200/  200000 | consumed samples:      2182400 | elapsed time per iteration (ms): 334.3 | learning rate: 3.814E-05 | global batch size:    32 | lm loss: 6.146511E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68300/  200000 | consumed samples:      2185600 | elapsed time per iteration (ms): 368.6 | learning rate: 3.805E-05 | global batch size:    32 | lm loss: 5.887875E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    68400/  200000 | consumed samples:      2188800 | elapsed time per iteration (ms): 343.8 | learning rate: 3.796E-05 | global batch size:    32 | lm loss: 6.096754E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68500/  200000 | consumed samples:      2192000 | elapsed time per iteration (ms): 311.1 | learning rate: 3.786E-05 | global batch size:    32 | lm loss: 6.056999E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68600/  200000 | consumed samples:      2195200 | elapsed time per iteration (ms): 482.2 | learning rate: 3.777E-05 | global batch size:    32 | lm loss: 5.900766E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68700/  200000 | consumed samples:      2198400 | elapsed time per iteration (ms): 325.0 | learning rate: 3.768E-05 | global batch size:    32 | lm loss: 5.701749E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68800/  200000 | consumed samples:      2201600 | elapsed time per iteration (ms): 356.2 | learning rate: 3.759E-05 | global batch size:    32 | lm loss: 5.549207E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    68900/  200000 | consumed samples:      2204800 | elapsed time per iteration (ms): 371.9 | learning rate: 3.750E-05 | global batch size:    32 | lm loss: 5.780890E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69000/  200000 | consumed samples:      2208000 | elapsed time per iteration (ms): 302.9 | learning rate: 3.741E-05 | global batch size:    32 | lm loss: 5.862722E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69100/  200000 | consumed samples:      2211200 | elapsed time per iteration (ms): 301.7 | learning rate: 3.732E-05 | global batch size:    32 | lm loss: 5.899930E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69200/  200000 | consumed samples:      2214400 | elapsed time per iteration (ms): 289.3 | learning rate: 3.723E-05 | global batch size:    32 | lm loss: 5.760582E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69300/  200000 | consumed samples:      2217600 | elapsed time per iteration (ms): 283.2 | learning rate: 3.714E-05 | global batch size:    32 | lm loss: 5.649013E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69400/  200000 | consumed samples:      2220800 | elapsed time per iteration (ms): 379.2 | learning rate: 3.704E-05 | global batch size:    32 | lm loss: 5.931046E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69500/  200000 | consumed samples:      2224000 | elapsed time per iteration (ms): 387.7 | learning rate: 3.695E-05 | global batch size:    32 | lm loss: 6.011829E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69600/  200000 | consumed samples:      2227200 | elapsed time per iteration (ms): 485.2 | learning rate: 3.686E-05 | global batch size:    32 | lm loss: 5.580524E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69700/  200000 | consumed samples:      2230400 | elapsed time per iteration (ms): 403.7 | learning rate: 3.677E-05 | global batch size:    32 | lm loss: 5.457868E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69800/  200000 | consumed samples:      2233600 | elapsed time per iteration (ms): 359.2 | learning rate: 3.668E-05 | global batch size:    32 | lm loss: 6.012879E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    69900/  200000 | consumed samples:      2236800 | elapsed time per iteration (ms): 407.6 | learning rate: 3.659E-05 | global batch size:    32 | lm loss: 5.827800E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70000/  200000 | consumed samples:      2240000 | elapsed time per iteration (ms): 354.4 | learning rate: 3.650E-05 | global batch size:    32 | lm loss: 5.810269E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70100/  200000 | consumed samples:      2243200 | elapsed time per iteration (ms): 387.8 | learning rate: 3.641E-05 | global batch size:    32 | lm loss: 5.906743E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70200/  200000 | consumed samples:      2246400 | elapsed time per iteration (ms): 341.1 | learning rate: 3.632E-05 | global batch size:    32 | lm loss: 5.829387E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70300/  200000 | consumed samples:      2249600 | elapsed time per iteration (ms): 414.5 | learning rate: 3.622E-05 | global batch size:    32 | lm loss: 6.025516E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70400/  200000 | consumed samples:      2252800 | elapsed time per iteration (ms): 341.9 | learning rate: 3.613E-05 | global batch size:    32 | lm loss: 6.226845E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70500/  200000 | consumed samples:      2256000 | elapsed time per iteration (ms): 370.6 | learning rate: 3.604E-05 | global batch size:    32 | lm loss: 6.179684E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70600/  200000 | consumed samples:      2259200 | elapsed time per iteration (ms): 390.9 | learning rate: 3.595E-05 | global batch size:    32 | lm loss: 6.014262E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70700/  200000 | consumed samples:      2262400 | elapsed time per iteration (ms): 380.3 | learning rate: 3.586E-05 | global batch size:    32 | lm loss: 5.912518E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70800/  200000 | consumed samples:      2265600 | elapsed time per iteration (ms): 380.0 | learning rate: 3.577E-05 | global batch size:    32 | lm loss: 5.602218E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    70900/  200000 | consumed samples:      2268800 | elapsed time per iteration (ms): 376.0 | learning rate: 3.568E-05 | global batch size:    32 | lm loss: 5.947497E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71000/  200000 | consumed samples:      2272000 | elapsed time per iteration (ms): 344.0 | learning rate: 3.559E-05 | global batch size:    32 | lm loss: 6.289854E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71100/  200000 | consumed samples:      2275200 | elapsed time per iteration (ms): 365.4 | learning rate: 3.550E-05 | global batch size:    32 | lm loss: 6.126452E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71200/  200000 | consumed samples:      2278400 | elapsed time per iteration (ms): 340.9 | learning rate: 3.540E-05 | global batch size:    32 | lm loss: 6.156364E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71300/  200000 | consumed samples:      2281600 | elapsed time per iteration (ms): 388.3 | learning rate: 3.532E-05 | global batch size:    32 | lm loss: 6.324046E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    71400/  200000 | consumed samples:      2284800 | elapsed time per iteration (ms): 366.3 | learning rate: 3.522E-05 | global batch size:    32 | lm loss: 6.204449E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71500/  200000 | consumed samples:      2288000 | elapsed time per iteration (ms): 366.5 | learning rate: 3.513E-05 | global batch size:    32 | lm loss: 6.236843E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71600/  200000 | consumed samples:      2291200 | elapsed time per iteration (ms): 387.5 | learning rate: 3.504E-05 | global batch size:    32 | lm loss: 5.785394E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71700/  200000 | consumed samples:      2294400 | elapsed time per iteration (ms): 355.1 | learning rate: 3.495E-05 | global batch size:    32 | lm loss: 6.072526E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71800/  200000 | consumed samples:      2297600 | elapsed time per iteration (ms): 423.9 | learning rate: 3.486E-05 | global batch size:    32 | lm loss: 5.887086E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    71900/  200000 | consumed samples:      2300800 | elapsed time per iteration (ms): 370.1 | learning rate: 3.477E-05 | global batch size:    32 | lm loss: 5.664509E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72000/  200000 | consumed samples:      2304000 | elapsed time per iteration (ms): 362.9 | learning rate: 3.468E-05 | global batch size:    32 | lm loss: 5.597586E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72100/  200000 | consumed samples:      2307200 | elapsed time per iteration (ms): 366.5 | learning rate: 3.459E-05 | global batch size:    32 | lm loss: 5.761181E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72200/  200000 | consumed samples:      2310400 | elapsed time per iteration (ms): 359.4 | learning rate: 3.450E-05 | global batch size:    32 | lm loss: 5.843791E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72300/  200000 | consumed samples:      2313600 | elapsed time per iteration (ms): 399.9 | learning rate: 3.440E-05 | global batch size:    32 | lm loss: 5.814511E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72400/  200000 | consumed samples:      2316800 | elapsed time per iteration (ms): 362.3 | learning rate: 3.431E-05 | global batch size:    32 | lm loss: 6.109629E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72500/  200000 | consumed samples:      2320000 | elapsed time per iteration (ms): 389.4 | learning rate: 3.422E-05 | global batch size:    32 | lm loss: 6.254016E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72600/  200000 | consumed samples:      2323200 | elapsed time per iteration (ms): 379.1 | learning rate: 3.413E-05 | global batch size:    32 | lm loss: 5.789206E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72700/  200000 | consumed samples:      2326400 | elapsed time per iteration (ms): 375.5 | learning rate: 3.404E-05 | global batch size:    32 | lm loss: 5.721409E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72800/  200000 | consumed samples:      2329600 | elapsed time per iteration (ms): 397.0 | learning rate: 3.395E-05 | global batch size:    32 | lm loss: 5.853599E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    72900/  200000 | consumed samples:      2332800 | elapsed time per iteration (ms): 354.3 | learning rate: 3.386E-05 | global batch size:    32 | lm loss: 6.192410E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73000/  200000 | consumed samples:      2336000 | elapsed time per iteration (ms): 356.9 | learning rate: 3.377E-05 | global batch size:    32 | lm loss: 5.779429E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73100/  200000 | consumed samples:      2339200 | elapsed time per iteration (ms): 382.6 | learning rate: 3.368E-05 | global batch size:    32 | lm loss: 5.965637E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73200/  200000 | consumed samples:      2342400 | elapsed time per iteration (ms): 362.8 | learning rate: 3.358E-05 | global batch size:    32 | lm loss: 5.757835E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73300/  200000 | consumed samples:      2345600 | elapsed time per iteration (ms): 356.4 | learning rate: 3.349E-05 | global batch size:    32 | lm loss: 6.024683E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73400/  200000 | consumed samples:      2348800 | elapsed time per iteration (ms): 355.5 | learning rate: 3.340E-05 | global batch size:    32 | lm loss: 5.947196E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73500/  200000 | consumed samples:      2352000 | elapsed time per iteration (ms): 343.7 | learning rate: 3.331E-05 | global batch size:    32 | lm loss: 6.364780E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73600/  200000 | consumed samples:      2355200 | elapsed time per iteration (ms): 381.7 | learning rate: 3.322E-05 | global batch size:    32 | lm loss: 6.007338E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    73700/  200000 | consumed samples:      2358400 | elapsed time per iteration (ms): 404.0 | learning rate: 3.313E-05 | global batch size:    32 | lm loss: 5.973711E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73800/  200000 | consumed samples:      2361600 | elapsed time per iteration (ms): 353.2 | learning rate: 3.304E-05 | global batch size:    32 | lm loss: 5.938274E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    73900/  200000 | consumed samples:      2364800 | elapsed time per iteration (ms): 360.6 | learning rate: 3.295E-05 | global batch size:    32 | lm loss: 5.983798E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74000/  200000 | consumed samples:      2368000 | elapsed time per iteration (ms): 355.5 | learning rate: 3.286E-05 | global batch size:    32 | lm loss: 6.209209E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74100/  200000 | consumed samples:      2371200 | elapsed time per iteration (ms): 357.6 | learning rate: 3.277E-05 | global batch size:    32 | lm loss: 6.047517E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74200/  200000 | consumed samples:      2374400 | elapsed time per iteration (ms): 355.0 | learning rate: 3.268E-05 | global batch size:    32 | lm loss: 5.844540E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74300/  200000 | consumed samples:      2377600 | elapsed time per iteration (ms): 346.3 | learning rate: 3.259E-05 | global batch size:    32 | lm loss: 6.076517E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74400/  200000 | consumed samples:      2380800 | elapsed time per iteration (ms): 489.6 | learning rate: 3.249E-05 | global batch size:    32 | lm loss: 5.751477E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74500/  200000 | consumed samples:      2384000 | elapsed time per iteration (ms): 341.0 | learning rate: 3.240E-05 | global batch size:    32 | lm loss: 6.000774E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74600/  200000 | consumed samples:      2387200 | elapsed time per iteration (ms): 425.8 | learning rate: 3.231E-05 | global batch size:    32 | lm loss: 5.499305E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74700/  200000 | consumed samples:      2390400 | elapsed time per iteration (ms): 336.3 | learning rate: 3.222E-05 | global batch size:    32 | lm loss: 6.026618E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74800/  200000 | consumed samples:      2393600 | elapsed time per iteration (ms): 381.1 | learning rate: 3.213E-05 | global batch size:    32 | lm loss: 5.939172E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    74900/  200000 | consumed samples:      2396800 | elapsed time per iteration (ms): 401.0 | learning rate: 3.204E-05 | global batch size:    32 | lm loss: 5.681065E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75000/  200000 | consumed samples:      2400000 | elapsed time per iteration (ms): 381.5 | learning rate: 3.195E-05 | global batch size:    32 | lm loss: 5.687789E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75100/  200000 | consumed samples:      2403200 | elapsed time per iteration (ms): 517.5 | learning rate: 3.186E-05 | global batch size:    32 | lm loss: 5.684228E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75200/  200000 | consumed samples:      2406400 | elapsed time per iteration (ms): 354.7 | learning rate: 3.177E-05 | global batch size:    32 | lm loss: 5.611988E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75300/  200000 | consumed samples:      2409600 | elapsed time per iteration (ms): 339.3 | learning rate: 3.167E-05 | global batch size:    32 | lm loss: 5.557734E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75400/  200000 | consumed samples:      2412800 | elapsed time per iteration (ms): 359.5 | learning rate: 3.158E-05 | global batch size:    32 | lm loss: 5.567152E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75500/  200000 | consumed samples:      2416000 | elapsed time per iteration (ms): 301.2 | learning rate: 3.149E-05 | global batch size:    32 | lm loss: 5.827904E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75600/  200000 | consumed samples:      2419200 | elapsed time per iteration (ms): 361.7 | learning rate: 3.140E-05 | global batch size:    32 | lm loss: 5.632006E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75700/  200000 | consumed samples:      2422400 | elapsed time per iteration (ms): 314.2 | learning rate: 3.131E-05 | global batch size:    32 | lm loss: 5.813144E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    75800/  200000 | consumed samples:      2425600 | elapsed time per iteration (ms): 404.9 | learning rate: 3.122E-05 | global batch size:    32 | lm loss: 5.693527E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    75900/  200000 | consumed samples:      2428800 | elapsed time per iteration (ms): 482.6 | learning rate: 3.113E-05 | global batch size:    32 | lm loss: 6.529079E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76000/  200000 | consumed samples:      2432000 | elapsed time per iteration (ms): 306.3 | learning rate: 3.104E-05 | global batch size:    32 | lm loss: 5.873455E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76100/  200000 | consumed samples:      2435200 | elapsed time per iteration (ms): 327.8 | learning rate: 3.095E-05 | global batch size:    32 | lm loss: 5.702772E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76200/  200000 | consumed samples:      2438400 | elapsed time per iteration (ms): 329.0 | learning rate: 3.086E-05 | global batch size:    32 | lm loss: 5.679216E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76300/  200000 | consumed samples:      2441600 | elapsed time per iteration (ms): 297.4 | learning rate: 3.077E-05 | global batch size:    32 | lm loss: 5.730130E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76400/  200000 | consumed samples:      2444800 | elapsed time per iteration (ms): 291.3 | learning rate: 3.067E-05 | global batch size:    32 | lm loss: 5.769433E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76500/  200000 | consumed samples:      2448000 | elapsed time per iteration (ms): 298.6 | learning rate: 3.058E-05 | global batch size:    32 | lm loss: 5.736527E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76600/  200000 | consumed samples:      2451200 | elapsed time per iteration (ms): 451.2 | learning rate: 3.049E-05 | global batch size:    32 | lm loss: 5.801338E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    76700/  200000 | consumed samples:      2454400 | elapsed time per iteration (ms): 351.3 | learning rate: 3.040E-05 | global batch size:    32 | lm loss: 5.858660E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76800/  200000 | consumed samples:      2457600 | elapsed time per iteration (ms): 366.3 | learning rate: 3.031E-05 | global batch size:    32 | lm loss: 5.780091E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    76900/  200000 | consumed samples:      2460800 | elapsed time per iteration (ms): 357.9 | learning rate: 3.022E-05 | global batch size:    32 | lm loss: 5.550345E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77000/  200000 | consumed samples:      2464000 | elapsed time per iteration (ms): 327.6 | learning rate: 3.013E-05 | global batch size:    32 | lm loss: 5.928783E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77100/  200000 | consumed samples:      2467200 | elapsed time per iteration (ms): 302.1 | learning rate: 3.004E-05 | global batch size:    32 | lm loss: 5.520497E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77200/  200000 | consumed samples:      2470400 | elapsed time per iteration (ms): 312.3 | learning rate: 2.995E-05 | global batch size:    32 | lm loss: 5.732871E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77300/  200000 | consumed samples:      2473600 | elapsed time per iteration (ms): 515.4 | learning rate: 2.986E-05 | global batch size:    32 | lm loss: 5.906409E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77400/  200000 | consumed samples:      2476800 | elapsed time per iteration (ms): 406.1 | learning rate: 2.976E-05 | global batch size:    32 | lm loss: 6.034859E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77500/  200000 | consumed samples:      2480000 | elapsed time per iteration (ms): 344.7 | learning rate: 2.967E-05 | global batch size:    32 | lm loss: 5.887554E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77600/  200000 | consumed samples:      2483200 | elapsed time per iteration (ms): 507.2 | learning rate: 2.958E-05 | global batch size:    32 | lm loss: 5.997704E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77700/  200000 | consumed samples:      2486400 | elapsed time per iteration (ms): 347.6 | learning rate: 2.949E-05 | global batch size:    32 | lm loss: 6.024049E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77800/  200000 | consumed samples:      2489600 | elapsed time per iteration (ms): 419.7 | learning rate: 2.940E-05 | global batch size:    32 | lm loss: 5.779355E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    77900/  200000 | consumed samples:      2492800 | elapsed time per iteration (ms): 346.3 | learning rate: 2.931E-05 | global batch size:    32 | lm loss: 5.910106E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78000/  200000 | consumed samples:      2496000 | elapsed time per iteration (ms): 428.2 | learning rate: 2.922E-05 | global batch size:    32 | lm loss: 5.479856E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78100/  200000 | consumed samples:      2499200 | elapsed time per iteration (ms): 379.2 | learning rate: 2.913E-05 | global batch size:    32 | lm loss: 5.636392E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78200/  200000 | consumed samples:      2502400 | elapsed time per iteration (ms): 343.1 | learning rate: 2.904E-05 | global batch size:    32 | lm loss: 5.395350E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78300/  200000 | consumed samples:      2505600 | elapsed time per iteration (ms): 334.6 | learning rate: 2.894E-05 | global batch size:    32 | lm loss: 5.535514E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78400/  200000 | consumed samples:      2508800 | elapsed time per iteration (ms): 413.4 | learning rate: 2.885E-05 | global batch size:    32 | lm loss: 5.857034E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78500/  200000 | consumed samples:      2512000 | elapsed time per iteration (ms): 355.2 | learning rate: 2.876E-05 | global batch size:    32 | lm loss: 5.804703E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78600/  200000 | consumed samples:      2515200 | elapsed time per iteration (ms): 400.0 | learning rate: 2.867E-05 | global batch size:    32 | lm loss: 5.638694E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78700/  200000 | consumed samples:      2518400 | elapsed time per iteration (ms): 402.1 | learning rate: 2.858E-05 | global batch size:    32 | lm loss: 5.609519E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    78800/  200000 | consumed samples:      2521600 | elapsed time per iteration (ms): 372.9 | learning rate: 2.849E-05 | global batch size:    32 | lm loss: 5.700590E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    78900/  200000 | consumed samples:      2524800 | elapsed time per iteration (ms): 358.6 | learning rate: 2.840E-05 | global batch size:    32 | lm loss: 5.423918E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    79000/  200000 | consumed samples:      2528000 | elapsed time per iteration (ms): 363.9 | learning rate: 2.831E-05 | global batch size:    32 | lm loss: 5.627444E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79100/  200000 | consumed samples:      2531200 | elapsed time per iteration (ms): 395.0 | learning rate: 2.822E-05 | global batch size:    32 | lm loss: 5.880435E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79200/  200000 | consumed samples:      2534400 | elapsed time per iteration (ms): 341.3 | learning rate: 2.813E-05 | global batch size:    32 | lm loss: 5.569339E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79300/  200000 | consumed samples:      2537600 | elapsed time per iteration (ms): 370.9 | learning rate: 2.804E-05 | global batch size:    32 | lm loss: 5.605646E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79400/  200000 | consumed samples:      2540800 | elapsed time per iteration (ms): 386.9 | learning rate: 2.794E-05 | global batch size:    32 | lm loss: 5.591384E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79500/  200000 | consumed samples:      2544000 | elapsed time per iteration (ms): 355.2 | learning rate: 2.785E-05 | global batch size:    32 | lm loss: 5.737392E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79600/  200000 | consumed samples:      2547200 | elapsed time per iteration (ms): 346.9 | learning rate: 2.776E-05 | global batch size:    32 | lm loss: 5.557137E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79700/  200000 | consumed samples:      2550400 | elapsed time per iteration (ms): 386.3 | learning rate: 2.767E-05 | global batch size:    32 | lm loss: 5.596848E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79800/  200000 | consumed samples:      2553600 | elapsed time per iteration (ms): 358.7 | learning rate: 2.758E-05 | global batch size:    32 | lm loss: 5.800546E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    79900/  200000 | consumed samples:      2556800 | elapsed time per iteration (ms): 348.2 | learning rate: 2.749E-05 | global batch size:    32 | lm loss: 5.710709E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80000/  200000 | consumed samples:      2560000 | elapsed time per iteration (ms): 361.2 | learning rate: 2.740E-05 | global batch size:    32 | lm loss: 5.840708E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80100/  200000 | consumed samples:      2563200 | elapsed time per iteration (ms): 837.0 | learning rate: 2.731E-05 | global batch size:    32 | lm loss: 5.346765E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80200/  200000 | consumed samples:      2566400 | elapsed time per iteration (ms): 404.2 | learning rate: 2.722E-05 | global batch size:    32 | lm loss: 5.816165E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80300/  200000 | consumed samples:      2569600 | elapsed time per iteration (ms): 365.3 | learning rate: 2.713E-05 | global batch size:    32 | lm loss: 5.768291E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80400/  200000 | consumed samples:      2572800 | elapsed time per iteration (ms): 355.2 | learning rate: 2.703E-05 | global batch size:    32 | lm loss: 5.704537E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80500/  200000 | consumed samples:      2576000 | elapsed time per iteration (ms): 389.2 | learning rate: 2.694E-05 | global batch size:    32 | lm loss: 6.002035E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80600/  200000 | consumed samples:      2579200 | elapsed time per iteration (ms): 422.8 | learning rate: 2.685E-05 | global batch size:    32 | lm loss: 5.951680E-06 | loss scale: 536870912.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80700/  200000 | consumed samples:      2582400 | elapsed time per iteration (ms): 343.6 | learning rate: 2.676E-05 | global batch size:    32 | lm loss: 5.666210E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80800/  200000 | consumed samples:      2585600 | elapsed time per iteration (ms): 356.6 | learning rate: 2.667E-05 | global batch size:    32 | lm loss: 5.614015E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    80900/  200000 | consumed samples:      2588800 | elapsed time per iteration (ms): 367.5 | learning rate: 2.658E-05 | global batch size:    32 | lm loss: 5.559516E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81000/  200000 | consumed samples:      2592000 | elapsed time per iteration (ms): 368.4 | learning rate: 2.649E-05 | global batch size:    32 | lm loss: 5.756739E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81100/  200000 | consumed samples:      2595200 | elapsed time per iteration (ms): 376.4 | learning rate: 2.640E-05 | global batch size:    32 | lm loss: 5.616942E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81200/  200000 | consumed samples:      2598400 | elapsed time per iteration (ms): 420.3 | learning rate: 2.631E-05 | global batch size:    32 | lm loss: 5.320540E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81300/  200000 | consumed samples:      2601600 | elapsed time per iteration (ms): 335.2 | learning rate: 2.621E-05 | global batch size:    32 | lm loss: 5.650185E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81400/  200000 | consumed samples:      2604800 | elapsed time per iteration (ms): 330.5 | learning rate: 2.612E-05 | global batch size:    32 | lm loss: 5.687571E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81500/  200000 | consumed samples:      2608000 | elapsed time per iteration (ms): 394.4 | learning rate: 2.603E-05 | global batch size:    32 | lm loss: 5.743608E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81600/  200000 | consumed samples:      2611200 | elapsed time per iteration (ms): 386.4 | learning rate: 2.594E-05 | global batch size:    32 | lm loss: 5.466102E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81700/  200000 | consumed samples:      2614400 | elapsed time per iteration (ms): 354.1 | learning rate: 2.585E-05 | global batch size:    32 | lm loss: 5.660810E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81800/  200000 | consumed samples:      2617600 | elapsed time per iteration (ms): 368.2 | learning rate: 2.576E-05 | global batch size:    32 | lm loss: 5.617585E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    81900/  200000 | consumed samples:      2620800 | elapsed time per iteration (ms): 346.0 | learning rate: 2.567E-05 | global batch size:    32 | lm loss: 5.401517E-06 | loss scale: 1073741824.0 | grad norm: 0.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    82000/  200000 | consumed samples:      2624000 | elapsed time per iteration (ms): 358.2 | learning rate: 2.558E-05 | global batch size:    32 | lm loss: 5.862381E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    82100/  200000 | consumed samples:      2627200 | elapsed time per iteration (ms): 342.9 | learning rate: 2.549E-05 | global batch size:    32 | lm loss: 5.702371E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82200/  200000 | consumed samples:      2630400 | elapsed time per iteration (ms): 392.5 | learning rate: 2.540E-05 | global batch size:    32 | lm loss: 5.382128E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82300/  200000 | consumed samples:      2633600 | elapsed time per iteration (ms): 369.4 | learning rate: 2.531E-05 | global batch size:    32 | lm loss: 5.539004E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82400/  200000 | consumed samples:      2636800 | elapsed time per iteration (ms): 335.7 | learning rate: 2.521E-05 | global batch size:    32 | lm loss: 5.804392E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82500/  200000 | consumed samples:      2640000 | elapsed time per iteration (ms): 345.7 | learning rate: 2.512E-05 | global batch size:    32 | lm loss: 6.048095E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82600/  200000 | consumed samples:      2643200 | elapsed time per iteration (ms): 382.5 | learning rate: 2.503E-05 | global batch size:    32 | lm loss: 5.673651E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82700/  200000 | consumed samples:      2646400 | elapsed time per iteration (ms): 368.5 | learning rate: 2.494E-05 | global batch size:    32 | lm loss: 5.719112E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82800/  200000 | consumed samples:      2649600 | elapsed time per iteration (ms): 348.5 | learning rate: 2.485E-05 | global batch size:    32 | lm loss: 5.519083E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    82900/  200000 | consumed samples:      2652800 | elapsed time per iteration (ms): 395.0 | learning rate: 2.476E-05 | global batch size:    32 | lm loss: 5.919606E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83000/  200000 | consumed samples:      2656000 | elapsed time per iteration (ms): 366.2 | learning rate: 2.467E-05 | global batch size:    32 | lm loss: 5.955848E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83100/  200000 | consumed samples:      2659200 | elapsed time per iteration (ms): 324.8 | learning rate: 2.458E-05 | global batch size:    32 | lm loss: 5.765415E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    83200/  200000 | consumed samples:      2662400 | elapsed time per iteration (ms): 334.9 | learning rate: 2.449E-05 | global batch size:    32 | lm loss: 5.890991E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   3 | number of nan iterations:   0 |
 iteration    83300/  200000 | consumed samples:      2665600 | elapsed time per iteration (ms): 367.8 | learning rate: 2.440E-05 | global batch size:    32 | lm loss: 5.637009E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83400/  200000 | consumed samples:      2668800 | elapsed time per iteration (ms): 359.1 | learning rate: 2.431E-05 | global batch size:    32 | lm loss: 5.826263E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83500/  200000 | consumed samples:      2672000 | elapsed time per iteration (ms): 368.8 | learning rate: 2.422E-05 | global batch size:    32 | lm loss: 5.943805E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83600/  200000 | consumed samples:      2675200 | elapsed time per iteration (ms): 360.1 | learning rate: 2.413E-05 | global batch size:    32 | lm loss: 5.721634E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83700/  200000 | consumed samples:      2678400 | elapsed time per iteration (ms): 355.5 | learning rate: 2.403E-05 | global batch size:    32 | lm loss: 5.684471E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83800/  200000 | consumed samples:      2681600 | elapsed time per iteration (ms): 560.1 | learning rate: 2.394E-05 | global batch size:    32 | lm loss: 5.883942E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    83900/  200000 | consumed samples:      2684800 | elapsed time per iteration (ms): 405.3 | learning rate: 2.385E-05 | global batch size:    32 | lm loss: 5.743857E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84000/  200000 | consumed samples:      2688000 | elapsed time per iteration (ms): 371.3 | learning rate: 2.376E-05 | global batch size:    32 | lm loss: 5.682379E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84100/  200000 | consumed samples:      2691200 | elapsed time per iteration (ms): 359.9 | learning rate: 2.367E-05 | global batch size:    32 | lm loss: 5.850323E-06 | loss scale: 134217728.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84200/  200000 | consumed samples:      2694400 | elapsed time per iteration (ms): 339.3 | learning rate: 2.358E-05 | global batch size:    32 | lm loss: 5.673984E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84300/  200000 | consumed samples:      2697600 | elapsed time per iteration (ms): 345.7 | learning rate: 2.349E-05 | global batch size:    32 | lm loss: 5.682427E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84400/  200000 | consumed samples:      2700800 | elapsed time per iteration (ms): 336.7 | learning rate: 2.340E-05 | global batch size:    32 | lm loss: 5.581583E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84500/  200000 | consumed samples:      2704000 | elapsed time per iteration (ms): 326.1 | learning rate: 2.331E-05 | global batch size:    32 | lm loss: 5.576756E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84600/  200000 | consumed samples:      2707200 | elapsed time per iteration (ms): 371.4 | learning rate: 2.321E-05 | global batch size:    32 | lm loss: 5.609212E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84700/  200000 | consumed samples:      2710400 | elapsed time per iteration (ms): 297.0 | learning rate: 2.312E-05 | global batch size:    32 | lm loss: 5.338354E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84800/  200000 | consumed samples:      2713600 | elapsed time per iteration (ms): 297.4 | learning rate: 2.303E-05 | global batch size:    32 | lm loss: 5.684943E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    84900/  200000 | consumed samples:      2716800 | elapsed time per iteration (ms): 294.4 | learning rate: 2.294E-05 | global batch size:    32 | lm loss: 5.472529E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85000/  200000 | consumed samples:      2720000 | elapsed time per iteration (ms): 292.0 | learning rate: 2.285E-05 | global batch size:    32 | lm loss: 5.476100E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85100/  200000 | consumed samples:      2723200 | elapsed time per iteration (ms): 300.3 | learning rate: 2.276E-05 | global batch size:    32 | lm loss: 5.692448E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85200/  200000 | consumed samples:      2726400 | elapsed time per iteration (ms): 344.8 | learning rate: 2.267E-05 | global batch size:    32 | lm loss: 5.526313E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85300/  200000 | consumed samples:      2729600 | elapsed time per iteration (ms): 306.0 | learning rate: 2.258E-05 | global batch size:    32 | lm loss: 5.627429E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85400/  200000 | consumed samples:      2732800 | elapsed time per iteration (ms): 342.9 | learning rate: 2.249E-05 | global batch size:    32 | lm loss: 5.447796E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    85500/  200000 | consumed samples:      2736000 | elapsed time per iteration (ms): 434.4 | learning rate: 2.240E-05 | global batch size:    32 | lm loss: 5.474411E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85600/  200000 | consumed samples:      2739200 | elapsed time per iteration (ms): 461.9 | learning rate: 2.230E-05 | global batch size:    32 | lm loss: 5.536518E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85700/  200000 | consumed samples:      2742400 | elapsed time per iteration (ms): 375.9 | learning rate: 2.221E-05 | global batch size:    32 | lm loss: 5.710560E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85800/  200000 | consumed samples:      2745600 | elapsed time per iteration (ms): 350.8 | learning rate: 2.212E-05 | global batch size:    32 | lm loss: 5.553489E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    85900/  200000 | consumed samples:      2748800 | elapsed time per iteration (ms): 376.0 | learning rate: 2.203E-05 | global batch size:    32 | lm loss: 5.526343E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86000/  200000 | consumed samples:      2752000 | elapsed time per iteration (ms): 335.1 | learning rate: 2.194E-05 | global batch size:    32 | lm loss: 5.560543E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86100/  200000 | consumed samples:      2755200 | elapsed time per iteration (ms): 372.6 | learning rate: 2.185E-05 | global batch size:    32 | lm loss: 5.704429E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86200/  200000 | consumed samples:      2758400 | elapsed time per iteration (ms): 345.4 | learning rate: 2.176E-05 | global batch size:    32 | lm loss: 5.622860E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86300/  200000 | consumed samples:      2761600 | elapsed time per iteration (ms): 404.0 | learning rate: 2.167E-05 | global batch size:    32 | lm loss: 5.626656E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86400/  200000 | consumed samples:      2764800 | elapsed time per iteration (ms): 342.5 | learning rate: 2.158E-05 | global batch size:    32 | lm loss: 5.624032E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86500/  200000 | consumed samples:      2768000 | elapsed time per iteration (ms): 362.2 | learning rate: 2.148E-05 | global batch size:    32 | lm loss: 5.642646E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86600/  200000 | consumed samples:      2771200 | elapsed time per iteration (ms): 432.1 | learning rate: 2.139E-05 | global batch size:    32 | lm loss: 5.794349E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86700/  200000 | consumed samples:      2774400 | elapsed time per iteration (ms): 350.1 | learning rate: 2.130E-05 | global batch size:    32 | lm loss: 5.703983E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    86800/  200000 | consumed samples:      2777600 | elapsed time per iteration (ms): 364.3 | learning rate: 2.121E-05 | global batch size:    32 | lm loss: 5.503279E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    86900/  200000 | consumed samples:      2780800 | elapsed time per iteration (ms): 353.6 | learning rate: 2.112E-05 | global batch size:    32 | lm loss: 5.581984E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    87000/  200000 | consumed samples:      2784000 | elapsed time per iteration (ms): 372.4 | learning rate: 2.103E-05 | global batch size:    32 | lm loss: 5.693847E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87100/  200000 | consumed samples:      2787200 | elapsed time per iteration (ms): 352.1 | learning rate: 2.094E-05 | global batch size:    32 | lm loss: 5.553430E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87200/  200000 | consumed samples:      2790400 | elapsed time per iteration (ms): 379.1 | learning rate: 2.085E-05 | global batch size:    32 | lm loss: 5.576692E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87300/  200000 | consumed samples:      2793600 | elapsed time per iteration (ms): 391.5 | learning rate: 2.076E-05 | global batch size:    32 | lm loss: 5.468646E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87400/  200000 | consumed samples:      2796800 | elapsed time per iteration (ms): 400.4 | learning rate: 2.067E-05 | global batch size:    32 | lm loss: 5.521957E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87500/  200000 | consumed samples:      2800000 | elapsed time per iteration (ms): 364.7 | learning rate: 2.058E-05 | global batch size:    32 | lm loss: 5.524387E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87600/  200000 | consumed samples:      2803200 | elapsed time per iteration (ms): 382.1 | learning rate: 2.048E-05 | global batch size:    32 | lm loss: 5.464503E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87700/  200000 | consumed samples:      2806400 | elapsed time per iteration (ms): 352.8 | learning rate: 2.039E-05 | global batch size:    32 | lm loss: 5.660867E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87800/  200000 | consumed samples:      2809600 | elapsed time per iteration (ms): 368.4 | learning rate: 2.030E-05 | global batch size:    32 | lm loss: 5.761653E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    87900/  200000 | consumed samples:      2812800 | elapsed time per iteration (ms): 354.2 | learning rate: 2.021E-05 | global batch size:    32 | lm loss: 5.634846E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88000/  200000 | consumed samples:      2816000 | elapsed time per iteration (ms): 362.6 | learning rate: 2.012E-05 | global batch size:    32 | lm loss: 5.259156E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88100/  200000 | consumed samples:      2819200 | elapsed time per iteration (ms): 393.2 | learning rate: 2.003E-05 | global batch size:    32 | lm loss: 5.595547E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88200/  200000 | consumed samples:      2822400 | elapsed time per iteration (ms): 372.2 | learning rate: 1.994E-05 | global batch size:    32 | lm loss: 5.587148E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    88300/  200000 | consumed samples:      2825600 | elapsed time per iteration (ms): 370.2 | learning rate: 1.985E-05 | global batch size:    32 | lm loss: 5.486449E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88400/  200000 | consumed samples:      2828800 | elapsed time per iteration (ms): 349.5 | learning rate: 1.976E-05 | global batch size:    32 | lm loss: 5.550183E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88500/  200000 | consumed samples:      2832000 | elapsed time per iteration (ms): 371.5 | learning rate: 1.967E-05 | global batch size:    32 | lm loss: 5.753555E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88600/  200000 | consumed samples:      2835200 | elapsed time per iteration (ms): 406.9 | learning rate: 1.957E-05 | global batch size:    32 | lm loss: 5.709892E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88700/  200000 | consumed samples:      2838400 | elapsed time per iteration (ms): 356.6 | learning rate: 1.948E-05 | global batch size:    32 | lm loss: 5.571815E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88800/  200000 | consumed samples:      2841600 | elapsed time per iteration (ms): 372.6 | learning rate: 1.939E-05 | global batch size:    32 | lm loss: 5.557709E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    88900/  200000 | consumed samples:      2844800 | elapsed time per iteration (ms): 356.2 | learning rate: 1.930E-05 | global batch size:    32 | lm loss: 5.743427E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89000/  200000 | consumed samples:      2848000 | elapsed time per iteration (ms): 344.2 | learning rate: 1.921E-05 | global batch size:    32 | lm loss: 5.547943E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89100/  200000 | consumed samples:      2851200 | elapsed time per iteration (ms): 384.6 | learning rate: 1.912E-05 | global batch size:    32 | lm loss: 5.650417E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89200/  200000 | consumed samples:      2854400 | elapsed time per iteration (ms): 362.2 | learning rate: 1.903E-05 | global batch size:    32 | lm loss: 5.601437E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89300/  200000 | consumed samples:      2857600 | elapsed time per iteration (ms): 350.6 | learning rate: 1.894E-05 | global batch size:    32 | lm loss: 5.508739E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    89400/  200000 | consumed samples:      2860800 | elapsed time per iteration (ms): 347.1 | learning rate: 1.885E-05 | global batch size:    32 | lm loss: 5.615251E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89500/  200000 | consumed samples:      2864000 | elapsed time per iteration (ms): 373.3 | learning rate: 1.876E-05 | global batch size:    32 | lm loss: 5.635961E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89600/  200000 | consumed samples:      2867200 | elapsed time per iteration (ms): 370.4 | learning rate: 1.867E-05 | global batch size:    32 | lm loss: 5.659084E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89700/  200000 | consumed samples:      2870400 | elapsed time per iteration (ms): 345.0 | learning rate: 1.857E-05 | global batch size:    32 | lm loss: 5.628415E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89800/  200000 | consumed samples:      2873600 | elapsed time per iteration (ms): 332.3 | learning rate: 1.848E-05 | global batch size:    32 | lm loss: 5.709671E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    89900/  200000 | consumed samples:      2876800 | elapsed time per iteration (ms): 341.8 | learning rate: 1.839E-05 | global batch size:    32 | lm loss: 5.608868E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90000/  200000 | consumed samples:      2880000 | elapsed time per iteration (ms): 336.3 | learning rate: 1.830E-05 | global batch size:    32 | lm loss: 5.462014E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90100/  200000 | consumed samples:      2883200 | elapsed time per iteration (ms): 361.0 | learning rate: 1.821E-05 | global batch size:    32 | lm loss: 5.638821E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90200/  200000 | consumed samples:      2886400 | elapsed time per iteration (ms): 399.0 | learning rate: 1.812E-05 | global batch size:    32 | lm loss: 5.674383E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90300/  200000 | consumed samples:      2889600 | elapsed time per iteration (ms): 397.6 | learning rate: 1.803E-05 | global batch size:    32 | lm loss: 5.529332E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    90400/  200000 | consumed samples:      2892800 | elapsed time per iteration (ms): 347.1 | learning rate: 1.794E-05 | global batch size:    32 | lm loss: 5.603301E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90500/  200000 | consumed samples:      2896000 | elapsed time per iteration (ms): 419.5 | learning rate: 1.785E-05 | global batch size:    32 | lm loss: 5.571344E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90600/  200000 | consumed samples:      2899200 | elapsed time per iteration (ms): 413.9 | learning rate: 1.776E-05 | global batch size:    32 | lm loss: 5.747534E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90700/  200000 | consumed samples:      2902400 | elapsed time per iteration (ms): 355.7 | learning rate: 1.766E-05 | global batch size:    32 | lm loss: 5.594766E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90800/  200000 | consumed samples:      2905600 | elapsed time per iteration (ms): 356.5 | learning rate: 1.757E-05 | global batch size:    32 | lm loss: 5.333499E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    90900/  200000 | consumed samples:      2908800 | elapsed time per iteration (ms): 345.9 | learning rate: 1.748E-05 | global batch size:    32 | lm loss: 5.580408E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91000/  200000 | consumed samples:      2912000 | elapsed time per iteration (ms): 366.0 | learning rate: 1.739E-05 | global batch size:    32 | lm loss: 5.517085E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91100/  200000 | consumed samples:      2915200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.730E-05 | global batch size:    32 | lm loss: 5.415720E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91200/  200000 | consumed samples:      2918400 | elapsed time per iteration (ms): 330.9 | learning rate: 1.721E-05 | global batch size:    32 | lm loss: 5.734126E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    91300/  200000 | consumed samples:      2921600 | elapsed time per iteration (ms): 299.4 | learning rate: 1.712E-05 | global batch size:    32 | lm loss: 5.640757E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91400/  200000 | consumed samples:      2924800 | elapsed time per iteration (ms): 375.3 | learning rate: 1.703E-05 | global batch size:    32 | lm loss: 5.572618E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91500/  200000 | consumed samples:      2928000 | elapsed time per iteration (ms): 352.9 | learning rate: 1.694E-05 | global batch size:    32 | lm loss: 5.562433E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91600/  200000 | consumed samples:      2931200 | elapsed time per iteration (ms): 345.6 | learning rate: 1.685E-05 | global batch size:    32 | lm loss: 5.437243E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91700/  200000 | consumed samples:      2934400 | elapsed time per iteration (ms): 394.6 | learning rate: 1.675E-05 | global batch size:    32 | lm loss: 5.336835E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91800/  200000 | consumed samples:      2937600 | elapsed time per iteration (ms): 378.2 | learning rate: 1.666E-05 | global batch size:    32 | lm loss: 5.298282E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    91900/  200000 | consumed samples:      2940800 | elapsed time per iteration (ms): 351.5 | learning rate: 1.657E-05 | global batch size:    32 | lm loss: 5.621005E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92000/  200000 | consumed samples:      2944000 | elapsed time per iteration (ms): 318.3 | learning rate: 1.648E-05 | global batch size:    32 | lm loss: 5.630523E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92100/  200000 | consumed samples:      2947200 | elapsed time per iteration (ms): 351.8 | learning rate: 1.639E-05 | global batch size:    32 | lm loss: 5.508955E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92200/  200000 | consumed samples:      2950400 | elapsed time per iteration (ms): 376.5 | learning rate: 1.630E-05 | global batch size:    32 | lm loss: 5.741570E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92300/  200000 | consumed samples:      2953600 | elapsed time per iteration (ms): 314.7 | learning rate: 1.621E-05 | global batch size:    32 | lm loss: 5.587582E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92400/  200000 | consumed samples:      2956800 | elapsed time per iteration (ms): 506.0 | learning rate: 1.612E-05 | global batch size:    32 | lm loss: 5.693880E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92500/  200000 | consumed samples:      2960000 | elapsed time per iteration (ms): 415.5 | learning rate: 1.603E-05 | global batch size:    32 | lm loss: 5.768681E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92600/  200000 | consumed samples:      2963200 | elapsed time per iteration (ms): 352.9 | learning rate: 1.593E-05 | global batch size:    32 | lm loss: 5.420728E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92700/  200000 | consumed samples:      2966400 | elapsed time per iteration (ms): 285.9 | learning rate: 1.584E-05 | global batch size:    32 | lm loss: 5.398660E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92800/  200000 | consumed samples:      2969600 | elapsed time per iteration (ms): 314.4 | learning rate: 1.575E-05 | global batch size:    32 | lm loss: 5.469952E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    92900/  200000 | consumed samples:      2972800 | elapsed time per iteration (ms): 339.6 | learning rate: 1.566E-05 | global batch size:    32 | lm loss: 5.562814E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93000/  200000 | consumed samples:      2976000 | elapsed time per iteration (ms): 431.5 | learning rate: 1.557E-05 | global batch size:    32 | lm loss: 5.568992E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93100/  200000 | consumed samples:      2979200 | elapsed time per iteration (ms): 362.8 | learning rate: 1.548E-05 | global batch size:    32 | lm loss: 5.474281E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93200/  200000 | consumed samples:      2982400 | elapsed time per iteration (ms): 359.9 | learning rate: 1.539E-05 | global batch size:    32 | lm loss: 5.482404E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93300/  200000 | consumed samples:      2985600 | elapsed time per iteration (ms): 330.7 | learning rate: 1.530E-05 | global batch size:    32 | lm loss: 5.514196E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93400/  200000 | consumed samples:      2988800 | elapsed time per iteration (ms): 379.3 | learning rate: 1.521E-05 | global batch size:    32 | lm loss: 5.624461E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    93500/  200000 | consumed samples:      2992000 | elapsed time per iteration (ms): 349.3 | learning rate: 1.512E-05 | global batch size:    32 | lm loss: 5.582945E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    93600/  200000 | consumed samples:      2995200 | elapsed time per iteration (ms): 511.1 | learning rate: 1.503E-05 | global batch size:    32 | lm loss: 5.761396E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93700/  200000 | consumed samples:      2998400 | elapsed time per iteration (ms): 339.6 | learning rate: 1.493E-05 | global batch size:    32 | lm loss: 5.469150E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93800/  200000 | consumed samples:      3001600 | elapsed time per iteration (ms): 369.2 | learning rate: 1.484E-05 | global batch size:    32 | lm loss: 5.252303E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    93900/  200000 | consumed samples:      3004800 | elapsed time per iteration (ms): 389.6 | learning rate: 1.475E-05 | global batch size:    32 | lm loss: 5.583526E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94000/  200000 | consumed samples:      3008000 | elapsed time per iteration (ms): 367.2 | learning rate: 1.466E-05 | global batch size:    32 | lm loss: 5.450933E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94100/  200000 | consumed samples:      3011200 | elapsed time per iteration (ms): 346.4 | learning rate: 1.457E-05 | global batch size:    32 | lm loss: 5.543237E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94200/  200000 | consumed samples:      3014400 | elapsed time per iteration (ms): 386.9 | learning rate: 1.448E-05 | global batch size:    32 | lm loss: 5.130256E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94300/  200000 | consumed samples:      3017600 | elapsed time per iteration (ms): 331.5 | learning rate: 1.439E-05 | global batch size:    32 | lm loss: 5.368391E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94400/  200000 | consumed samples:      3020800 | elapsed time per iteration (ms): 417.5 | learning rate: 1.430E-05 | global batch size:    32 | lm loss: 5.540092E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94500/  200000 | consumed samples:      3024000 | elapsed time per iteration (ms): 340.7 | learning rate: 1.421E-05 | global batch size:    32 | lm loss: 5.427829E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration    94600/  200000 | consumed samples:      3027200 | elapsed time per iteration (ms): 441.3 | learning rate: 1.412E-05 | global batch size:    32 | lm loss: 5.537822E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94700/  200000 | consumed samples:      3030400 | elapsed time per iteration (ms): 348.7 | learning rate: 1.403E-05 | global batch size:    32 | lm loss: 5.396837E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94800/  200000 | consumed samples:      3033600 | elapsed time per iteration (ms): 373.8 | learning rate: 1.393E-05 | global batch size:    32 | lm loss: 5.615894E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    94900/  200000 | consumed samples:      3036800 | elapsed time per iteration (ms): 347.7 | learning rate: 1.384E-05 | global batch size:    32 | lm loss: 5.555758E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95000/  200000 | consumed samples:      3040000 | elapsed time per iteration (ms): 364.7 | learning rate: 1.375E-05 | global batch size:    32 | lm loss: 5.462458E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95100/  200000 | consumed samples:      3043200 | elapsed time per iteration (ms): 351.9 | learning rate: 1.366E-05 | global batch size:    32 | lm loss: 5.787685E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95200/  200000 | consumed samples:      3046400 | elapsed time per iteration (ms): 370.9 | learning rate: 1.357E-05 | global batch size:    32 | lm loss: 5.582589E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95300/  200000 | consumed samples:      3049600 | elapsed time per iteration (ms): 377.2 | learning rate: 1.348E-05 | global batch size:    32 | lm loss: 5.682007E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95400/  200000 | consumed samples:      3052800 | elapsed time per iteration (ms): 391.7 | learning rate: 1.339E-05 | global batch size:    32 | lm loss: 5.634028E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95500/  200000 | consumed samples:      3056000 | elapsed time per iteration (ms): 368.5 | learning rate: 1.330E-05 | global batch size:    32 | lm loss: 5.557070E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95600/  200000 | consumed samples:      3059200 | elapsed time per iteration (ms): 362.5 | learning rate: 1.321E-05 | global batch size:    32 | lm loss: 5.638599E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95700/  200000 | consumed samples:      3062400 | elapsed time per iteration (ms): 354.4 | learning rate: 1.312E-05 | global batch size:    32 | lm loss: 5.682828E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    95800/  200000 | consumed samples:      3065600 | elapsed time per iteration (ms): 373.5 | learning rate: 1.302E-05 | global batch size:    32 | lm loss: 5.607910E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    95900/  200000 | consumed samples:      3068800 | elapsed time per iteration (ms): 358.5 | learning rate: 1.293E-05 | global batch size:    32 | lm loss: 5.569272E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96000/  200000 | consumed samples:      3072000 | elapsed time per iteration (ms): 390.0 | learning rate: 1.284E-05 | global batch size:    32 | lm loss: 5.704581E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    96100/  200000 | consumed samples:      3075200 | elapsed time per iteration (ms): 356.2 | learning rate: 1.275E-05 | global batch size:    32 | lm loss: 5.741193E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96200/  200000 | consumed samples:      3078400 | elapsed time per iteration (ms): 356.3 | learning rate: 1.266E-05 | global batch size:    32 | lm loss: 5.575368E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96300/  200000 | consumed samples:      3081600 | elapsed time per iteration (ms): 343.8 | learning rate: 1.257E-05 | global batch size:    32 | lm loss: 5.476268E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96400/  200000 | consumed samples:      3084800 | elapsed time per iteration (ms): 362.0 | learning rate: 1.248E-05 | global batch size:    32 | lm loss: 5.790221E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96500/  200000 | consumed samples:      3088000 | elapsed time per iteration (ms): 397.4 | learning rate: 1.239E-05 | global batch size:    32 | lm loss: 5.594954E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96600/  200000 | consumed samples:      3091200 | elapsed time per iteration (ms): 419.4 | learning rate: 1.230E-05 | global batch size:    32 | lm loss: 5.406944E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96700/  200000 | consumed samples:      3094400 | elapsed time per iteration (ms): 398.7 | learning rate: 1.221E-05 | global batch size:    32 | lm loss: 5.523478E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96800/  200000 | consumed samples:      3097600 | elapsed time per iteration (ms): 352.5 | learning rate: 1.211E-05 | global batch size:    32 | lm loss: 5.648761E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    96900/  200000 | consumed samples:      3100800 | elapsed time per iteration (ms): 377.2 | learning rate: 1.202E-05 | global batch size:    32 | lm loss: 5.521262E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97000/  200000 | consumed samples:      3104000 | elapsed time per iteration (ms): 354.7 | learning rate: 1.193E-05 | global batch size:    32 | lm loss: 5.402858E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97100/  200000 | consumed samples:      3107200 | elapsed time per iteration (ms): 391.6 | learning rate: 1.184E-05 | global batch size:    32 | lm loss: 5.475268E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97200/  200000 | consumed samples:      3110400 | elapsed time per iteration (ms): 352.9 | learning rate: 1.175E-05 | global batch size:    32 | lm loss: 5.430980E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97300/  200000 | consumed samples:      3113600 | elapsed time per iteration (ms): 370.7 | learning rate: 1.166E-05 | global batch size:    32 | lm loss: 5.384471E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97400/  200000 | consumed samples:      3116800 | elapsed time per iteration (ms): 361.3 | learning rate: 1.157E-05 | global batch size:    32 | lm loss: 5.608198E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97500/  200000 | consumed samples:      3120000 | elapsed time per iteration (ms): 410.0 | learning rate: 1.148E-05 | global batch size:    32 | lm loss: 5.562007E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97600/  200000 | consumed samples:      3123200 | elapsed time per iteration (ms): 350.3 | learning rate: 1.139E-05 | global batch size:    32 | lm loss: 5.460717E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97700/  200000 | consumed samples:      3126400 | elapsed time per iteration (ms): 350.9 | learning rate: 1.129E-05 | global batch size:    32 | lm loss: 5.525943E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97800/  200000 | consumed samples:      3129600 | elapsed time per iteration (ms): 315.3 | learning rate: 1.120E-05 | global batch size:    32 | lm loss: 5.541441E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    97900/  200000 | consumed samples:      3132800 | elapsed time per iteration (ms): 370.7 | learning rate: 1.111E-05 | global batch size:    32 | lm loss: 5.683508E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98000/  200000 | consumed samples:      3136000 | elapsed time per iteration (ms): 341.2 | learning rate: 1.102E-05 | global batch size:    32 | lm loss: 5.644763E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    98100/  200000 | consumed samples:      3139200 | elapsed time per iteration (ms): 416.4 | learning rate: 1.093E-05 | global batch size:    32 | lm loss: 5.543786E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    98200/  200000 | consumed samples:      3142400 | elapsed time per iteration (ms): 596.2 | learning rate: 1.084E-05 | global batch size:    32 | lm loss: 5.535170E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    98300/  200000 | consumed samples:      3145600 | elapsed time per iteration (ms): 326.9 | learning rate: 1.075E-05 | global batch size:    32 | lm loss: 5.819087E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98400/  200000 | consumed samples:      3148800 | elapsed time per iteration (ms): 341.1 | learning rate: 1.066E-05 | global batch size:    32 | lm loss: 5.630643E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98500/  200000 | consumed samples:      3152000 | elapsed time per iteration (ms): 406.8 | learning rate: 1.057E-05 | global batch size:    32 | lm loss: 5.833156E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98600/  200000 | consumed samples:      3155200 | elapsed time per iteration (ms): 368.2 | learning rate: 1.048E-05 | global batch size:    32 | lm loss: 5.536050E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98700/  200000 | consumed samples:      3158400 | elapsed time per iteration (ms): 357.2 | learning rate: 1.039E-05 | global batch size:    32 | lm loss: 5.739919E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98800/  200000 | consumed samples:      3161600 | elapsed time per iteration (ms): 341.3 | learning rate: 1.030E-05 | global batch size:    32 | lm loss: 5.666678E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    98900/  200000 | consumed samples:      3164800 | elapsed time per iteration (ms): 413.4 | learning rate: 1.020E-05 | global batch size:    32 | lm loss: 5.626824E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99000/  200000 | consumed samples:      3168000 | elapsed time per iteration (ms): 293.4 | learning rate: 1.011E-05 | global batch size:    32 | lm loss: 5.520670E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99100/  200000 | consumed samples:      3171200 | elapsed time per iteration (ms): 346.5 | learning rate: 1.002E-05 | global batch size:    32 | lm loss: 5.426583E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99200/  200000 | consumed samples:      3174400 | elapsed time per iteration (ms): 341.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.536183E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99300/  200000 | consumed samples:      3177600 | elapsed time per iteration (ms): 314.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.683189E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99400/  200000 | consumed samples:      3180800 | elapsed time per iteration (ms): 314.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.861739E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99500/  200000 | consumed samples:      3184000 | elapsed time per iteration (ms): 314.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.508712E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99600/  200000 | consumed samples:      3187200 | elapsed time per iteration (ms): 356.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.579172E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99700/  200000 | consumed samples:      3190400 | elapsed time per iteration (ms): 344.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.639482E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    99800/  200000 | consumed samples:      3193600 | elapsed time per iteration (ms): 444.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.357933E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration    99900/  200000 | consumed samples:      3196800 | elapsed time per iteration (ms): 343.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.727264E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100000/  200000 | consumed samples:      3200000 | elapsed time per iteration (ms): 354.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.483417E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100100/  200000 | consumed samples:      3203200 | elapsed time per iteration (ms): 776.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.519656E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100200/  200000 | consumed samples:      3206400 | elapsed time per iteration (ms): 313.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.426034E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100300/  200000 | consumed samples:      3209600 | elapsed time per iteration (ms): 304.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.763838E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   100400/  200000 | consumed samples:      3212800 | elapsed time per iteration (ms): 336.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.701827E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100500/  200000 | consumed samples:      3216000 | elapsed time per iteration (ms): 363.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.424693E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100600/  200000 | consumed samples:      3219200 | elapsed time per iteration (ms): 359.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.564067E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100700/  200000 | consumed samples:      3222400 | elapsed time per iteration (ms): 313.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.359144E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100800/  200000 | consumed samples:      3225600 | elapsed time per iteration (ms): 338.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.670887E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   100900/  200000 | consumed samples:      3228800 | elapsed time per iteration (ms): 345.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.421593E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101000/  200000 | consumed samples:      3232000 | elapsed time per iteration (ms): 335.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.572645E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101100/  200000 | consumed samples:      3235200 | elapsed time per iteration (ms): 383.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.790471E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101200/  200000 | consumed samples:      3238400 | elapsed time per iteration (ms): 305.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.453363E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101300/  200000 | consumed samples:      3241600 | elapsed time per iteration (ms): 295.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.936179E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101400/  200000 | consumed samples:      3244800 | elapsed time per iteration (ms): 316.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.532629E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101500/  200000 | consumed samples:      3248000 | elapsed time per iteration (ms): 378.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.375577E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101600/  200000 | consumed samples:      3251200 | elapsed time per iteration (ms): 408.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.750611E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101700/  200000 | consumed samples:      3254400 | elapsed time per iteration (ms): 474.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.741739E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101800/  200000 | consumed samples:      3257600 | elapsed time per iteration (ms): 394.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.560955E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   101900/  200000 | consumed samples:      3260800 | elapsed time per iteration (ms): 351.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.758510E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102000/  200000 | consumed samples:      3264000 | elapsed time per iteration (ms): 372.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.608170E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102100/  200000 | consumed samples:      3267200 | elapsed time per iteration (ms): 340.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.570719E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102200/  200000 | consumed samples:      3270400 | elapsed time per iteration (ms): 366.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.677252E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102300/  200000 | consumed samples:      3273600 | elapsed time per iteration (ms): 353.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.485951E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102400/  200000 | consumed samples:      3276800 | elapsed time per iteration (ms): 371.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.452550E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102500/  200000 | consumed samples:      3280000 | elapsed time per iteration (ms): 354.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.738370E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102600/  200000 | consumed samples:      3283200 | elapsed time per iteration (ms): 443.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.529125E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102700/  200000 | consumed samples:      3286400 | elapsed time per iteration (ms): 360.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.605040E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   102800/  200000 | consumed samples:      3289600 | elapsed time per iteration (ms): 355.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.648369E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   102900/  200000 | consumed samples:      3292800 | elapsed time per iteration (ms): 391.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.638675E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103000/  200000 | consumed samples:      3296000 | elapsed time per iteration (ms): 383.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.531900E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103100/  200000 | consumed samples:      3299200 | elapsed time per iteration (ms): 378.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.665846E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103200/  200000 | consumed samples:      3302400 | elapsed time per iteration (ms): 398.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.572311E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103300/  200000 | consumed samples:      3305600 | elapsed time per iteration (ms): 355.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.419800E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   103400/  200000 | consumed samples:      3308800 | elapsed time per iteration (ms): 377.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.407096E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103500/  200000 | consumed samples:      3312000 | elapsed time per iteration (ms): 350.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.607274E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103600/  200000 | consumed samples:      3315200 | elapsed time per iteration (ms): 432.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.393098E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103700/  200000 | consumed samples:      3318400 | elapsed time per iteration (ms): 344.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.714534E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103800/  200000 | consumed samples:      3321600 | elapsed time per iteration (ms): 369.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.382201E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   103900/  200000 | consumed samples:      3324800 | elapsed time per iteration (ms): 357.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.676771E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104000/  200000 | consumed samples:      3328000 | elapsed time per iteration (ms): 365.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.401587E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104100/  200000 | consumed samples:      3331200 | elapsed time per iteration (ms): 346.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.633511E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104200/  200000 | consumed samples:      3334400 | elapsed time per iteration (ms): 375.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.763191E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104300/  200000 | consumed samples:      3337600 | elapsed time per iteration (ms): 362.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.503664E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104400/  200000 | consumed samples:      3340800 | elapsed time per iteration (ms): 363.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.658085E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104500/  200000 | consumed samples:      3344000 | elapsed time per iteration (ms): 376.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.636899E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   104600/  200000 | consumed samples:      3347200 | elapsed time per iteration (ms): 415.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.534718E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104700/  200000 | consumed samples:      3350400 | elapsed time per iteration (ms): 369.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.438355E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   104800/  200000 | consumed samples:      3353600 | elapsed time per iteration (ms): 357.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.438145E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   104900/  200000 | consumed samples:      3356800 | elapsed time per iteration (ms): 349.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.420413E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105000/  200000 | consumed samples:      3360000 | elapsed time per iteration (ms): 398.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.479269E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105100/  200000 | consumed samples:      3363200 | elapsed time per iteration (ms): 354.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.396244E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105200/  200000 | consumed samples:      3366400 | elapsed time per iteration (ms): 360.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.660907E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   105300/  200000 | consumed samples:      3369600 | elapsed time per iteration (ms): 369.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.518273E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105400/  200000 | consumed samples:      3372800 | elapsed time per iteration (ms): 374.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.578675E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   105500/  200000 | consumed samples:      3376000 | elapsed time per iteration (ms): 364.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.440654E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105600/  200000 | consumed samples:      3379200 | elapsed time per iteration (ms): 369.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.462408E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105700/  200000 | consumed samples:      3382400 | elapsed time per iteration (ms): 336.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.451147E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105800/  200000 | consumed samples:      3385600 | elapsed time per iteration (ms): 357.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.625992E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   105900/  200000 | consumed samples:      3388800 | elapsed time per iteration (ms): 339.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.362526E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106000/  200000 | consumed samples:      3392000 | elapsed time per iteration (ms): 375.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.430449E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106100/  200000 | consumed samples:      3395200 | elapsed time per iteration (ms): 407.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.352733E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106200/  200000 | consumed samples:      3398400 | elapsed time per iteration (ms): 372.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.298259E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106300/  200000 | consumed samples:      3401600 | elapsed time per iteration (ms): 335.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.547926E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106400/  200000 | consumed samples:      3404800 | elapsed time per iteration (ms): 341.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.407887E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106500/  200000 | consumed samples:      3408000 | elapsed time per iteration (ms): 394.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.382354E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106600/  200000 | consumed samples:      3411200 | elapsed time per iteration (ms): 366.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.364090E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106700/  200000 | consumed samples:      3414400 | elapsed time per iteration (ms): 355.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.310552E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106800/  200000 | consumed samples:      3417600 | elapsed time per iteration (ms): 382.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.443479E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   106900/  200000 | consumed samples:      3420800 | elapsed time per iteration (ms): 354.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.599220E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107000/  200000 | consumed samples:      3424000 | elapsed time per iteration (ms): 350.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.555179E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107100/  200000 | consumed samples:      3427200 | elapsed time per iteration (ms): 391.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.538940E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107200/  200000 | consumed samples:      3430400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.543450E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107300/  200000 | consumed samples:      3433600 | elapsed time per iteration (ms): 369.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.562657E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107400/  200000 | consumed samples:      3436800 | elapsed time per iteration (ms): 333.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.440968E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107500/  200000 | consumed samples:      3440000 | elapsed time per iteration (ms): 390.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.479373E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107600/  200000 | consumed samples:      3443200 | elapsed time per iteration (ms): 355.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.220823E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107700/  200000 | consumed samples:      3446400 | elapsed time per iteration (ms): 327.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.509252E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107800/  200000 | consumed samples:      3449600 | elapsed time per iteration (ms): 502.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.438756E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   107900/  200000 | consumed samples:      3452800 | elapsed time per iteration (ms): 314.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.513492E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108000/  200000 | consumed samples:      3456000 | elapsed time per iteration (ms): 341.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.407248E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108100/  200000 | consumed samples:      3459200 | elapsed time per iteration (ms): 347.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.780436E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108200/  200000 | consumed samples:      3462400 | elapsed time per iteration (ms): 416.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.478408E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108300/  200000 | consumed samples:      3465600 | elapsed time per iteration (ms): 415.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.557106E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108400/  200000 | consumed samples:      3468800 | elapsed time per iteration (ms): 377.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.608008E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108500/  200000 | consumed samples:      3472000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.269881E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   108600/  200000 | consumed samples:      3475200 | elapsed time per iteration (ms): 360.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.276705E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   108700/  200000 | consumed samples:      3478400 | elapsed time per iteration (ms): 344.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.385102E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108800/  200000 | consumed samples:      3481600 | elapsed time per iteration (ms): 349.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.474192E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   108900/  200000 | consumed samples:      3484800 | elapsed time per iteration (ms): 358.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.491491E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109000/  200000 | consumed samples:      3488000 | elapsed time per iteration (ms): 410.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.559177E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109100/  200000 | consumed samples:      3491200 | elapsed time per iteration (ms): 353.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.439542E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   109200/  200000 | consumed samples:      3494400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.536535E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109300/  200000 | consumed samples:      3497600 | elapsed time per iteration (ms): 290.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.432052E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109400/  200000 | consumed samples:      3500800 | elapsed time per iteration (ms): 288.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.307605E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109500/  200000 | consumed samples:      3504000 | elapsed time per iteration (ms): 289.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.326176E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109600/  200000 | consumed samples:      3507200 | elapsed time per iteration (ms): 343.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.399148E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109700/  200000 | consumed samples:      3510400 | elapsed time per iteration (ms): 436.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.225878E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109800/  200000 | consumed samples:      3513600 | elapsed time per iteration (ms): 552.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.247056E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   109900/  200000 | consumed samples:      3516800 | elapsed time per iteration (ms): 360.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.427429E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110000/  200000 | consumed samples:      3520000 | elapsed time per iteration (ms): 368.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.442486E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110100/  200000 | consumed samples:      3523200 | elapsed time per iteration (ms): 342.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.251780E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110200/  200000 | consumed samples:      3526400 | elapsed time per iteration (ms): 357.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.432295E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   110300/  200000 | consumed samples:      3529600 | elapsed time per iteration (ms): 360.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.389033E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   110400/  200000 | consumed samples:      3532800 | elapsed time per iteration (ms): 377.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.435661E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110500/  200000 | consumed samples:      3536000 | elapsed time per iteration (ms): 378.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.642993E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110600/  200000 | consumed samples:      3539200 | elapsed time per iteration (ms): 387.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.386425E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110700/  200000 | consumed samples:      3542400 | elapsed time per iteration (ms): 380.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.179704E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110800/  200000 | consumed samples:      3545600 | elapsed time per iteration (ms): 388.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.283321E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   110900/  200000 | consumed samples:      3548800 | elapsed time per iteration (ms): 353.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.423592E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111000/  200000 | consumed samples:      3552000 | elapsed time per iteration (ms): 365.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.303274E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111100/  200000 | consumed samples:      3555200 | elapsed time per iteration (ms): 361.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.279687E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111200/  200000 | consumed samples:      3558400 | elapsed time per iteration (ms): 360.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.335244E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111300/  200000 | consumed samples:      3561600 | elapsed time per iteration (ms): 360.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489071E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111400/  200000 | consumed samples:      3564800 | elapsed time per iteration (ms): 366.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.553194E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111500/  200000 | consumed samples:      3568000 | elapsed time per iteration (ms): 362.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.624271E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111600/  200000 | consumed samples:      3571200 | elapsed time per iteration (ms): 387.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.502481E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111700/  200000 | consumed samples:      3574400 | elapsed time per iteration (ms): 336.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.480963E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111800/  200000 | consumed samples:      3577600 | elapsed time per iteration (ms): 420.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.610670E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   111900/  200000 | consumed samples:      3580800 | elapsed time per iteration (ms): 368.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.581271E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112000/  200000 | consumed samples:      3584000 | elapsed time per iteration (ms): 385.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.246128E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112100/  200000 | consumed samples:      3587200 | elapsed time per iteration (ms): 338.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.582678E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112200/  200000 | consumed samples:      3590400 | elapsed time per iteration (ms): 364.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.431000E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112300/  200000 | consumed samples:      3593600 | elapsed time per iteration (ms): 382.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.526255E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112400/  200000 | consumed samples:      3596800 | elapsed time per iteration (ms): 354.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.222495E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112500/  200000 | consumed samples:      3600000 | elapsed time per iteration (ms): 371.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.494849E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112600/  200000 | consumed samples:      3603200 | elapsed time per iteration (ms): 463.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.354429E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112700/  200000 | consumed samples:      3606400 | elapsed time per iteration (ms): 337.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.408768E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112800/  200000 | consumed samples:      3609600 | elapsed time per iteration (ms): 413.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.384641E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   112900/  200000 | consumed samples:      3612800 | elapsed time per iteration (ms): 363.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.315957E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113000/  200000 | consumed samples:      3616000 | elapsed time per iteration (ms): 368.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.300950E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113100/  200000 | consumed samples:      3619200 | elapsed time per iteration (ms): 343.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.474901E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113200/  200000 | consumed samples:      3622400 | elapsed time per iteration (ms): 365.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.559670E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113300/  200000 | consumed samples:      3625600 | elapsed time per iteration (ms): 362.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.503703E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113400/  200000 | consumed samples:      3628800 | elapsed time per iteration (ms): 383.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.457856E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113500/  200000 | consumed samples:      3632000 | elapsed time per iteration (ms): 354.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.310435E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   113600/  200000 | consumed samples:      3635200 | elapsed time per iteration (ms): 382.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.403442E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   113700/  200000 | consumed samples:      3638400 | elapsed time per iteration (ms): 362.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.661778E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113800/  200000 | consumed samples:      3641600 | elapsed time per iteration (ms): 388.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.720541E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   113900/  200000 | consumed samples:      3644800 | elapsed time per iteration (ms): 334.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.416765E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114000/  200000 | consumed samples:      3648000 | elapsed time per iteration (ms): 360.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.557765E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114100/  200000 | consumed samples:      3651200 | elapsed time per iteration (ms): 372.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.409148E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114200/  200000 | consumed samples:      3654400 | elapsed time per iteration (ms): 344.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.463829E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114300/  200000 | consumed samples:      3657600 | elapsed time per iteration (ms): 375.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.396747E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114400/  200000 | consumed samples:      3660800 | elapsed time per iteration (ms): 334.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.420963E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114500/  200000 | consumed samples:      3664000 | elapsed time per iteration (ms): 364.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.438430E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114600/  200000 | consumed samples:      3667200 | elapsed time per iteration (ms): 410.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.413085E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114700/  200000 | consumed samples:      3670400 | elapsed time per iteration (ms): 469.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.394333E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   114800/  200000 | consumed samples:      3673600 | elapsed time per iteration (ms): 361.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.567909E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   114900/  200000 | consumed samples:      3676800 | elapsed time per iteration (ms): 355.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.587691E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115000/  200000 | consumed samples:      3680000 | elapsed time per iteration (ms): 330.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.172447E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115100/  200000 | consumed samples:      3683200 | elapsed time per iteration (ms): 338.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.374200E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115200/  200000 | consumed samples:      3686400 | elapsed time per iteration (ms): 348.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320001E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115300/  200000 | consumed samples:      3689600 | elapsed time per iteration (ms): 422.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.671880E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115400/  200000 | consumed samples:      3692800 | elapsed time per iteration (ms): 374.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.434636E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115500/  200000 | consumed samples:      3696000 | elapsed time per iteration (ms): 338.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.225140E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115600/  200000 | consumed samples:      3699200 | elapsed time per iteration (ms): 334.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.464685E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115700/  200000 | consumed samples:      3702400 | elapsed time per iteration (ms): 355.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.290851E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115800/  200000 | consumed samples:      3705600 | elapsed time per iteration (ms): 345.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.214839E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   115900/  200000 | consumed samples:      3708800 | elapsed time per iteration (ms): 311.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.421464E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116000/  200000 | consumed samples:      3712000 | elapsed time per iteration (ms): 349.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.375963E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116100/  200000 | consumed samples:      3715200 | elapsed time per iteration (ms): 342.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.377639E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   116200/  200000 | consumed samples:      3718400 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.395921E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   116300/  200000 | consumed samples:      3721600 | elapsed time per iteration (ms): 307.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.227287E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116400/  200000 | consumed samples:      3724800 | elapsed time per iteration (ms): 327.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.289362E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116500/  200000 | consumed samples:      3728000 | elapsed time per iteration (ms): 338.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.326690E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116600/  200000 | consumed samples:      3731200 | elapsed time per iteration (ms): 352.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.174377E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116700/  200000 | consumed samples:      3734400 | elapsed time per iteration (ms): 294.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.328871E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   116800/  200000 | consumed samples:      3737600 | elapsed time per iteration (ms): 286.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.195725E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   116900/  200000 | consumed samples:      3740800 | elapsed time per iteration (ms): 317.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.209667E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117000/  200000 | consumed samples:      3744000 | elapsed time per iteration (ms): 332.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.502760E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117100/  200000 | consumed samples:      3747200 | elapsed time per iteration (ms): 339.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.476839E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117200/  200000 | consumed samples:      3750400 | elapsed time per iteration (ms): 313.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.187822E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117300/  200000 | consumed samples:      3753600 | elapsed time per iteration (ms): 282.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.419739E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117400/  200000 | consumed samples:      3756800 | elapsed time per iteration (ms): 282.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.427899E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117500/  200000 | consumed samples:      3760000 | elapsed time per iteration (ms): 281.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.308556E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117600/  200000 | consumed samples:      3763200 | elapsed time per iteration (ms): 305.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.387109E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117700/  200000 | consumed samples:      3766400 | elapsed time per iteration (ms): 351.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.219950E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117800/  200000 | consumed samples:      3769600 | elapsed time per iteration (ms): 360.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.423470E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   117900/  200000 | consumed samples:      3772800 | elapsed time per iteration (ms): 462.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.195654E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118000/  200000 | consumed samples:      3776000 | elapsed time per iteration (ms): 383.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.367962E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118100/  200000 | consumed samples:      3779200 | elapsed time per iteration (ms): 346.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.348965E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118200/  200000 | consumed samples:      3782400 | elapsed time per iteration (ms): 393.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.303248E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118300/  200000 | consumed samples:      3785600 | elapsed time per iteration (ms): 350.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.269260E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118400/  200000 | consumed samples:      3788800 | elapsed time per iteration (ms): 386.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.289585E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   118500/  200000 | consumed samples:      3792000 | elapsed time per iteration (ms): 406.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.284535E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   118600/  200000 | consumed samples:      3795200 | elapsed time per iteration (ms): 412.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.208454E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118700/  200000 | consumed samples:      3798400 | elapsed time per iteration (ms): 366.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.358094E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118800/  200000 | consumed samples:      3801600 | elapsed time per iteration (ms): 350.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.172785E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   118900/  200000 | consumed samples:      3804800 | elapsed time per iteration (ms): 373.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.307586E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119000/  200000 | consumed samples:      3808000 | elapsed time per iteration (ms): 360.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.112293E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119100/  200000 | consumed samples:      3811200 | elapsed time per iteration (ms): 375.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.202927E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119200/  200000 | consumed samples:      3814400 | elapsed time per iteration (ms): 359.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.200180E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119300/  200000 | consumed samples:      3817600 | elapsed time per iteration (ms): 361.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.144202E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119400/  200000 | consumed samples:      3820800 | elapsed time per iteration (ms): 359.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.223213E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119500/  200000 | consumed samples:      3824000 | elapsed time per iteration (ms): 447.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.182854E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119600/  200000 | consumed samples:      3827200 | elapsed time per iteration (ms): 343.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.115922E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   119700/  200000 | consumed samples:      3830400 | elapsed time per iteration (ms): 378.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.156581E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119800/  200000 | consumed samples:      3833600 | elapsed time per iteration (ms): 393.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.482236E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   119900/  200000 | consumed samples:      3836800 | elapsed time per iteration (ms): 397.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.378768E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120000/  200000 | consumed samples:      3840000 | elapsed time per iteration (ms): 376.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.268107E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120100/  200000 | consumed samples:      3843200 | elapsed time per iteration (ms): 832.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.215912E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120200/  200000 | consumed samples:      3846400 | elapsed time per iteration (ms): 370.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.186443E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120300/  200000 | consumed samples:      3849600 | elapsed time per iteration (ms): 358.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.288083E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120400/  200000 | consumed samples:      3852800 | elapsed time per iteration (ms): 421.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.382804E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120500/  200000 | consumed samples:      3856000 | elapsed time per iteration (ms): 360.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.342688E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120600/  200000 | consumed samples:      3859200 | elapsed time per iteration (ms): 396.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.229087E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120700/  200000 | consumed samples:      3862400 | elapsed time per iteration (ms): 343.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.303238E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120800/  200000 | consumed samples:      3865600 | elapsed time per iteration (ms): 372.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.351645E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   120900/  200000 | consumed samples:      3868800 | elapsed time per iteration (ms): 339.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.244361E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121000/  200000 | consumed samples:      3872000 | elapsed time per iteration (ms): 384.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.433229E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121100/  200000 | consumed samples:      3875200 | elapsed time per iteration (ms): 366.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.413761E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121200/  200000 | consumed samples:      3878400 | elapsed time per iteration (ms): 383.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.419734E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   121300/  200000 | consumed samples:      3881600 | elapsed time per iteration (ms): 330.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.273569E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121400/  200000 | consumed samples:      3884800 | elapsed time per iteration (ms): 412.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.419430E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121500/  200000 | consumed samples:      3888000 | elapsed time per iteration (ms): 332.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.517977E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121600/  200000 | consumed samples:      3891200 | elapsed time per iteration (ms): 359.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.293232E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   121700/  200000 | consumed samples:      3894400 | elapsed time per iteration (ms): 376.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.191183E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   121800/  200000 | consumed samples:      3897600 | elapsed time per iteration (ms): 358.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.177429E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   121900/  200000 | consumed samples:      3900800 | elapsed time per iteration (ms): 360.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.171386E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122000/  200000 | consumed samples:      3904000 | elapsed time per iteration (ms): 346.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.125598E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122100/  200000 | consumed samples:      3907200 | elapsed time per iteration (ms): 368.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.311675E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122200/  200000 | consumed samples:      3910400 | elapsed time per iteration (ms): 385.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.205650E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122300/  200000 | consumed samples:      3913600 | elapsed time per iteration (ms): 346.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.036017E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122400/  200000 | consumed samples:      3916800 | elapsed time per iteration (ms): 388.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.410154E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122500/  200000 | consumed samples:      3920000 | elapsed time per iteration (ms): 369.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.517773E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122600/  200000 | consumed samples:      3923200 | elapsed time per iteration (ms): 401.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489448E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122700/  200000 | consumed samples:      3926400 | elapsed time per iteration (ms): 365.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.376207E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122800/  200000 | consumed samples:      3929600 | elapsed time per iteration (ms): 374.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.388060E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   122900/  200000 | consumed samples:      3932800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.514181E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123000/  200000 | consumed samples:      3936000 | elapsed time per iteration (ms): 331.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.213045E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123100/  200000 | consumed samples:      3939200 | elapsed time per iteration (ms): 334.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.541954E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123200/  200000 | consumed samples:      3942400 | elapsed time per iteration (ms): 344.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.475647E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123300/  200000 | consumed samples:      3945600 | elapsed time per iteration (ms): 318.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.450914E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123400/  200000 | consumed samples:      3948800 | elapsed time per iteration (ms): 453.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.430933E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123500/  200000 | consumed samples:      3952000 | elapsed time per iteration (ms): 394.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.451948E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123600/  200000 | consumed samples:      3955200 | elapsed time per iteration (ms): 364.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.413304E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123700/  200000 | consumed samples:      3958400 | elapsed time per iteration (ms): 371.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.460478E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123800/  200000 | consumed samples:      3961600 | elapsed time per iteration (ms): 430.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.579255E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   123900/  200000 | consumed samples:      3964800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.580637E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124000/  200000 | consumed samples:      3968000 | elapsed time per iteration (ms): 284.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.469312E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124100/  200000 | consumed samples:      3971200 | elapsed time per iteration (ms): 314.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.318334E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124200/  200000 | consumed samples:      3974400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.673828E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124300/  200000 | consumed samples:      3977600 | elapsed time per iteration (ms): 549.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.538971E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124400/  200000 | consumed samples:      3980800 | elapsed time per iteration (ms): 289.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.479874E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124500/  200000 | consumed samples:      3984000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.497057E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124600/  200000 | consumed samples:      3987200 | elapsed time per iteration (ms): 352.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.379731E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124700/  200000 | consumed samples:      3990400 | elapsed time per iteration (ms): 392.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.514516E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124800/  200000 | consumed samples:      3993600 | elapsed time per iteration (ms): 427.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489836E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   124900/  200000 | consumed samples:      3996800 | elapsed time per iteration (ms): 301.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.167230E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125000/  200000 | consumed samples:      4000000 | elapsed time per iteration (ms): 299.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.278839E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   125100/  200000 | consumed samples:      4003200 | elapsed time per iteration (ms): 291.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.186872E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125200/  200000 | consumed samples:      4006400 | elapsed time per iteration (ms): 297.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.403361E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   125300/  200000 | consumed samples:      4009600 | elapsed time per iteration (ms): 291.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.426637E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125400/  200000 | consumed samples:      4012800 | elapsed time per iteration (ms): 331.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.453369E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125500/  200000 | consumed samples:      4016000 | elapsed time per iteration (ms): 332.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.240843E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125600/  200000 | consumed samples:      4019200 | elapsed time per iteration (ms): 369.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.607625E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125700/  200000 | consumed samples:      4022400 | elapsed time per iteration (ms): 356.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.438405E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125800/  200000 | consumed samples:      4025600 | elapsed time per iteration (ms): 495.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.439530E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   125900/  200000 | consumed samples:      4028800 | elapsed time per iteration (ms): 379.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.331860E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126000/  200000 | consumed samples:      4032000 | elapsed time per iteration (ms): 382.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.400673E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126100/  200000 | consumed samples:      4035200 | elapsed time per iteration (ms): 377.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.493417E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126200/  200000 | consumed samples:      4038400 | elapsed time per iteration (ms): 338.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.536280E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126300/  200000 | consumed samples:      4041600 | elapsed time per iteration (ms): 380.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.421932E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126400/  200000 | consumed samples:      4044800 | elapsed time per iteration (ms): 369.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.305050E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   126500/  200000 | consumed samples:      4048000 | elapsed time per iteration (ms): 390.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.462358E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126600/  200000 | consumed samples:      4051200 | elapsed time per iteration (ms): 398.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.679227E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126700/  200000 | consumed samples:      4054400 | elapsed time per iteration (ms): 431.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.402883E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   126800/  200000 | consumed samples:      4057600 | elapsed time per iteration (ms): 379.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.499519E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   126900/  200000 | consumed samples:      4060800 | elapsed time per iteration (ms): 366.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.657344E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127000/  200000 | consumed samples:      4064000 | elapsed time per iteration (ms): 380.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.525902E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   127100/  200000 | consumed samples:      4067200 | elapsed time per iteration (ms): 369.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.185768E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127200/  200000 | consumed samples:      4070400 | elapsed time per iteration (ms): 359.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.508570E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127300/  200000 | consumed samples:      4073600 | elapsed time per iteration (ms): 373.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.399036E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127400/  200000 | consumed samples:      4076800 | elapsed time per iteration (ms): 336.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.702912E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127500/  200000 | consumed samples:      4080000 | elapsed time per iteration (ms): 363.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.508373E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127600/  200000 | consumed samples:      4083200 | elapsed time per iteration (ms): 344.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.385617E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127700/  200000 | consumed samples:      4086400 | elapsed time per iteration (ms): 392.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.182803E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127800/  200000 | consumed samples:      4089600 | elapsed time per iteration (ms): 380.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.419869E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   127900/  200000 | consumed samples:      4092800 | elapsed time per iteration (ms): 399.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.495241E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128000/  200000 | consumed samples:      4096000 | elapsed time per iteration (ms): 357.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.260980E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128100/  200000 | consumed samples:      4099200 | elapsed time per iteration (ms): 355.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320300E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   128200/  200000 | consumed samples:      4102400 | elapsed time per iteration (ms): 345.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.552146E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128300/  200000 | consumed samples:      4105600 | elapsed time per iteration (ms): 369.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.330820E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128400/  200000 | consumed samples:      4108800 | elapsed time per iteration (ms): 386.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.318756E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128500/  200000 | consumed samples:      4112000 | elapsed time per iteration (ms): 379.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.228391E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128600/  200000 | consumed samples:      4115200 | elapsed time per iteration (ms): 435.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.209635E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128700/  200000 | consumed samples:      4118400 | elapsed time per iteration (ms): 420.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.251011E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128800/  200000 | consumed samples:      4121600 | elapsed time per iteration (ms): 345.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.505474E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   128900/  200000 | consumed samples:      4124800 | elapsed time per iteration (ms): 382.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.327530E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129000/  200000 | consumed samples:      4128000 | elapsed time per iteration (ms): 351.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.303822E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129100/  200000 | consumed samples:      4131200 | elapsed time per iteration (ms): 391.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.149192E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129200/  200000 | consumed samples:      4134400 | elapsed time per iteration (ms): 347.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329314E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129300/  200000 | consumed samples:      4137600 | elapsed time per iteration (ms): 365.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.610352E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   129400/  200000 | consumed samples:      4140800 | elapsed time per iteration (ms): 355.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.583972E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129500/  200000 | consumed samples:      4144000 | elapsed time per iteration (ms): 463.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.440465E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129600/  200000 | consumed samples:      4147200 | elapsed time per iteration (ms): 365.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.440056E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129700/  200000 | consumed samples:      4150400 | elapsed time per iteration (ms): 408.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.376058E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   129800/  200000 | consumed samples:      4153600 | elapsed time per iteration (ms): 348.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.234610E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   129900/  200000 | consumed samples:      4156800 | elapsed time per iteration (ms): 407.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.362711E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130000/  200000 | consumed samples:      4160000 | elapsed time per iteration (ms): 346.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.335432E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130100/  200000 | consumed samples:      4163200 | elapsed time per iteration (ms): 377.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.576605E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130200/  200000 | consumed samples:      4166400 | elapsed time per iteration (ms): 335.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329057E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130300/  200000 | consumed samples:      4169600 | elapsed time per iteration (ms): 363.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.359001E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130400/  200000 | consumed samples:      4172800 | elapsed time per iteration (ms): 352.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.434934E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130500/  200000 | consumed samples:      4176000 | elapsed time per iteration (ms): 348.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.291208E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130600/  200000 | consumed samples:      4179200 | elapsed time per iteration (ms): 391.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.602557E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130700/  200000 | consumed samples:      4182400 | elapsed time per iteration (ms): 365.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.668818E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   130800/  200000 | consumed samples:      4185600 | elapsed time per iteration (ms): 411.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.412148E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   130900/  200000 | consumed samples:      4188800 | elapsed time per iteration (ms): 358.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.475777E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   131000/  200000 | consumed samples:      4192000 | elapsed time per iteration (ms): 366.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.275061E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131100/  200000 | consumed samples:      4195200 | elapsed time per iteration (ms): 340.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.248988E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131200/  200000 | consumed samples:      4198400 | elapsed time per iteration (ms): 377.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.300058E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131300/  200000 | consumed samples:      4201600 | elapsed time per iteration (ms): 380.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.378897E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131400/  200000 | consumed samples:      4204800 | elapsed time per iteration (ms): 361.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.174488E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131500/  200000 | consumed samples:      4208000 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.405091E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131600/  200000 | consumed samples:      4211200 | elapsed time per iteration (ms): 355.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.490824E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131700/  200000 | consumed samples:      4214400 | elapsed time per iteration (ms): 349.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.242837E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131800/  200000 | consumed samples:      4217600 | elapsed time per iteration (ms): 294.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329477E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   131900/  200000 | consumed samples:      4220800 | elapsed time per iteration (ms): 400.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.245693E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132000/  200000 | consumed samples:      4224000 | elapsed time per iteration (ms): 348.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.461675E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132100/  200000 | consumed samples:      4227200 | elapsed time per iteration (ms): 314.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.423862E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132200/  200000 | consumed samples:      4230400 | elapsed time per iteration (ms): 317.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.405339E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132300/  200000 | consumed samples:      4233600 | elapsed time per iteration (ms): 294.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.240809E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132400/  200000 | consumed samples:      4236800 | elapsed time per iteration (ms): 331.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.384892E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   132500/  200000 | consumed samples:      4240000 | elapsed time per iteration (ms): 353.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.371291E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132600/  200000 | consumed samples:      4243200 | elapsed time per iteration (ms): 394.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.291102E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132700/  200000 | consumed samples:      4246400 | elapsed time per iteration (ms): 356.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.402366E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132800/  200000 | consumed samples:      4249600 | elapsed time per iteration (ms): 367.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.566169E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   132900/  200000 | consumed samples:      4252800 | elapsed time per iteration (ms): 307.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.532755E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133000/  200000 | consumed samples:      4256000 | elapsed time per iteration (ms): 317.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.355824E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133100/  200000 | consumed samples:      4259200 | elapsed time per iteration (ms): 368.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.534949E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133200/  200000 | consumed samples:      4262400 | elapsed time per iteration (ms): 359.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.554011E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133300/  200000 | consumed samples:      4265600 | elapsed time per iteration (ms): 401.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.623336E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133400/  200000 | consumed samples:      4268800 | elapsed time per iteration (ms): 344.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381011E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   133500/  200000 | consumed samples:      4272000 | elapsed time per iteration (ms): 402.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.558170E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133600/  200000 | consumed samples:      4275200 | elapsed time per iteration (ms): 345.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.478005E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   133700/  200000 | consumed samples:      4278400 | elapsed time per iteration (ms): 365.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.481049E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133800/  200000 | consumed samples:      4281600 | elapsed time per iteration (ms): 485.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.483055E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   133900/  200000 | consumed samples:      4284800 | elapsed time per iteration (ms): 368.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.436107E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134000/  200000 | consumed samples:      4288000 | elapsed time per iteration (ms): 357.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381877E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134100/  200000 | consumed samples:      4291200 | elapsed time per iteration (ms): 428.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.454402E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134200/  200000 | consumed samples:      4294400 | elapsed time per iteration (ms): 373.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.385097E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134300/  200000 | consumed samples:      4297600 | elapsed time per iteration (ms): 414.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.494095E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134400/  200000 | consumed samples:      4300800 | elapsed time per iteration (ms): 339.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.323860E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134500/  200000 | consumed samples:      4304000 | elapsed time per iteration (ms): 367.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.501292E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134600/  200000 | consumed samples:      4307200 | elapsed time per iteration (ms): 388.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.209255E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134700/  200000 | consumed samples:      4310400 | elapsed time per iteration (ms): 378.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.352582E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134800/  200000 | consumed samples:      4313600 | elapsed time per iteration (ms): 348.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.215654E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   134900/  200000 | consumed samples:      4316800 | elapsed time per iteration (ms): 389.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329924E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135000/  200000 | consumed samples:      4320000 | elapsed time per iteration (ms): 346.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.478729E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135100/  200000 | consumed samples:      4323200 | elapsed time per iteration (ms): 400.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.366392E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135200/  200000 | consumed samples:      4326400 | elapsed time per iteration (ms): 369.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329954E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135300/  200000 | consumed samples:      4329600 | elapsed time per iteration (ms): 399.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.210247E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135400/  200000 | consumed samples:      4332800 | elapsed time per iteration (ms): 359.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320170E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135500/  200000 | consumed samples:      4336000 | elapsed time per iteration (ms): 351.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.265152E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135600/  200000 | consumed samples:      4339200 | elapsed time per iteration (ms): 393.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.609600E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   135700/  200000 | consumed samples:      4342400 | elapsed time per iteration (ms): 374.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.516480E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135800/  200000 | consumed samples:      4345600 | elapsed time per iteration (ms): 360.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.409019E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   135900/  200000 | consumed samples:      4348800 | elapsed time per iteration (ms): 379.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.014008E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136000/  200000 | consumed samples:      4352000 | elapsed time per iteration (ms): 365.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.580415E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   136100/  200000 | consumed samples:      4355200 | elapsed time per iteration (ms): 371.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301542E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136200/  200000 | consumed samples:      4358400 | elapsed time per iteration (ms): 358.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.153734E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136300/  200000 | consumed samples:      4361600 | elapsed time per iteration (ms): 363.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.156797E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136400/  200000 | consumed samples:      4364800 | elapsed time per iteration (ms): 369.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.512205E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136500/  200000 | consumed samples:      4368000 | elapsed time per iteration (ms): 386.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.394562E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136600/  200000 | consumed samples:      4371200 | elapsed time per iteration (ms): 422.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.364172E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136700/  200000 | consumed samples:      4374400 | elapsed time per iteration (ms): 399.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.401090E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   136800/  200000 | consumed samples:      4377600 | elapsed time per iteration (ms): 336.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.394957E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   136900/  200000 | consumed samples:      4380800 | elapsed time per iteration (ms): 398.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.335504E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137000/  200000 | consumed samples:      4384000 | elapsed time per iteration (ms): 343.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.600792E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   137100/  200000 | consumed samples:      4387200 | elapsed time per iteration (ms): 387.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.621577E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137200/  200000 | consumed samples:      4390400 | elapsed time per iteration (ms): 394.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.226329E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137300/  200000 | consumed samples:      4393600 | elapsed time per iteration (ms): 356.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.316428E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137400/  200000 | consumed samples:      4396800 | elapsed time per iteration (ms): 370.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.523380E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137500/  200000 | consumed samples:      4400000 | elapsed time per iteration (ms): 348.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.145819E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137600/  200000 | consumed samples:      4403200 | elapsed time per iteration (ms): 429.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.472824E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137700/  200000 | consumed samples:      4406400 | elapsed time per iteration (ms): 344.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.298022E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137800/  200000 | consumed samples:      4409600 | elapsed time per iteration (ms): 530.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.213915E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   137900/  200000 | consumed samples:      4412800 | elapsed time per iteration (ms): 379.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.414141E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138000/  200000 | consumed samples:      4416000 | elapsed time per iteration (ms): 362.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.475815E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138100/  200000 | consumed samples:      4419200 | elapsed time per iteration (ms): 356.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.293411E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138200/  200000 | consumed samples:      4422400 | elapsed time per iteration (ms): 370.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.369877E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138300/  200000 | consumed samples:      4425600 | elapsed time per iteration (ms): 355.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.094740E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138400/  200000 | consumed samples:      4428800 | elapsed time per iteration (ms): 359.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.223125E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138500/  200000 | consumed samples:      4432000 | elapsed time per iteration (ms): 348.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.396781E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138600/  200000 | consumed samples:      4435200 | elapsed time per iteration (ms): 427.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.271730E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138700/  200000 | consumed samples:      4438400 | elapsed time per iteration (ms): 348.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.221143E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138800/  200000 | consumed samples:      4441600 | elapsed time per iteration (ms): 480.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.290482E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   138900/  200000 | consumed samples:      4444800 | elapsed time per iteration (ms): 371.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.531159E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139000/  200000 | consumed samples:      4448000 | elapsed time per iteration (ms): 349.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.362211E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139100/  200000 | consumed samples:      4451200 | elapsed time per iteration (ms): 369.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.559979E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139200/  200000 | consumed samples:      4454400 | elapsed time per iteration (ms): 463.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.446749E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139300/  200000 | consumed samples:      4457600 | elapsed time per iteration (ms): 332.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.430654E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   139400/  200000 | consumed samples:      4460800 | elapsed time per iteration (ms): 341.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.380052E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139500/  200000 | consumed samples:      4464000 | elapsed time per iteration (ms): 326.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.371755E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139600/  200000 | consumed samples:      4467200 | elapsed time per iteration (ms): 352.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.309658E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139700/  200000 | consumed samples:      4470400 | elapsed time per iteration (ms): 363.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.471113E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139800/  200000 | consumed samples:      4473600 | elapsed time per iteration (ms): 307.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.273171E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   139900/  200000 | consumed samples:      4476800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.390011E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140000/  200000 | consumed samples:      4480000 | elapsed time per iteration (ms): 416.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.463589E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140100/  200000 | consumed samples:      4483200 | elapsed time per iteration (ms): 756.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.574086E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140200/  200000 | consumed samples:      4486400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.365777E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140300/  200000 | consumed samples:      4489600 | elapsed time per iteration (ms): 309.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.278583E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140400/  200000 | consumed samples:      4492800 | elapsed time per iteration (ms): 347.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.235885E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140500/  200000 | consumed samples:      4496000 | elapsed time per iteration (ms): 311.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.192995E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140600/  200000 | consumed samples:      4499200 | elapsed time per iteration (ms): 332.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.283976E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140700/  200000 | consumed samples:      4502400 | elapsed time per iteration (ms): 381.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.274442E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   140800/  200000 | consumed samples:      4505600 | elapsed time per iteration (ms): 295.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.272229E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   140900/  200000 | consumed samples:      4508800 | elapsed time per iteration (ms): 289.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.479321E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   141000/  200000 | consumed samples:      4512000 | elapsed time per iteration (ms): 289.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.213348E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141100/  200000 | consumed samples:      4515200 | elapsed time per iteration (ms): 291.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.216479E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141200/  200000 | consumed samples:      4518400 | elapsed time per iteration (ms): 287.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.567517E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141300/  200000 | consumed samples:      4521600 | elapsed time per iteration (ms): 348.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.460599E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141400/  200000 | consumed samples:      4524800 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.293413E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141500/  200000 | consumed samples:      4528000 | elapsed time per iteration (ms): 300.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.131275E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141600/  200000 | consumed samples:      4531200 | elapsed time per iteration (ms): 312.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.069320E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141700/  200000 | consumed samples:      4534400 | elapsed time per iteration (ms): 367.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.254464E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141800/  200000 | consumed samples:      4537600 | elapsed time per iteration (ms): 349.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.201334E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   141900/  200000 | consumed samples:      4540800 | elapsed time per iteration (ms): 492.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.347936E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   142000/  200000 | consumed samples:      4544000 | elapsed time per iteration (ms): 387.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.162979E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142100/  200000 | consumed samples:      4547200 | elapsed time per iteration (ms): 357.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.410242E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142200/  200000 | consumed samples:      4550400 | elapsed time per iteration (ms): 376.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.285713E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142300/  200000 | consumed samples:      4553600 | elapsed time per iteration (ms): 332.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.359934E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142400/  200000 | consumed samples:      4556800 | elapsed time per iteration (ms): 374.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.288810E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142500/  200000 | consumed samples:      4560000 | elapsed time per iteration (ms): 346.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.234981E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142600/  200000 | consumed samples:      4563200 | elapsed time per iteration (ms): 499.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.315858E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   142700/  200000 | consumed samples:      4566400 | elapsed time per iteration (ms): 387.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.529332E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142800/  200000 | consumed samples:      4569600 | elapsed time per iteration (ms): 384.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.410117E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   142900/  200000 | consumed samples:      4572800 | elapsed time per iteration (ms): 362.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.245342E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143000/  200000 | consumed samples:      4576000 | elapsed time per iteration (ms): 360.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.496237E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143100/  200000 | consumed samples:      4579200 | elapsed time per iteration (ms): 391.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489176E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143200/  200000 | consumed samples:      4582400 | elapsed time per iteration (ms): 411.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.456333E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143300/  200000 | consumed samples:      4585600 | elapsed time per iteration (ms): 366.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.491831E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143400/  200000 | consumed samples:      4588800 | elapsed time per iteration (ms): 330.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.506012E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143500/  200000 | consumed samples:      4592000 | elapsed time per iteration (ms): 405.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.293539E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143600/  200000 | consumed samples:      4595200 | elapsed time per iteration (ms): 369.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.210708E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143700/  200000 | consumed samples:      4598400 | elapsed time per iteration (ms): 381.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320640E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143800/  200000 | consumed samples:      4601600 | elapsed time per iteration (ms): 364.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.304550E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   143900/  200000 | consumed samples:      4604800 | elapsed time per iteration (ms): 364.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.327913E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144000/  200000 | consumed samples:      4608000 | elapsed time per iteration (ms): 370.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.236291E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144100/  200000 | consumed samples:      4611200 | elapsed time per iteration (ms): 388.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.307908E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144200/  200000 | consumed samples:      4614400 | elapsed time per iteration (ms): 392.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.191354E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144300/  200000 | consumed samples:      4617600 | elapsed time per iteration (ms): 367.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.328735E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144400/  200000 | consumed samples:      4620800 | elapsed time per iteration (ms): 351.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.462564E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144500/  200000 | consumed samples:      4624000 | elapsed time per iteration (ms): 352.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.267265E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144600/  200000 | consumed samples:      4627200 | elapsed time per iteration (ms): 452.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.507343E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144700/  200000 | consumed samples:      4630400 | elapsed time per iteration (ms): 356.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.601821E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144800/  200000 | consumed samples:      4633600 | elapsed time per iteration (ms): 347.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.482620E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   144900/  200000 | consumed samples:      4636800 | elapsed time per iteration (ms): 356.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.447834E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145000/  200000 | consumed samples:      4640000 | elapsed time per iteration (ms): 351.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.339698E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145100/  200000 | consumed samples:      4643200 | elapsed time per iteration (ms): 433.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.279459E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   145200/  200000 | consumed samples:      4646400 | elapsed time per iteration (ms): 341.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.451335E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   145300/  200000 | consumed samples:      4649600 | elapsed time per iteration (ms): 367.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.349691E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145400/  200000 | consumed samples:      4652800 | elapsed time per iteration (ms): 331.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.575454E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145500/  200000 | consumed samples:      4656000 | elapsed time per iteration (ms): 394.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.440859E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145600/  200000 | consumed samples:      4659200 | elapsed time per iteration (ms): 334.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.699441E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145700/  200000 | consumed samples:      4662400 | elapsed time per iteration (ms): 392.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.631334E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145800/  200000 | consumed samples:      4665600 | elapsed time per iteration (ms): 332.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.493490E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   145900/  200000 | consumed samples:      4668800 | elapsed time per iteration (ms): 373.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.350413E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146000/  200000 | consumed samples:      4672000 | elapsed time per iteration (ms): 328.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.700023E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146100/  200000 | consumed samples:      4675200 | elapsed time per iteration (ms): 437.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381411E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146200/  200000 | consumed samples:      4678400 | elapsed time per iteration (ms): 340.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.665627E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146300/  200000 | consumed samples:      4681600 | elapsed time per iteration (ms): 359.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.394051E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   146400/  200000 | consumed samples:      4684800 | elapsed time per iteration (ms): 450.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.483407E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146500/  200000 | consumed samples:      4688000 | elapsed time per iteration (ms): 376.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.467091E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   146600/  200000 | consumed samples:      4691200 | elapsed time per iteration (ms): 450.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.330156E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146700/  200000 | consumed samples:      4694400 | elapsed time per iteration (ms): 386.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.348810E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146800/  200000 | consumed samples:      4697600 | elapsed time per iteration (ms): 347.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.483154E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   146900/  200000 | consumed samples:      4700800 | elapsed time per iteration (ms): 391.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489876E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147000/  200000 | consumed samples:      4704000 | elapsed time per iteration (ms): 348.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.428473E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147100/  200000 | consumed samples:      4707200 | elapsed time per iteration (ms): 358.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.471709E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147200/  200000 | consumed samples:      4710400 | elapsed time per iteration (ms): 348.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.036453E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147300/  200000 | consumed samples:      4713600 | elapsed time per iteration (ms): 364.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.460306E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147400/  200000 | consumed samples:      4716800 | elapsed time per iteration (ms): 347.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.384434E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147500/  200000 | consumed samples:      4720000 | elapsed time per iteration (ms): 418.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.452616E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147600/  200000 | consumed samples:      4723200 | elapsed time per iteration (ms): 291.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.159024E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147700/  200000 | consumed samples:      4726400 | elapsed time per iteration (ms): 347.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.428637E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147800/  200000 | consumed samples:      4729600 | elapsed time per iteration (ms): 344.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.706601E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   147900/  200000 | consumed samples:      4732800 | elapsed time per iteration (ms): 414.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.205629E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148000/  200000 | consumed samples:      4736000 | elapsed time per iteration (ms): 327.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.502370E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148100/  200000 | consumed samples:      4739200 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381845E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148200/  200000 | consumed samples:      4742400 | elapsed time per iteration (ms): 308.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.514599E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148300/  200000 | consumed samples:      4745600 | elapsed time per iteration (ms): 303.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.386230E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148400/  200000 | consumed samples:      4748800 | elapsed time per iteration (ms): 308.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.547904E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148500/  200000 | consumed samples:      4752000 | elapsed time per iteration (ms): 362.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.469301E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148600/  200000 | consumed samples:      4755200 | elapsed time per iteration (ms): 394.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.571355E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148700/  200000 | consumed samples:      4758400 | elapsed time per iteration (ms): 352.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.732212E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148800/  200000 | consumed samples:      4761600 | elapsed time per iteration (ms): 317.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.658614E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   148900/  200000 | consumed samples:      4764800 | elapsed time per iteration (ms): 332.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.450118E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149000/  200000 | consumed samples:      4768000 | elapsed time per iteration (ms): 417.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.429888E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149100/  200000 | consumed samples:      4771200 | elapsed time per iteration (ms): 362.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.404446E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149200/  200000 | consumed samples:      4774400 | elapsed time per iteration (ms): 309.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.620408E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   149300/  200000 | consumed samples:      4777600 | elapsed time per iteration (ms): 475.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.443154E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149400/  200000 | consumed samples:      4780800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.405280E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149500/  200000 | consumed samples:      4784000 | elapsed time per iteration (ms): 294.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.153322E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149600/  200000 | consumed samples:      4787200 | elapsed time per iteration (ms): 318.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.486909E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149700/  200000 | consumed samples:      4790400 | elapsed time per iteration (ms): 399.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.395843E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   149800/  200000 | consumed samples:      4793600 | elapsed time per iteration (ms): 350.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.315374E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   149900/  200000 | consumed samples:      4796800 | elapsed time per iteration (ms): 330.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.474423E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150000/  200000 | consumed samples:      4800000 | elapsed time per iteration (ms): 439.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.261403E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150100/  200000 | consumed samples:      4803200 | elapsed time per iteration (ms): 569.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.217314E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150200/  200000 | consumed samples:      4806400 | elapsed time per iteration (ms): 349.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.399911E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   150300/  200000 | consumed samples:      4809600 | elapsed time per iteration (ms): 369.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.347324E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150400/  200000 | consumed samples:      4812800 | elapsed time per iteration (ms): 336.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.178435E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150500/  200000 | consumed samples:      4816000 | elapsed time per iteration (ms): 357.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.470162E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150600/  200000 | consumed samples:      4819200 | elapsed time per iteration (ms): 386.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.331459E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150700/  200000 | consumed samples:      4822400 | elapsed time per iteration (ms): 357.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.460781E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150800/  200000 | consumed samples:      4825600 | elapsed time per iteration (ms): 380.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.243183E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   150900/  200000 | consumed samples:      4828800 | elapsed time per iteration (ms): 354.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.387156E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151000/  200000 | consumed samples:      4832000 | elapsed time per iteration (ms): 358.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.441899E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151100/  200000 | consumed samples:      4835200 | elapsed time per iteration (ms): 416.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.054968E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151200/  200000 | consumed samples:      4838400 | elapsed time per iteration (ms): 345.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.411820E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151300/  200000 | consumed samples:      4841600 | elapsed time per iteration (ms): 373.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.326085E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   151400/  200000 | consumed samples:      4844800 | elapsed time per iteration (ms): 347.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.415080E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151500/  200000 | consumed samples:      4848000 | elapsed time per iteration (ms): 393.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.327380E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151600/  200000 | consumed samples:      4851200 | elapsed time per iteration (ms): 357.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.464826E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151700/  200000 | consumed samples:      4854400 | elapsed time per iteration (ms): 371.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.164891E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151800/  200000 | consumed samples:      4857600 | elapsed time per iteration (ms): 337.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.163913E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   151900/  200000 | consumed samples:      4860800 | elapsed time per iteration (ms): 379.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.336977E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152000/  200000 | consumed samples:      4864000 | elapsed time per iteration (ms): 381.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.349700E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152100/  200000 | consumed samples:      4867200 | elapsed time per iteration (ms): 411.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.639988E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152200/  200000 | consumed samples:      4870400 | elapsed time per iteration (ms): 359.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.380933E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152300/  200000 | consumed samples:      4873600 | elapsed time per iteration (ms): 367.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.275840E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   4 | number of nan iterations:   0 |
 iteration   152400/  200000 | consumed samples:      4876800 | elapsed time per iteration (ms): 332.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.312164E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152500/  200000 | consumed samples:      4880000 | elapsed time per iteration (ms): 361.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.436174E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152600/  200000 | consumed samples:      4883200 | elapsed time per iteration (ms): 389.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.253308E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152700/  200000 | consumed samples:      4886400 | elapsed time per iteration (ms): 373.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.409263E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152800/  200000 | consumed samples:      4889600 | elapsed time per iteration (ms): 410.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.621316E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   152900/  200000 | consumed samples:      4892800 | elapsed time per iteration (ms): 373.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.159942E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153000/  200000 | consumed samples:      4896000 | elapsed time per iteration (ms): 403.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.287639E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153100/  200000 | consumed samples:      4899200 | elapsed time per iteration (ms): 357.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.222677E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153200/  200000 | consumed samples:      4902400 | elapsed time per iteration (ms): 361.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.314892E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153300/  200000 | consumed samples:      4905600 | elapsed time per iteration (ms): 368.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.407066E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153400/  200000 | consumed samples:      4908800 | elapsed time per iteration (ms): 360.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.184557E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153500/  200000 | consumed samples:      4912000 | elapsed time per iteration (ms): 371.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.206175E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153600/  200000 | consumed samples:      4915200 | elapsed time per iteration (ms): 377.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.444908E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153700/  200000 | consumed samples:      4918400 | elapsed time per iteration (ms): 365.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.280985E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153800/  200000 | consumed samples:      4921600 | elapsed time per iteration (ms): 381.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.598489E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   153900/  200000 | consumed samples:      4924800 | elapsed time per iteration (ms): 360.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.458725E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154000/  200000 | consumed samples:      4928000 | elapsed time per iteration (ms): 425.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.396950E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154100/  200000 | consumed samples:      4931200 | elapsed time per iteration (ms): 341.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.426220E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154200/  200000 | consumed samples:      4934400 | elapsed time per iteration (ms): 378.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.377146E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   154300/  200000 | consumed samples:      4937600 | elapsed time per iteration (ms): 349.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.157693E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154400/  200000 | consumed samples:      4940800 | elapsed time per iteration (ms): 345.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.417317E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154500/  200000 | consumed samples:      4944000 | elapsed time per iteration (ms): 328.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.250769E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154600/  200000 | consumed samples:      4947200 | elapsed time per iteration (ms): 373.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.465674E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154700/  200000 | consumed samples:      4950400 | elapsed time per iteration (ms): 359.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.752025E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154800/  200000 | consumed samples:      4953600 | elapsed time per iteration (ms): 352.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489157E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   154900/  200000 | consumed samples:      4956800 | elapsed time per iteration (ms): 370.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.448161E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155000/  200000 | consumed samples:      4960000 | elapsed time per iteration (ms): 307.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.725706E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155100/  200000 | consumed samples:      4963200 | elapsed time per iteration (ms): 401.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.487318E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155200/  200000 | consumed samples:      4966400 | elapsed time per iteration (ms): 358.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.552567E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155300/  200000 | consumed samples:      4969600 | elapsed time per iteration (ms): 377.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.497191E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155400/  200000 | consumed samples:      4972800 | elapsed time per iteration (ms): 351.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.434856E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155500/  200000 | consumed samples:      4976000 | elapsed time per iteration (ms): 359.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.356018E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155600/  200000 | consumed samples:      4979200 | elapsed time per iteration (ms): 306.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.469241E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155700/  200000 | consumed samples:      4982400 | elapsed time per iteration (ms): 366.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.418616E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155800/  200000 | consumed samples:      4985600 | elapsed time per iteration (ms): 367.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.562566E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   155900/  200000 | consumed samples:      4988800 | elapsed time per iteration (ms): 349.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.235556E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156000/  200000 | consumed samples:      4992000 | elapsed time per iteration (ms): 392.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.189184E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156100/  200000 | consumed samples:      4995200 | elapsed time per iteration (ms): 354.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.371966E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156200/  200000 | consumed samples:      4998400 | elapsed time per iteration (ms): 397.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.648288E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156300/  200000 | consumed samples:      5001600 | elapsed time per iteration (ms): 346.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.465198E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156400/  200000 | consumed samples:      5004800 | elapsed time per iteration (ms): 372.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.530713E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156500/  200000 | consumed samples:      5008000 | elapsed time per iteration (ms): 377.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.546479E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   156600/  200000 | consumed samples:      5011200 | elapsed time per iteration (ms): 364.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.544611E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   156700/  200000 | consumed samples:      5014400 | elapsed time per iteration (ms): 276.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.466251E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156800/  200000 | consumed samples:      5017600 | elapsed time per iteration (ms): 393.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.268517E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   156900/  200000 | consumed samples:      5020800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.465391E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157000/  200000 | consumed samples:      5024000 | elapsed time per iteration (ms): 330.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.489787E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157100/  200000 | consumed samples:      5027200 | elapsed time per iteration (ms): 333.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.374260E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157200/  200000 | consumed samples:      5030400 | elapsed time per iteration (ms): 377.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.435798E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157300/  200000 | consumed samples:      5033600 | elapsed time per iteration (ms): 413.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.273052E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157400/  200000 | consumed samples:      5036800 | elapsed time per iteration (ms): 358.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.575442E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157500/  200000 | consumed samples:      5040000 | elapsed time per iteration (ms): 326.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.385149E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157600/  200000 | consumed samples:      5043200 | elapsed time per iteration (ms): 358.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.436028E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157700/  200000 | consumed samples:      5046400 | elapsed time per iteration (ms): 311.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.326532E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   157800/  200000 | consumed samples:      5049600 | elapsed time per iteration (ms): 310.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.579808E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   157900/  200000 | consumed samples:      5052800 | elapsed time per iteration (ms): 361.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.334407E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   158000/  200000 | consumed samples:      5056000 | elapsed time per iteration (ms): 388.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.568982E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158100/  200000 | consumed samples:      5059200 | elapsed time per iteration (ms): 371.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.542038E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158200/  200000 | consumed samples:      5062400 | elapsed time per iteration (ms): 463.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.203336E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158300/  200000 | consumed samples:      5065600 | elapsed time per iteration (ms): 429.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.427579E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158400/  200000 | consumed samples:      5068800 | elapsed time per iteration (ms): 332.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.528281E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158500/  200000 | consumed samples:      5072000 | elapsed time per iteration (ms): 374.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.303600E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158600/  200000 | consumed samples:      5075200 | elapsed time per iteration (ms): 401.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.382713E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158700/  200000 | consumed samples:      5078400 | elapsed time per iteration (ms): 387.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.756583E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158800/  200000 | consumed samples:      5081600 | elapsed time per iteration (ms): 366.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.587757E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   158900/  200000 | consumed samples:      5084800 | elapsed time per iteration (ms): 399.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.167642E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159000/  200000 | consumed samples:      5088000 | elapsed time per iteration (ms): 354.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.487570E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159100/  200000 | consumed samples:      5091200 | elapsed time per iteration (ms): 391.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.250589E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159200/  200000 | consumed samples:      5094400 | elapsed time per iteration (ms): 356.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.593878E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159300/  200000 | consumed samples:      5097600 | elapsed time per iteration (ms): 375.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.539561E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159400/  200000 | consumed samples:      5100800 | elapsed time per iteration (ms): 353.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.395500E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159500/  200000 | consumed samples:      5104000 | elapsed time per iteration (ms): 388.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.118414E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159600/  200000 | consumed samples:      5107200 | elapsed time per iteration (ms): 349.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.554480E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159700/  200000 | consumed samples:      5110400 | elapsed time per iteration (ms): 387.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.276336E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159800/  200000 | consumed samples:      5113600 | elapsed time per iteration (ms): 356.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.393500E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   159900/  200000 | consumed samples:      5116800 | elapsed time per iteration (ms): 407.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.218508E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160000/  200000 | consumed samples:      5120000 | elapsed time per iteration (ms): 344.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.442465E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160100/  200000 | consumed samples:      5123200 | elapsed time per iteration (ms): 805.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320791E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160200/  200000 | consumed samples:      5126400 | elapsed time per iteration (ms): 355.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.696373E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160300/  200000 | consumed samples:      5129600 | elapsed time per iteration (ms): 405.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.247161E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160400/  200000 | consumed samples:      5132800 | elapsed time per iteration (ms): 343.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.448876E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160500/  200000 | consumed samples:      5136000 | elapsed time per iteration (ms): 366.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.458847E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160600/  200000 | consumed samples:      5139200 | elapsed time per iteration (ms): 426.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.452641E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160700/  200000 | consumed samples:      5142400 | elapsed time per iteration (ms): 393.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.406479E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160800/  200000 | consumed samples:      5145600 | elapsed time per iteration (ms): 352.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.364291E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   160900/  200000 | consumed samples:      5148800 | elapsed time per iteration (ms): 357.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.545716E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   161000/  200000 | consumed samples:      5152000 | elapsed time per iteration (ms): 373.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.241704E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161100/  200000 | consumed samples:      5155200 | elapsed time per iteration (ms): 351.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.541317E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161200/  200000 | consumed samples:      5158400 | elapsed time per iteration (ms): 376.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.403965E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161300/  200000 | consumed samples:      5161600 | elapsed time per iteration (ms): 357.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301489E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161400/  200000 | consumed samples:      5164800 | elapsed time per iteration (ms): 364.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.580196E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   161500/  200000 | consumed samples:      5168000 | elapsed time per iteration (ms): 360.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.503921E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161600/  200000 | consumed samples:      5171200 | elapsed time per iteration (ms): 378.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.333514E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161700/  200000 | consumed samples:      5174400 | elapsed time per iteration (ms): 400.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.296424E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   161800/  200000 | consumed samples:      5177600 | elapsed time per iteration (ms): 337.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.471983E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   161900/  200000 | consumed samples:      5180800 | elapsed time per iteration (ms): 353.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.448807E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162000/  200000 | consumed samples:      5184000 | elapsed time per iteration (ms): 363.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.241469E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162100/  200000 | consumed samples:      5187200 | elapsed time per iteration (ms): 393.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.586499E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162200/  200000 | consumed samples:      5190400 | elapsed time per iteration (ms): 374.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.498269E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162300/  200000 | consumed samples:      5193600 | elapsed time per iteration (ms): 367.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.339988E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162400/  200000 | consumed samples:      5196800 | elapsed time per iteration (ms): 340.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.360249E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162500/  200000 | consumed samples:      5200000 | elapsed time per iteration (ms): 363.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.395905E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162600/  200000 | consumed samples:      5203200 | elapsed time per iteration (ms): 374.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.364273E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162700/  200000 | consumed samples:      5206400 | elapsed time per iteration (ms): 345.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.434506E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162800/  200000 | consumed samples:      5209600 | elapsed time per iteration (ms): 344.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.467151E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   162900/  200000 | consumed samples:      5212800 | elapsed time per iteration (ms): 365.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.336052E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163000/  200000 | consumed samples:      5216000 | elapsed time per iteration (ms): 399.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.565816E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163100/  200000 | consumed samples:      5219200 | elapsed time per iteration (ms): 346.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.474710E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163200/  200000 | consumed samples:      5222400 | elapsed time per iteration (ms): 378.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.490567E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163300/  200000 | consumed samples:      5225600 | elapsed time per iteration (ms): 356.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.503804E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163400/  200000 | consumed samples:      5228800 | elapsed time per iteration (ms): 365.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.264675E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163500/  200000 | consumed samples:      5232000 | elapsed time per iteration (ms): 356.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.306463E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   163600/  200000 | consumed samples:      5235200 | elapsed time per iteration (ms): 338.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.585811E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163700/  200000 | consumed samples:      5238400 | elapsed time per iteration (ms): 369.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.342143E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163800/  200000 | consumed samples:      5241600 | elapsed time per iteration (ms): 365.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.316206E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   163900/  200000 | consumed samples:      5244800 | elapsed time per iteration (ms): 329.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.524358E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164000/  200000 | consumed samples:      5248000 | elapsed time per iteration (ms): 361.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.264716E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164100/  200000 | consumed samples:      5251200 | elapsed time per iteration (ms): 318.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.747137E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164200/  200000 | consumed samples:      5254400 | elapsed time per iteration (ms): 302.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.311912E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164300/  200000 | consumed samples:      5257600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.345856E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164400/  200000 | consumed samples:      5260800 | elapsed time per iteration (ms): 334.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.349084E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164500/  200000 | consumed samples:      5264000 | elapsed time per iteration (ms): 580.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.436415E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164600/  200000 | consumed samples:      5267200 | elapsed time per iteration (ms): 340.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.524012E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164700/  200000 | consumed samples:      5270400 | elapsed time per iteration (ms): 333.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.306736E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164800/  200000 | consumed samples:      5273600 | elapsed time per iteration (ms): 336.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.680567E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   164900/  200000 | consumed samples:      5276800 | elapsed time per iteration (ms): 370.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.645405E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165000/  200000 | consumed samples:      5280000 | elapsed time per iteration (ms): 331.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.282168E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165100/  200000 | consumed samples:      5283200 | elapsed time per iteration (ms): 353.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.399158E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165200/  200000 | consumed samples:      5286400 | elapsed time per iteration (ms): 362.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.443760E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165300/  200000 | consumed samples:      5289600 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.476139E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165400/  200000 | consumed samples:      5292800 | elapsed time per iteration (ms): 295.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.384624E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165500/  200000 | consumed samples:      5296000 | elapsed time per iteration (ms): 339.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.349239E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165600/  200000 | consumed samples:      5299200 | elapsed time per iteration (ms): 318.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.214778E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165700/  200000 | consumed samples:      5302400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.336853E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165800/  200000 | consumed samples:      5305600 | elapsed time per iteration (ms): 284.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.305142E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   165900/  200000 | consumed samples:      5308800 | elapsed time per iteration (ms): 318.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.459408E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166000/  200000 | consumed samples:      5312000 | elapsed time per iteration (ms): 292.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.242668E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   166100/  200000 | consumed samples:      5315200 | elapsed time per iteration (ms): 296.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.295680E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   166200/  200000 | consumed samples:      5318400 | elapsed time per iteration (ms): 362.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.299696E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166300/  200000 | consumed samples:      5321600 | elapsed time per iteration (ms): 407.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.235997E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166400/  200000 | consumed samples:      5324800 | elapsed time per iteration (ms): 481.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.570252E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166500/  200000 | consumed samples:      5328000 | elapsed time per iteration (ms): 385.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.160903E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166600/  200000 | consumed samples:      5331200 | elapsed time per iteration (ms): 400.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.506590E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166700/  200000 | consumed samples:      5334400 | elapsed time per iteration (ms): 375.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.223083E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166800/  200000 | consumed samples:      5337600 | elapsed time per iteration (ms): 331.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.274045E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   166900/  200000 | consumed samples:      5340800 | elapsed time per iteration (ms): 417.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.262841E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167000/  200000 | consumed samples:      5344000 | elapsed time per iteration (ms): 352.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.479712E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167100/  200000 | consumed samples:      5347200 | elapsed time per iteration (ms): 379.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.340088E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167200/  200000 | consumed samples:      5350400 | elapsed time per iteration (ms): 366.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.035097E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167300/  200000 | consumed samples:      5353600 | elapsed time per iteration (ms): 392.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.375313E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167400/  200000 | consumed samples:      5356800 | elapsed time per iteration (ms): 371.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.617389E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167500/  200000 | consumed samples:      5360000 | elapsed time per iteration (ms): 364.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.427856E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167600/  200000 | consumed samples:      5363200 | elapsed time per iteration (ms): 353.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.449405E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167700/  200000 | consumed samples:      5366400 | elapsed time per iteration (ms): 357.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.311084E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167800/  200000 | consumed samples:      5369600 | elapsed time per iteration (ms): 364.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.539355E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   167900/  200000 | consumed samples:      5372800 | elapsed time per iteration (ms): 362.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.409227E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168000/  200000 | consumed samples:      5376000 | elapsed time per iteration (ms): 362.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.500556E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168100/  200000 | consumed samples:      5379200 | elapsed time per iteration (ms): 363.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.449718E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168200/  200000 | consumed samples:      5382400 | elapsed time per iteration (ms): 366.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.294719E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168300/  200000 | consumed samples:      5385600 | elapsed time per iteration (ms): 453.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.406896E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168400/  200000 | consumed samples:      5388800 | elapsed time per iteration (ms): 378.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.491705E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168500/  200000 | consumed samples:      5392000 | elapsed time per iteration (ms): 362.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.236809E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168600/  200000 | consumed samples:      5395200 | elapsed time per iteration (ms): 387.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.480747E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168700/  200000 | consumed samples:      5398400 | elapsed time per iteration (ms): 386.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.456098E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168800/  200000 | consumed samples:      5401600 | elapsed time per iteration (ms): 420.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.324845E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   168900/  200000 | consumed samples:      5404800 | elapsed time per iteration (ms): 358.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.218455E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169000/  200000 | consumed samples:      5408000 | elapsed time per iteration (ms): 380.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.422679E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169100/  200000 | consumed samples:      5411200 | elapsed time per iteration (ms): 334.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.554373E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   169200/  200000 | consumed samples:      5414400 | elapsed time per iteration (ms): 454.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.269251E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169300/  200000 | consumed samples:      5417600 | elapsed time per iteration (ms): 343.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.392375E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169400/  200000 | consumed samples:      5420800 | elapsed time per iteration (ms): 358.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.230322E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169500/  200000 | consumed samples:      5424000 | elapsed time per iteration (ms): 363.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.209827E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169600/  200000 | consumed samples:      5427200 | elapsed time per iteration (ms): 385.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.053201E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   169700/  200000 | consumed samples:      5430400 | elapsed time per iteration (ms): 362.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.357030E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   169800/  200000 | consumed samples:      5433600 | elapsed time per iteration (ms): 357.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.328866E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   169900/  200000 | consumed samples:      5436800 | elapsed time per iteration (ms): 342.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.249820E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170000/  200000 | consumed samples:      5440000 | elapsed time per iteration (ms): 359.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.179820E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170100/  200000 | consumed samples:      5443200 | elapsed time per iteration (ms): 359.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.295274E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170200/  200000 | consumed samples:      5446400 | elapsed time per iteration (ms): 376.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.931280E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170300/  200000 | consumed samples:      5449600 | elapsed time per iteration (ms): 377.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.515494E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170400/  200000 | consumed samples:      5452800 | elapsed time per iteration (ms): 341.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.313160E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170500/  200000 | consumed samples:      5456000 | elapsed time per iteration (ms): 365.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.164089E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170600/  200000 | consumed samples:      5459200 | elapsed time per iteration (ms): 386.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.262455E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170700/  200000 | consumed samples:      5462400 | elapsed time per iteration (ms): 379.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.231907E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170800/  200000 | consumed samples:      5465600 | elapsed time per iteration (ms): 359.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.197504E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   170900/  200000 | consumed samples:      5468800 | elapsed time per iteration (ms): 557.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.285800E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171000/  200000 | consumed samples:      5472000 | elapsed time per iteration (ms): 380.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.144372E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171100/  200000 | consumed samples:      5475200 | elapsed time per iteration (ms): 363.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.407663E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171200/  200000 | consumed samples:      5478400 | elapsed time per iteration (ms): 386.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.304135E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171300/  200000 | consumed samples:      5481600 | elapsed time per iteration (ms): 359.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.546615E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171400/  200000 | consumed samples:      5484800 | elapsed time per iteration (ms): 311.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.197393E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171500/  200000 | consumed samples:      5488000 | elapsed time per iteration (ms): 360.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.202063E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171600/  200000 | consumed samples:      5491200 | elapsed time per iteration (ms): 334.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.251846E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171700/  200000 | consumed samples:      5494400 | elapsed time per iteration (ms): 401.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.084408E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171800/  200000 | consumed samples:      5497600 | elapsed time per iteration (ms): 314.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.184399E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   171900/  200000 | consumed samples:      5500800 | elapsed time per iteration (ms): 337.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.380870E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172000/  200000 | consumed samples:      5504000 | elapsed time per iteration (ms): 352.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.181963E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   172100/  200000 | consumed samples:      5507200 | elapsed time per iteration (ms): 375.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.387795E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   172200/  200000 | consumed samples:      5510400 | elapsed time per iteration (ms): 385.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.939585E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172300/  200000 | consumed samples:      5513600 | elapsed time per iteration (ms): 391.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.187303E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172400/  200000 | consumed samples:      5516800 | elapsed time per iteration (ms): 404.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.331652E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172500/  200000 | consumed samples:      5520000 | elapsed time per iteration (ms): 354.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.047722E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172600/  200000 | consumed samples:      5523200 | elapsed time per iteration (ms): 394.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.194264E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172700/  200000 | consumed samples:      5526400 | elapsed time per iteration (ms): 318.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.329660E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172800/  200000 | consumed samples:      5529600 | elapsed time per iteration (ms): 389.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.234211E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   172900/  200000 | consumed samples:      5532800 | elapsed time per iteration (ms): 327.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.404964E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173000/  200000 | consumed samples:      5536000 | elapsed time per iteration (ms): 310.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.311668E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173100/  200000 | consumed samples:      5539200 | elapsed time per iteration (ms): 430.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.076827E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173200/  200000 | consumed samples:      5542400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.106922E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173300/  200000 | consumed samples:      5545600 | elapsed time per iteration (ms): 306.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.026289E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   173400/  200000 | consumed samples:      5548800 | elapsed time per iteration (ms): 315.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.204225E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173500/  200000 | consumed samples:      5552000 | elapsed time per iteration (ms): 317.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.472978E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173600/  200000 | consumed samples:      5555200 | elapsed time per iteration (ms): 342.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.230848E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173700/  200000 | consumed samples:      5558400 | elapsed time per iteration (ms): 405.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.198211E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173800/  200000 | consumed samples:      5561600 | elapsed time per iteration (ms): 363.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.124118E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   173900/  200000 | consumed samples:      5564800 | elapsed time per iteration (ms): 318.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.112740E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   174000/  200000 | consumed samples:      5568000 | elapsed time per iteration (ms): 356.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.272060E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174100/  200000 | consumed samples:      5571200 | elapsed time per iteration (ms): 347.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.212362E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174200/  200000 | consumed samples:      5574400 | elapsed time per iteration (ms): 377.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.077402E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174300/  200000 | consumed samples:      5577600 | elapsed time per iteration (ms): 374.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301310E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174400/  200000 | consumed samples:      5580800 | elapsed time per iteration (ms): 458.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.451098E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174500/  200000 | consumed samples:      5584000 | elapsed time per iteration (ms): 527.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301934E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174600/  200000 | consumed samples:      5587200 | elapsed time per iteration (ms): 407.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.210118E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174700/  200000 | consumed samples:      5590400 | elapsed time per iteration (ms): 447.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.101297E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174800/  200000 | consumed samples:      5593600 | elapsed time per iteration (ms): 349.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.206585E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   174900/  200000 | consumed samples:      5596800 | elapsed time per iteration (ms): 366.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.793359E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175000/  200000 | consumed samples:      5600000 | elapsed time per iteration (ms): 374.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.070898E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175100/  200000 | consumed samples:      5603200 | elapsed time per iteration (ms): 371.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.991340E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175200/  200000 | consumed samples:      5606400 | elapsed time per iteration (ms): 359.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.246660E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175300/  200000 | consumed samples:      5609600 | elapsed time per iteration (ms): 407.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.081962E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175400/  200000 | consumed samples:      5612800 | elapsed time per iteration (ms): 352.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.165748E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175500/  200000 | consumed samples:      5616000 | elapsed time per iteration (ms): 362.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.026251E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175600/  200000 | consumed samples:      5619200 | elapsed time per iteration (ms): 344.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.960428E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175700/  200000 | consumed samples:      5622400 | elapsed time per iteration (ms): 402.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.805241E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175800/  200000 | consumed samples:      5625600 | elapsed time per iteration (ms): 336.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.253471E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   175900/  200000 | consumed samples:      5628800 | elapsed time per iteration (ms): 378.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.984546E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176000/  200000 | consumed samples:      5632000 | elapsed time per iteration (ms): 374.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.182657E-06 | loss scale: 1073741824.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   176100/  200000 | consumed samples:      5635200 | elapsed time per iteration (ms): 365.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.193567E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   176200/  200000 | consumed samples:      5638400 | elapsed time per iteration (ms): 345.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.099061E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176300/  200000 | consumed samples:      5641600 | elapsed time per iteration (ms): 385.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.213923E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176400/  200000 | consumed samples:      5644800 | elapsed time per iteration (ms): 367.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.268329E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176500/  200000 | consumed samples:      5648000 | elapsed time per iteration (ms): 367.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.107805E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176600/  200000 | consumed samples:      5651200 | elapsed time per iteration (ms): 439.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.204717E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176700/  200000 | consumed samples:      5654400 | elapsed time per iteration (ms): 383.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.289054E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   176800/  200000 | consumed samples:      5657600 | elapsed time per iteration (ms): 350.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.979859E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   176900/  200000 | consumed samples:      5660800 | elapsed time per iteration (ms): 346.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.261668E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177000/  200000 | consumed samples:      5664000 | elapsed time per iteration (ms): 351.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.306037E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177100/  200000 | consumed samples:      5667200 | elapsed time per iteration (ms): 358.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.387780E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177200/  200000 | consumed samples:      5670400 | elapsed time per iteration (ms): 375.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.302024E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177300/  200000 | consumed samples:      5673600 | elapsed time per iteration (ms): 348.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.339591E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177400/  200000 | consumed samples:      5676800 | elapsed time per iteration (ms): 391.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.403482E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177500/  200000 | consumed samples:      5680000 | elapsed time per iteration (ms): 348.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.281738E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177600/  200000 | consumed samples:      5683200 | elapsed time per iteration (ms): 369.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.533478E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177700/  200000 | consumed samples:      5686400 | elapsed time per iteration (ms): 359.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.513001E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177800/  200000 | consumed samples:      5689600 | elapsed time per iteration (ms): 378.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.089265E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   177900/  200000 | consumed samples:      5692800 | elapsed time per iteration (ms): 347.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.294792E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178000/  200000 | consumed samples:      5696000 | elapsed time per iteration (ms): 388.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381581E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178100/  200000 | consumed samples:      5699200 | elapsed time per iteration (ms): 406.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301057E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178200/  200000 | consumed samples:      5702400 | elapsed time per iteration (ms): 376.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.273461E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178300/  200000 | consumed samples:      5705600 | elapsed time per iteration (ms): 347.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.104580E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178400/  200000 | consumed samples:      5708800 | elapsed time per iteration (ms): 361.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.375795E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178500/  200000 | consumed samples:      5712000 | elapsed time per iteration (ms): 352.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.455075E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178600/  200000 | consumed samples:      5715200 | elapsed time per iteration (ms): 409.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.540817E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178700/  200000 | consumed samples:      5718400 | elapsed time per iteration (ms): 356.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.275436E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178800/  200000 | consumed samples:      5721600 | elapsed time per iteration (ms): 353.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.452971E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   178900/  200000 | consumed samples:      5724800 | elapsed time per iteration (ms): 590.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.395279E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179000/  200000 | consumed samples:      5728000 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.221472E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179100/  200000 | consumed samples:      5731200 | elapsed time per iteration (ms): 353.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.610084E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179200/  200000 | consumed samples:      5734400 | elapsed time per iteration (ms): 345.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.508469E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   179300/  200000 | consumed samples:      5737600 | elapsed time per iteration (ms): 368.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.313291E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179400/  200000 | consumed samples:      5740800 | elapsed time per iteration (ms): 326.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.605550E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179500/  200000 | consumed samples:      5744000 | elapsed time per iteration (ms): 360.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.503016E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179600/  200000 | consumed samples:      5747200 | elapsed time per iteration (ms): 418.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.500532E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   179700/  200000 | consumed samples:      5750400 | elapsed time per iteration (ms): 348.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.264547E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179800/  200000 | consumed samples:      5753600 | elapsed time per iteration (ms): 354.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.466905E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   179900/  200000 | consumed samples:      5756800 | elapsed time per iteration (ms): 358.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.484032E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180000/  200000 | consumed samples:      5760000 | elapsed time per iteration (ms): 391.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.346570E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180100/  200000 | consumed samples:      5763200 | elapsed time per iteration (ms): 761.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.442183E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180200/  200000 | consumed samples:      5766400 | elapsed time per iteration (ms): 336.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.497169E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180300/  200000 | consumed samples:      5769600 | elapsed time per iteration (ms): 362.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.468993E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180400/  200000 | consumed samples:      5772800 | elapsed time per iteration (ms): 336.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.746518E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180500/  200000 | consumed samples:      5776000 | elapsed time per iteration (ms): 301.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.312614E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180600/  200000 | consumed samples:      5779200 | elapsed time per iteration (ms): 329.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.670736E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180700/  200000 | consumed samples:      5782400 | elapsed time per iteration (ms): 313.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.184369E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180800/  200000 | consumed samples:      5785600 | elapsed time per iteration (ms): 290.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.432985E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   180900/  200000 | consumed samples:      5788800 | elapsed time per iteration (ms): 318.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.446888E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181000/  200000 | consumed samples:      5792000 | elapsed time per iteration (ms): 303.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.320141E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181100/  200000 | consumed samples:      5795200 | elapsed time per iteration (ms): 298.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.388344E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181200/  200000 | consumed samples:      5798400 | elapsed time per iteration (ms): 297.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.381253E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181300/  200000 | consumed samples:      5801600 | elapsed time per iteration (ms): 305.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.520635E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181400/  200000 | consumed samples:      5804800 | elapsed time per iteration (ms): 302.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.280727E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181500/  200000 | consumed samples:      5808000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.459840E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181600/  200000 | consumed samples:      5811200 | elapsed time per iteration (ms): 301.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.348917E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   181700/  200000 | consumed samples:      5814400 | elapsed time per iteration (ms): 296.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.269776E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   181800/  200000 | consumed samples:      5817600 | elapsed time per iteration (ms): 294.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.401607E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   181900/  200000 | consumed samples:      5820800 | elapsed time per iteration (ms): 288.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.464230E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182000/  200000 | consumed samples:      5824000 | elapsed time per iteration (ms): 286.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.207329E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182100/  200000 | consumed samples:      5827200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.168850E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182200/  200000 | consumed samples:      5830400 | elapsed time per iteration (ms): 373.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.339250E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182300/  200000 | consumed samples:      5833600 | elapsed time per iteration (ms): 516.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.333658E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182400/  200000 | consumed samples:      5836800 | elapsed time per iteration (ms): 364.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.331002E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182500/  200000 | consumed samples:      5840000 | elapsed time per iteration (ms): 380.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.468458E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182600/  200000 | consumed samples:      5843200 | elapsed time per iteration (ms): 392.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.241957E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182700/  200000 | consumed samples:      5846400 | elapsed time per iteration (ms): 383.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.348982E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182800/  200000 | consumed samples:      5849600 | elapsed time per iteration (ms): 364.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.356428E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   182900/  200000 | consumed samples:      5852800 | elapsed time per iteration (ms): 367.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.368828E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183000/  200000 | consumed samples:      5856000 | elapsed time per iteration (ms): 382.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.444997E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   183100/  200000 | consumed samples:      5859200 | elapsed time per iteration (ms): 377.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.482486E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183200/  200000 | consumed samples:      5862400 | elapsed time per iteration (ms): 391.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.466182E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183300/  200000 | consumed samples:      5865600 | elapsed time per iteration (ms): 415.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.405895E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   183400/  200000 | consumed samples:      5868800 | elapsed time per iteration (ms): 359.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.070343E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183500/  200000 | consumed samples:      5872000 | elapsed time per iteration (ms): 359.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.412371E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183600/  200000 | consumed samples:      5875200 | elapsed time per iteration (ms): 371.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.239820E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183700/  200000 | consumed samples:      5878400 | elapsed time per iteration (ms): 344.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.247855E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183800/  200000 | consumed samples:      5881600 | elapsed time per iteration (ms): 347.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.253652E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   183900/  200000 | consumed samples:      5884800 | elapsed time per iteration (ms): 360.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.198015E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184000/  200000 | consumed samples:      5888000 | elapsed time per iteration (ms): 458.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.200153E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184100/  200000 | consumed samples:      5891200 | elapsed time per iteration (ms): 345.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.099876E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184200/  200000 | consumed samples:      5894400 | elapsed time per iteration (ms): 391.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.351316E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184300/  200000 | consumed samples:      5897600 | elapsed time per iteration (ms): 382.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.094137E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184400/  200000 | consumed samples:      5900800 | elapsed time per iteration (ms): 373.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.277944E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184500/  200000 | consumed samples:      5904000 | elapsed time per iteration (ms): 371.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.269434E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184600/  200000 | consumed samples:      5907200 | elapsed time per iteration (ms): 424.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.205502E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   184700/  200000 | consumed samples:      5910400 | elapsed time per iteration (ms): 346.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.143341E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   184800/  200000 | consumed samples:      5913600 | elapsed time per iteration (ms): 397.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.432739E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   184900/  200000 | consumed samples:      5916800 | elapsed time per iteration (ms): 361.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.134091E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185000/  200000 | consumed samples:      5920000 | elapsed time per iteration (ms): 378.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.078742E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185100/  200000 | consumed samples:      5923200 | elapsed time per iteration (ms): 341.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.322685E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185200/  200000 | consumed samples:      5926400 | elapsed time per iteration (ms): 379.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.300688E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185300/  200000 | consumed samples:      5929600 | elapsed time per iteration (ms): 355.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.384541E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185400/  200000 | consumed samples:      5932800 | elapsed time per iteration (ms): 379.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.215360E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185500/  200000 | consumed samples:      5936000 | elapsed time per iteration (ms): 345.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.106217E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185600/  200000 | consumed samples:      5939200 | elapsed time per iteration (ms): 346.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.309925E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185700/  200000 | consumed samples:      5942400 | elapsed time per iteration (ms): 344.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.203543E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   185800/  200000 | consumed samples:      5945600 | elapsed time per iteration (ms): 373.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.181173E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   185900/  200000 | consumed samples:      5948800 | elapsed time per iteration (ms): 355.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.205039E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186000/  200000 | consumed samples:      5952000 | elapsed time per iteration (ms): 353.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.342709E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186100/  200000 | consumed samples:      5955200 | elapsed time per iteration (ms): 398.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.276797E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186200/  200000 | consumed samples:      5958400 | elapsed time per iteration (ms): 362.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.181219E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186300/  200000 | consumed samples:      5961600 | elapsed time per iteration (ms): 398.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.442829E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186400/  200000 | consumed samples:      5964800 | elapsed time per iteration (ms): 303.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.315916E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186500/  200000 | consumed samples:      5968000 | elapsed time per iteration (ms): 356.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.254319E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186600/  200000 | consumed samples:      5971200 | elapsed time per iteration (ms): 401.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.525681E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   186700/  200000 | consumed samples:      5974400 | elapsed time per iteration (ms): 365.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.561693E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186800/  200000 | consumed samples:      5977600 | elapsed time per iteration (ms): 426.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.603526E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   186900/  200000 | consumed samples:      5980800 | elapsed time per iteration (ms): 345.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.134864E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187000/  200000 | consumed samples:      5984000 | elapsed time per iteration (ms): 362.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.391468E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187100/  200000 | consumed samples:      5987200 | elapsed time per iteration (ms): 394.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.194539E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187200/  200000 | consumed samples:      5990400 | elapsed time per iteration (ms): 347.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.137912E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187300/  200000 | consumed samples:      5993600 | elapsed time per iteration (ms): 401.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.112737E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187400/  200000 | consumed samples:      5996800 | elapsed time per iteration (ms): 347.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.406960E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187500/  200000 | consumed samples:      6000000 | elapsed time per iteration (ms): 474.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.165738E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187600/  200000 | consumed samples:      6003200 | elapsed time per iteration (ms): 368.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.387785E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187700/  200000 | consumed samples:      6006400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.204295E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187800/  200000 | consumed samples:      6009600 | elapsed time per iteration (ms): 374.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.319550E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   187900/  200000 | consumed samples:      6012800 | elapsed time per iteration (ms): 336.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.346354E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188000/  200000 | consumed samples:      6016000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.189906E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188100/  200000 | consumed samples:      6019200 | elapsed time per iteration (ms): 354.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.224419E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188200/  200000 | consumed samples:      6022400 | elapsed time per iteration (ms): 464.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.241504E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188300/  200000 | consumed samples:      6025600 | elapsed time per iteration (ms): 333.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.420759E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188400/  200000 | consumed samples:      6028800 | elapsed time per iteration (ms): 328.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.364120E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188500/  200000 | consumed samples:      6032000 | elapsed time per iteration (ms): 358.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.176213E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188600/  200000 | consumed samples:      6035200 | elapsed time per iteration (ms): 355.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.264438E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   188700/  200000 | consumed samples:      6038400 | elapsed time per iteration (ms): 337.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.257654E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   188800/  200000 | consumed samples:      6041600 | elapsed time per iteration (ms): 335.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.267708E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   188900/  200000 | consumed samples:      6044800 | elapsed time per iteration (ms): 287.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.114090E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189000/  200000 | consumed samples:      6048000 | elapsed time per iteration (ms): 329.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.332341E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189100/  200000 | consumed samples:      6051200 | elapsed time per iteration (ms): 339.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.191300E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189200/  200000 | consumed samples:      6054400 | elapsed time per iteration (ms): 361.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.420378E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189300/  200000 | consumed samples:      6057600 | elapsed time per iteration (ms): 354.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.134540E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189400/  200000 | consumed samples:      6060800 | elapsed time per iteration (ms): 351.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.186169E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189500/  200000 | consumed samples:      6064000 | elapsed time per iteration (ms): 313.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.238669E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189600/  200000 | consumed samples:      6067200 | elapsed time per iteration (ms): 299.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.524717E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189700/  200000 | consumed samples:      6070400 | elapsed time per iteration (ms): 340.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.290546E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189800/  200000 | consumed samples:      6073600 | elapsed time per iteration (ms): 314.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.136355E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   189900/  200000 | consumed samples:      6076800 | elapsed time per iteration (ms): 328.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.314654E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190000/  200000 | consumed samples:      6080000 | elapsed time per iteration (ms): 379.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.016753E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190100/  200000 | consumed samples:      6083200 | elapsed time per iteration (ms): 338.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.414140E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190200/  200000 | consumed samples:      6086400 | elapsed time per iteration (ms): 411.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.198036E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190300/  200000 | consumed samples:      6089600 | elapsed time per iteration (ms): 328.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.058663E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190400/  200000 | consumed samples:      6092800 | elapsed time per iteration (ms): 551.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.106189E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190500/  200000 | consumed samples:      6096000 | elapsed time per iteration (ms): 336.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.224850E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190600/  200000 | consumed samples:      6099200 | elapsed time per iteration (ms): 396.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.213243E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   190700/  200000 | consumed samples:      6102400 | elapsed time per iteration (ms): 348.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.085618E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190800/  200000 | consumed samples:      6105600 | elapsed time per iteration (ms): 359.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.020097E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   190900/  200000 | consumed samples:      6108800 | elapsed time per iteration (ms): 331.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.346406E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191000/  200000 | consumed samples:      6112000 | elapsed time per iteration (ms): 363.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.093492E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191100/  200000 | consumed samples:      6115200 | elapsed time per iteration (ms): 379.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.360613E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191200/  200000 | consumed samples:      6118400 | elapsed time per iteration (ms): 351.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.146465E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191300/  200000 | consumed samples:      6121600 | elapsed time per iteration (ms): 346.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.239086E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191400/  200000 | consumed samples:      6124800 | elapsed time per iteration (ms): 382.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.192225E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191500/  200000 | consumed samples:      6128000 | elapsed time per iteration (ms): 378.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.197896E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191600/  200000 | consumed samples:      6131200 | elapsed time per iteration (ms): 336.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.966223E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191700/  200000 | consumed samples:      6134400 | elapsed time per iteration (ms): 369.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.043398E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   191800/  200000 | consumed samples:      6137600 | elapsed time per iteration (ms): 368.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.097454E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   191900/  200000 | consumed samples:      6140800 | elapsed time per iteration (ms): 359.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.393895E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192000/  200000 | consumed samples:      6144000 | elapsed time per iteration (ms): 366.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.129932E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   192100/  200000 | consumed samples:      6147200 | elapsed time per iteration (ms): 362.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.194801E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192200/  200000 | consumed samples:      6150400 | elapsed time per iteration (ms): 348.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.265096E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192300/  200000 | consumed samples:      6153600 | elapsed time per iteration (ms): 369.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.307141E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192400/  200000 | consumed samples:      6156800 | elapsed time per iteration (ms): 362.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.477421E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192500/  200000 | consumed samples:      6160000 | elapsed time per iteration (ms): 411.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.204979E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192600/  200000 | consumed samples:      6163200 | elapsed time per iteration (ms): 426.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.218008E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192700/  200000 | consumed samples:      6166400 | elapsed time per iteration (ms): 378.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.263743E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192800/  200000 | consumed samples:      6169600 | elapsed time per iteration (ms): 339.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.258592E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   192900/  200000 | consumed samples:      6172800 | elapsed time per iteration (ms): 390.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.264958E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193000/  200000 | consumed samples:      6176000 | elapsed time per iteration (ms): 349.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.352168E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193100/  200000 | consumed samples:      6179200 | elapsed time per iteration (ms): 371.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.319432E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193200/  200000 | consumed samples:      6182400 | elapsed time per iteration (ms): 350.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.198465E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   193300/  200000 | consumed samples:      6185600 | elapsed time per iteration (ms): 378.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.210681E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   193400/  200000 | consumed samples:      6188800 | elapsed time per iteration (ms): 366.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.046691E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193500/  200000 | consumed samples:      6192000 | elapsed time per iteration (ms): 397.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.304791E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193600/  200000 | consumed samples:      6195200 | elapsed time per iteration (ms): 347.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.386889E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193700/  200000 | consumed samples:      6198400 | elapsed time per iteration (ms): 349.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.380273E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   193800/  200000 | consumed samples:      6201600 | elapsed time per iteration (ms): 372.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.265935E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   193900/  200000 | consumed samples:      6204800 | elapsed time per iteration (ms): 359.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.163341E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194000/  200000 | consumed samples:      6208000 | elapsed time per iteration (ms): 356.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.191605E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194100/  200000 | consumed samples:      6211200 | elapsed time per iteration (ms): 377.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.223784E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194200/  200000 | consumed samples:      6214400 | elapsed time per iteration (ms): 344.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.308328E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194300/  200000 | consumed samples:      6217600 | elapsed time per iteration (ms): 392.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.258439E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194400/  200000 | consumed samples:      6220800 | elapsed time per iteration (ms): 354.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.038417E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194500/  200000 | consumed samples:      6224000 | elapsed time per iteration (ms): 412.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.301828E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194600/  200000 | consumed samples:      6227200 | elapsed time per iteration (ms): 373.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.290689E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194700/  200000 | consumed samples:      6230400 | elapsed time per iteration (ms): 365.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.327921E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194800/  200000 | consumed samples:      6233600 | elapsed time per iteration (ms): 331.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.277994E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   194900/  200000 | consumed samples:      6236800 | elapsed time per iteration (ms): 359.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.194818E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195000/  200000 | consumed samples:      6240000 | elapsed time per iteration (ms): 348.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.010783E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195100/  200000 | consumed samples:      6243200 | elapsed time per iteration (ms): 360.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.442955E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195200/  200000 | consumed samples:      6246400 | elapsed time per iteration (ms): 340.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.424900E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195300/  200000 | consumed samples:      6249600 | elapsed time per iteration (ms): 351.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.220207E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195400/  200000 | consumed samples:      6252800 | elapsed time per iteration (ms): 360.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.321891E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195500/  200000 | consumed samples:      6256000 | elapsed time per iteration (ms): 345.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.156290E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195600/  200000 | consumed samples:      6259200 | elapsed time per iteration (ms): 400.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.160507E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195700/  200000 | consumed samples:      6262400 | elapsed time per iteration (ms): 334.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.046648E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   195800/  200000 | consumed samples:      6265600 | elapsed time per iteration (ms): 369.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.997028E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   195900/  200000 | consumed samples:      6268800 | elapsed time per iteration (ms): 347.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.086575E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   196000/  200000 | consumed samples:      6272000 | elapsed time per iteration (ms): 357.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.132064E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196100/  200000 | consumed samples:      6275200 | elapsed time per iteration (ms): 347.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.176852E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196200/  200000 | consumed samples:      6278400 | elapsed time per iteration (ms): 414.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.045001E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196300/  200000 | consumed samples:      6281600 | elapsed time per iteration (ms): 328.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.186460E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196400/  200000 | consumed samples:      6284800 | elapsed time per iteration (ms): 349.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.050909E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196500/  200000 | consumed samples:      6288000 | elapsed time per iteration (ms): 348.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.122638E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196600/  200000 | consumed samples:      6291200 | elapsed time per iteration (ms): 377.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.104060E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196700/  200000 | consumed samples:      6294400 | elapsed time per iteration (ms): 338.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.010666E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196800/  200000 | consumed samples:      6297600 | elapsed time per iteration (ms): 297.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.142083E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   196900/  200000 | consumed samples:      6300800 | elapsed time per iteration (ms): 346.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.099253E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197000/  200000 | consumed samples:      6304000 | elapsed time per iteration (ms): 288.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.107766E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197100/  200000 | consumed samples:      6307200 | elapsed time per iteration (ms): 286.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.979315E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197200/  200000 | consumed samples:      6310400 | elapsed time per iteration (ms): 289.7 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.977112E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197300/  200000 | consumed samples:      6313600 | elapsed time per iteration (ms): 282.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.953800E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197400/  200000 | consumed samples:      6316800 | elapsed time per iteration (ms): 290.5 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.011561E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197500/  200000 | consumed samples:      6320000 | elapsed time per iteration (ms): 283.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.082673E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197600/  200000 | consumed samples:      6323200 | elapsed time per iteration (ms): 308.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.984264E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197700/  200000 | consumed samples:      6326400 | elapsed time per iteration (ms): 350.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.086006E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197800/  200000 | consumed samples:      6329600 | elapsed time per iteration (ms): 440.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.910939E-06 | loss scale: 1073741824.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   197900/  200000 | consumed samples:      6332800 | elapsed time per iteration (ms): 318.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.915635E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198000/  200000 | consumed samples:      6336000 | elapsed time per iteration (ms): 297.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.067725E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   198100/  200000 | consumed samples:      6339200 | elapsed time per iteration (ms): 357.3 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.257666E-06 | loss scale: 2147483648.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198200/  200000 | consumed samples:      6342400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.281945E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   198300/  200000 | consumed samples:      6345600 | elapsed time per iteration (ms): 450.2 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.189895E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198400/  200000 | consumed samples:      6348800 | elapsed time per iteration (ms): 287.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.969608E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198500/  200000 | consumed samples:      6352000 | elapsed time per iteration (ms): 378.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.185859E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration   198600/  200000 | consumed samples:      6355200 | elapsed time per iteration (ms): 398.8 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.112314E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198700/  200000 | consumed samples:      6358400 | elapsed time per iteration (ms): 476.9 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.225298E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198800/  200000 | consumed samples:      6361600 | elapsed time per iteration (ms): 391.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.260915E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   198900/  200000 | consumed samples:      6364800 | elapsed time per iteration (ms): 396.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.316269E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199000/  200000 | consumed samples:      6368000 | elapsed time per iteration (ms): 415.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.085641E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199100/  200000 | consumed samples:      6371200 | elapsed time per iteration (ms): 419.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.194179E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199200/  200000 | consumed samples:      6374400 | elapsed time per iteration (ms): 403.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.249237E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199300/  200000 | consumed samples:      6377600 | elapsed time per iteration (ms): 343.6 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.129687E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199400/  200000 | consumed samples:      6380800 | elapsed time per iteration (ms): 397.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.108096E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199500/  200000 | consumed samples:      6384000 | elapsed time per iteration (ms): 360.1 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.141215E-06 | loss scale: 536870912.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199600/  200000 | consumed samples:      6387200 | elapsed time per iteration (ms): 415.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.029197E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 iteration   199700/  200000 | consumed samples:      6390400 | elapsed time per iteration (ms): 327.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.972082E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199800/  200000 | consumed samples:      6393600 | elapsed time per iteration (ms): 381.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 4.941276E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   199900/  200000 | consumed samples:      6396800 | elapsed time per iteration (ms): 352.4 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.043725E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration   200000/  200000 | consumed samples:      6400000 | elapsed time per iteration (ms): 372.0 | learning rate: 1.000E-05 | global batch size:    32 | lm loss: 5.198753E-06 | loss scale: 268435456.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
